- [IAM: Users & Groups](#IAM:-Users-&-Groups)
  - [IAM User 만들기](#IAM-User-만들기)
  - [정책](#정책)
  - [Password Policy](#Password-Policy)
    - [가상 MFA 장치](#가상-MFA-장치)
    - [U2F 보안 키](#U2F-보안-키)
  - [MFA 설정](#MFA-설정)
  - [AWS 액세스 키, CLI 및 SDK](#AWS-액세스-키,-CLI-및-SDK)
    - [CLI 란 무엇일까?](#CLI-란-무엇일까?)
    - [SDK 란 무엇일까?](#SDK-란-무엇일까?)
  - [CLI Install](#CLI-Install)
  - [AWS CLI 연습](#AWS-CLI-연습)
  - [역할](#역할)
    - [IAM 액세스 관리자](#IAM-액세스-관리자)
    - [IAM 모범 사례](#IAM-모범-사례)
- [EC2 기초](#EC2-기초)
  - [인스턴스 유형](#인스턴스-유형)
    - [범용의 인스턴스](#범용의-인스턴스)
    - [컴퓨팅 최적화 인스턴스](#컴퓨팅-최적화-인스턴스)
    - [메모리 최적화의 인스턴스](#메모리-최적화의-인스턴스)
    - [스토리지 최적화 인스턴스](#스토리지-최적화-인스턴스)
  - [보안 그룹](#보안-그룹)
    - [SSH](#SSH)
  - [온-디맨드 인스턴스](#온-디맨드-인스턴스)
  - [예약 인스턴스](#예약-인스턴스)
    - [정기 예약 인스턴스](#정기-예약-인스턴스)
    - [스팟 인스턴스](#스팟-인스턴스)
    - [전용 호스트](#전용-호스트)
    - [전용 인스턴스](#전용-인스턴스)
- [EBS 볼륨](#EBS-볼륨)
  - [스냅샷](#스냅샷)
  - [AMI](#AMI)
  - [인스턴스 스토어](#인스턴스-스토어)
  - [EBS 볼륨](#EBS-볼륨)
    - [IOPS](#IOPS)
    - [스토리지](#스토리지)
    - [st1과 sc1](#st1과-sc1)
    - [EBS 다중 연결](#EBS-다중-연결)
  - [EFS](#EFS)
    - [성능 모드](#성능-모드)
    - [처리량 모드](#처리량-모드)
  - [EBS vs EFS](#EBS-vs-EFS)
  - [EBS](#EBS)
  - [EFS](#EFS)
- [ELB](#ELB)
  - [고가용성과 확장성](#고가용성과-확장성)
    - [확장성](#확장성)
  - [로드 밸런싱](#로드-밸런싱)
  - [Sticky Sessions](#Sticky-Sessions)
    - [애플리케이션 기반 쿠키](#애플리케이션-기반-쿠키)
    - [기간 기반 쿠키](#기간-기반-쿠키)
  - [교차 영역 로드 밸런싱](#교차-영역-로드-밸런싱)
  - [SSL](#SSL)
  - [등록 취소 지연](#등록-취소-지연)
  - [오토스케일링 AGS](#오토스케일링-AGS)
    - [오토 스케일링 그룹의 스케일링 정책](#오토-스케일링-그룹의-스케일링-정책)
- [EBS 볼륨](EBS-볼륨)
  - [스냅샷](#스냅샷)
  - [AMI](#AMI)
  - [인스턴스 스토어](#인스턴스-스토어)
  - [EBS 볼륨](#EBS-볼륨)
    - [IOPS](#IOPS)
    - [스토리지](#스토리지)
    - [st1과 sc1](#st1과-sc1)
    - [EBS 다중 연결](#EBS-다중-연결)
  - [EFS](#EFS)
    - [성능 모드](#성능-모드)
    - [처리량 모드](#처리량-모드)
  - [EBS vs EFS](#EBS vs EFS)
    - [EBS](#EBS)
    - [EFS](#EFS)
- [RDS](#RDS)
  - [백업](#백업)
    - [오토스케일링](#오토스케일링)
  - [RDS 다중 AZ (Multi AZ)](#RDS-다중-AZ-(Multi AZ))
  - [읽기 전용 복제본 (Read Replica)](#읽기-전용-복제본-(Read Replica))
  - [암호화](#암호화)
  - [인증](#인증)
  - [Amazon 오로라(Aurora)](#Amazon-오로라(Aurora))
  - [Amazon 일래스틱 캐시](#Amazon-일래스틱-캐시)
    - [Memcached 를 선택](#Memcached-를-선택)
    - [Redis 를 선택](#Redis-를-선택)
  - [일래스틱캐시 (ElastiCashe) 전략](#일래스틱캐시-(ElastiCashe)-전략)
    - [레이지 로딩(Lazy Loading)](#레이지-로딩(Lazy Loading))
    - [라이트 스루(Write Through)](#라이트-스루(Write Through))
    - [캐시 제거와 타임 투 리브(TTL)](#캐시-제거와-타임-투-리브(TTL))
  - [Redis 클러스터 모드](#Redis-클러스터-모드)
    - [클러스터 모드 비활성화입니다](#클러스터-모드-비활성화입니다)
    - [클러스터 모드 활성화](#클러스터-모드-활성화)
- [DNS](#DNS)
  - [Route 53](#Route 53)
    - [A 레코드](#A-레코드)
    - [AAAA 레코드](#AAAA-레코드) 
    - [CNAME 레코드](#CNAME-레코드) 
    - [NS 레코드](#NS-레코드) 
    - [호스팅 존](#호스팅-존)
  - [레코드 TTL(Time To Live)](#레코드-TTL(Time To Live))
  - [CNAME 과 별칭의 차이](#CNAME-과-별칭의-차이)
  - [라우팅 정책](#라우팅-정책)
    - [단순 라우팅 정책](#단순-라우팅-정책) 
    - [가중치 기반 라우팅 정책](#가중치-기반-라우팅-정책) 
    - [지연 시간 기반 라우팅 정책](#지연-시간-기반-라우팅-정책)
    - [상태 확인 정책](#상태-확인-정책)
    - [장애 조치 정책](#장애-조치-정책)
    - [지리 위치(Geolocation) 라우팅 정책](#지리-위치(Geolocation)-라우팅-정책)
  - [지리 근접 라우팅](#지리-근접-라우팅)
    - [트래픽 플로우](#트래픽-플로우)
  - [다중 응답 라우팅 정책 (Multivalue answer)](#다중-응답-라우팅-정책-(Multivalue answer))
- [VPC](#VPC)
  - [네트워크 ACL의 개념과 보안 그룹](#네트워크-ACL의-개념과-보안-그룹) 
  - [VPC 플로우 로그](#VPC-플로우-로그)
  - [VPC 피어링](#VPC-피어링)
  - [NAT 게이트웨이](#NAT-게이트웨이)
- [S3](#S3)
  - [버전 관리](#버전-관리)
  - [객체 암호화](#객체-암호화)
    - [SSE-S3](#SSE-S3)
    - [SSE-KMS](#SSE-KMS)
    - [SSE-C](#SSE-C)
    - [클라이언트 측 암호화](#클라이언트-측-암호화)
  - [보안](#보안)
    - [사용자 기반 보안](#사용자-기반-보안)
    - [리소스 기반 보안](#리소스-기반-보안)
    - [S3 버킷 정책](#S3-버킷-정책)
    - [사전 서명된 URL](#사전-서명된-URL)
  - [정적 웹사이트](#정적-웹사이트)
  - [CORS 교차 오리진 리소스 공유](#CORS-교차-오리진-리소스-공유)
- [IAM 역할 및 정책](#IAM-역할-및-정책)
  - [CLI](#CLI)
  - [EC2 인스턴스 메타데이터](#EC2-인스턴스-메타데이터)
  - [AWS CLI 프로필](#AWS-CLI-프로필)
  - [MFA가 있는 AWS CLI](#MFA가-있는-AWS-CLI)
  - [AWS SDK 개요](#AWS-SDK-개요)
  - [지수 백오프 및 서비스 제한 증가](#지수-백오프-및-서비스-제한-증가)
    - [지수 백오프의 원리는 무엇일까요?](#지수-백오프의-원리는-무엇일까요?)
  - [자격 증명 공급자 및 체인](#자격-증명-공급자-및-체인)
    - [SDK](#SDK)
  - [AWS 서명 v4 서명](#AWS-서명-v4-서명)

# IAM: Users & Groups

IAM 은 `Identity and Access Management` 의 약자로  
IAM 에서는 사용자를 생성하고  
그룹에 배치하기 때문에 글로벌 서비스에 해당됩니다  

AWS에서는 모든 사용자에게 모든 것을 허용하지 않습니다  
그러면 엉망이 될 겁니다  
새로운 사용자가 너무 많은 서비스를 실행하여 큰 비용이  
발생하거나, 보안 문제를 야기할 수 있기 때문이죠  
따라서 AWS에서는 최소 권한의 원칙을 적용합니다  
즉 사용자가 꼭 필요로 하는 것 이상의 권한을 주지 않는 것입니다.  

## IAM User 만들기

처음으로 할 일은 IAM 사용자를 생성하는 것이죠

https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-1#/users

Users 항목으로 이동해 Add users 를 선택하겠습니다  
보시는 것처럼 상단의 계정 이름을 클릭해 보시면  
현재 루트 계정을 사용 중이죠  
루트 사용자는 계정에 대한 모든 권한을 가지고 있습니다  
그렇기 때문에 위험한 계정이 될 수도 있죠  
따라서 별도의 관리자 계정을 만드는 것이 좋습니다  
루트 계정은 정말로 반드시 꼭 필요할 때만 사용할 겁니다  

그룹 이름은 admin으로 하겠습니다  
admin 그룹에 배치된 사용자는  
이 그룹에 부여된 권한을 승계하게 됩니다  
그리고 권한은 정책을 통해 정의되죠  
admin 그룹에 연결할 정책은 AdministratorAccess 입니다
이 정책은 admin 그룹에 속한 모든 사용자가
계정의 관리자 역할을 하도록 허용할 겁니다  

Next: Tags를 클릭합니다  
AWS에서는 어디에서든 태그를 찾을 수 있는데요  
사용자의 접근을 추적, 조직, 제어할 수 있도록 도와주는 정보입니다    
이 강의에서는 굳이 여기저기에 태그를 만들지 않을 겁니다  
다만 사용자를 위한 태그 생성 방법을 보여드리죠  
그 특정 사용자에 대해 단순히 정보를 추가하는 것입니다  
예를 들어, 이 사용자가 속한 부서는 엔지니어링이라고 표시할 수 있죠

## 정책

~~~
{
    "Version": "2012-10-17",
    "Id": "S3-Account-Permissions"
    "Statement": [
        {
            "Sid": "1",
            "Effect": "Allow",
            "Principal": {
                "AWS": ["arn:aws:iam::123123123:root"]
            },
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
            ],
            "Resource": ["arn:aws:s3:::mybuckey/*"]
        }
    ]
}
~~~

IAM 정책 구조 요소는 버전 숫자를 포함하는데요  
보통은 2012-10-17로 정책 언어 버전입니다  
정책을 식별하는 `ID` 도 있는데 선택 사항이고요  
문장들도 구성 요소입니다  
문장은 하나일 수도 여러 개일 수도 있는데  
문장에는 아주 중요한 부분들이 있죠  
먼저 `Sid` 는 문장 ID로 문장의 식별자이고 역시 선택 사항입니다  
오른쪽에 보시면 1번이라고 나와있죠  
정책에서 `Effect` 는 문장이 특정 API에 접근하는 걸 허용할지 거부할지에 대한 내용입니다  
`Principal` 은 특정 정책이 적용될 사용자, 계정, 혹은 역할로 구성됩니다
이 예시에선 AWS 계정의 루트 계정에 적용이 되죠  
`Action` 은 `Effect` 에 기반해 허용 및 거부되는 API 호출의 목록입니다  
그리고 `Resource` 는 적용될 `Action` 의 리소스의 목록으로  
이 예시에선 버킷이지만 다른 것들도 될 수도 있겠죠

## Password Policy

이 그룹과 사용자들의 정보가 침해당하지 않도록 보호해야겠죠  
다요소 인증, `MFA` 입니다  
`MFA` 는 여러분이 알고 있는 비밀번호와  
여러분이 가지고 있는 보안 장치를 함께 사용하는 것입니다  
`MFA` 의 장점은 사용자가 해킹을 당해 비밀번호가  
누출된 상황이라고 해도 해커에게는 로그인을 위해 휴대전화 등  
사용자 소유의 물리적 장치가 추가로 필요해질 테니  
계정이 침해당하지 않는다는 점입니다  

AWS 에서의 `MFA 장치 옵션` 으로는 어떤 것들이 있을까요?

### 가상 MFA 장치

`Google Authenticator` 를 사용할 수 있는데 하나의 휴대전화에서만 사용이 가능하죠
`Authy` 는 여러 장치에서 사용이 가능합니다  
장치의 개수가 다를 뿐 작동 방식은 동일합니다  
개인적으로 저는 `Authy` 를 사용하는데 컴퓨터와  
휴대전화에서 같이 사용할 수 있기 때문이죠  
`Authy` 는 하나의 장치에서도 토큰을 여러 개 지원합니다  
즉, 가상 `MFA` 장치를 사용하면  
루트 계정, IAM 사용자 또 다른 계정, 그리고  
또 다른 IAM 사용자가 지원되는 식으로 가상 MFA 장치에  
원하는 수만큼의 계정 및 사용자 등록이 가능합니다  

### U2F 보안 키

이는 물리적 장치로 예를 들어  
Yubico 사의 YubiKey 가 있죠 Yubico 는 AWS 의 제3자 회사로  
AWS 제공 장치가 아니라 제3자 회사의 장치입니다  
이렇게 `물리적 장치를 사용하면 전자 열쇠`에 달고 다닐 수 있으니  
사용이 상당히 편리할 수 있겠죠  
YubiKey 는 하나의 보안 키에서 여러 루트 계정과 IAM 사용자를  
지원하기 때문에 하나의 키로도 충분합니다

### 하드웨어 키 팝 MFA 장치

역시 AWS 의 제3자 회사인 Gemalto 의 제품입니다  
만약 미국 정부의 클라우드인 AWS GovCloud 를  
사용하시는 경우라면, MFA 숫자를 실시간으로 보여주는 특수한 키 팝(작은 물건)이 필요한데요  
역시 SurePassID 라는 제3자 회사가 제공하고 있죠  

## MFA 설정

왼쪽의 `Account settings (계정 설정)` 에 들어가서  
`Change password policy (암호 정책 변경)` 를 누르면  
여기서 비밀번호 정책 적용이 가능하죠    
비밀번호 최소 길이 지정이 가능하고  
적어도 하나의 대문자 및 소문자 숫자를 포함하도록 합니다  

오른쪽에 있는 계정 이름을 클릭하고  
`My Security Credential(보안 자격 증명)` 로 들어갑니다  
https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials

`Multi-factor authentication (MFA) - 멀티 팩터 인증` 를 클릭하고  
휴대전화를 사용할 거니까 Virtual MFA device 를 선택하겠습니다

## AWS 액세스 키, CLI 및 SDK

Create access key 버튼으로 액세스 키를 생성하면  
곧 다운로드 권한이 주어질 겁니다  
직장에서 보안 문제를 피하기 위해서는  
절대 액세스 키를 공유하지 마세요 여러분만 알고 계셔야 합니다  

### CLI 란 무엇일까?

`CLI` 는 명령줄 인터페이스를 의미하며  
`AWS CLI` 는 명령줄 셸에서 명령어를 사용하여  
AWS 서비스들과 상호작용할 수 있도록 해 주는 도구입니다

`CLI` 를 사용하면 `AWS 서비스의 공용 API 로 직접 액세스가 가능`합니다
그리고 `CLI` 를 통해 리소스를 관리하는 스크립트를 개발해  
일부 작업을 자동화할 수 있죠  
`CLI` 는 오픈 소스로, GitHub 에서 모든 소스 코드를 찾으실 수 있으며  
AWS 관리 콘솔 대신 사용되기도 합니다  

### SDK 란 무엇일까?

`SDK 는 소프트웨어 개발 키트입니다`  
특정 언어로 된 라이브러리의 집합인데요  
따라서 프로그래밍 언어에 따라 개별 `SDK` 가 존재합니다  
이 방식을 사용해서도 역시 AWS 서비스나 API 에  
프로그래밍을 위한 액세스가 가능하도록 해줍니다  
하지만 `SDK 는 터미널 내에서는 사용하는 것이 아니라  
코딩을 통해 애플리케이션 내에 심어 두어야 하는 겁니다`  
애플리케이션 내에 자체적으로 AWS SDK 가 있는 거죠  
다양한 프로그래밍 언어를 지원하죠  
JavaScript Python, PHP, .NET  
Ruby, Java, Go Node.js, C++ 등을 지원합니다

## CLI Install

https://docs.aws.amazon.com/cli/latest/userguide/getting-started-version.html

## AWS CLI 연습

사용자 -> 생성된 IAM 유저 계정 클릭   
IAM 사용자인 상태이며 이제 Security credentials (보안 자격 증명) 로 이동합니다
액세스 키는 CLI, 즉 명령줄 인터페이스를 사용할 때 굉장히 유용합니다  
혹은 AWS 에 프로그래밍 언어의 구현을 위해 SDK 를 사용할 때도 유용하죠  
Create access key 를 클릭합시다 액세스 키는 기밀입니다  
오직 생성 시에만 표시 및 다운로드가 가능하죠  

먼저 AWS CLI 부터 구성해야 하는데요  
`aws configure` 라고 입력하겠습니다  
그러면 액세스 키 ID를 입력하라고 나오네요  
생성된 `액세스 키를 붙여 넣어` 입력한 후 Enter 를 누르고요  
이번엔 암호 액세스 키를 입력하라는 안내가 나옵니다  
역시 이렇게 입력해 주겠습니다  
기본 리전 이름은 가까운 리전을 말하는 겁니다  
강의 전체가 eu-west-1에서 진행될 테니 eu-west-1로 지정해 주겠습니다  
여러분들은 각자의 리전을 선택해 입력하시면 됩니다  

그럼 어떻게 작동하는지도 한 번 봐야겠죠
aws iam list-users 를 입력 후 Enter 를 누르면
제 계정의 모든 사용자를 목록으로 보여 줄 겁니다

## AWS 클라우드쉘

`CloudShell` 은 화면 우측 상단의 이 아이콘입니다  
사용 할 수 있는 리전에 있는지 확인하세요 모든 리전에서 가능한 건 아니거든요  
AWS CloudShell FAQs에 가시면 사용이 불가능한 리전이 나와 있습니다

## 역할

EC2 인스턴스는 AWS에서 어떤 작업을 수행하려고 할 수 있습니다  
그러기 위해서는 EC2 인스턴스에 권한을 부여해야 합니다  
이를 위해 IAM 역할을 만들어 이들을 하나의 개체로 만듭니다  
EC2 인스턴스가 AWS에 있는 어떤 정보에 접근하려고 할 때  
IAM 역할을 사용하게 될 것입니다  
만약 IAM 역할의 권한을 올바르게 부여한 경우  
하려고 하는 호출에 접근하게 될 것입니다  

역할은 여러분이 신뢰하는 개체에 권한을 부여하기 위해 사용됩니다

### IAM 액세스 관리자

이것은 사용자 수준에서 가능합니다 액세스 관리자는  
사용자에게 부여된 서비스의 권한과  
해당 서비스에 마지막으로 액세스한 시간이 보입니다  
최소권한의 원칙에 따랐을 때 매우 도움 되는 정보입니다  
해당 도구를 사용하여 어떤 권한이 사용되지 않는지 볼 수 있고  
따라서 사용자의 권한을 줄여 최소권한의 원칙을 지킬 수 있습니다

왼쪽 하단에 Credential report 가 있고 Download Report 를 클릭하여  
보고서를 다운로드합니다 CSV 파일이 다운로드될 거예요  
사용자가 언제 생성되었는지, 비밀번호가 활성화되었는지,  
비밀번호를 마지막으로 언제 사용했는지, 마지막으로 언제 변경되었는지,  
비밀번호 변경 주기를 활성화한 경우 다음 주기는 언제인지  
MFA 가 활성화되었는지 출력됩니다.

다음으로는 IAM 액세스 관리자를 이야기하겠습니다  
Users를 클릭합니다  
오른쪽에 Access Advisor 가 있습니다  
마지막에 사용된 서비스를 보여줄 것입니다  
보통 최근 4시간 동안의 활동 내역이 보입니다  
만약 보이지 않는다면 4시간이 지났기 때문이죠

### IAM 모범 사례

루트 계정은 AWS 계정을 설정할 때를 제외하고 사용하지 마세요  
사용자를 그룹에 넣어 해당 그룹에 권한을 부여할 수 있어요  
따라서 그룹 수준에서 보안을 관리할 수 있습니다  
또한 비밀번호 정책을 강력하게 만들어야 합니다  
다요소 인증(MFA)을 사용한다.  
AWS 서비스에 권한을 부여할 때마다 역할을 만들고 사용해야 합니다  
가상 서버인 EC2 인스턴스를 포함해서요  
AWS를 프로그래밍할 경우, 즉, CLI나 SDK를 사용할 경우  
반드시 액세스 키를 만들어야 합니다 액세스 키는 비밀번호와 같습니다

# EC2 기초

이것은 일래스틱 컴퓨트 클라우드의 약자로 AWS에서 제공하는 서비스형 인프라스트럭처입니다  
즉, EC2는 하나의 서비스가 아닙니다  
높은 수준에서 보면 많은 것을 포함하고 있습니다  
가상 머신을 EC2에서 임대할 수 있는데 이를 EC2 인스턴스라고 합니다  

데이터를 가상 드라이브 또는 EBS 볼륨에 저장할 수 있고  
일래스틱 로드 밸런서로 로드는 분산시킬 수 있습니다  
또 오토 스케일링 그룹(ASG)을 통해 서비스를 확장할 수 있습니다  

즉, EC2 사용자 데이터 스크립트를 사용하여 인스턴스를 부트스트래핑할 수 있습니다  
부트스트래핑이 무슨 뜻일까요?  
이는 머신이 작동될 때 명령을 시작하는 것을 말합니다  
스크립트는 처음 시작할 때 한 번만 실행되고 다시 실행되지 않습니다

## 인스턴스 유형

m5.2xlarge 라는 유형의 인스턴스를 예로 들어 보겠습니다  
`m 을 인스턴스 클래스`로 부르겠습니다  
그리고 이 인스턴스 클래스는 범용의 인스턴스입니다  
`5는 인스턴스의 세대`를 뜻합니다  
즉, AWS 가 하드웨어를 계속 개선해서 새로운 세대의 하드웨어를 출시하고  
m5 이후에 m 유형의 인스턴스 클래스를 개선하면  
m6가 되는 것입니다 2xlarge 는 인스턴스 클래스 내에서 크기를 나타냅니다  
small 로 시작해 large, 2xlarge 4xlarge 등의 크기가 있죠  
인스턴스의 크기를 나타내며 크기가 클수록 인스턴스에  
더 많은 메모리와 CPU 를 가지게 됩니다

### 범용의 인스턴스

먼저, 범용의 인스턴스는 웹 서버나 코드 저장소와 같은 다양한 작업에 적합합니다  
컴퓨팅, 메모리, 네트워킹 간의 균형도 잘 맞습니다

### 컴퓨팅 최적화 인스턴스

이제 컴퓨팅 최적화 인스턴스는 컴퓨터 집약적인 작업에 최적화된 인스턴스입니다  
그러면 고성능 프로세서는 어디에 사용할까요?  
일부 데이터의 일괄 처리에 사용하거나  
미디어 트랜스코딩 작업 시 혹은 고성능 웹 서버가 필요하거나  
고성능 컴퓨팅이라는 HPC 작업을 할 때 그리고 머신 러닝이나  
전용 게임 서버가 있을 때 사용합니다  
모두 훌륭한 CPU와 컴퓨팅을 요구하는 작업이며  
EC2 인스턴스는 이런 특성을 가지고 있습니다  
그리고 컴퓨터 최적화의 모든 인스턴스는  
C로 시작하는 이름을 가지고 있습니다  
C5, C6 등이죠  

### 메모리 최적화의 인스턴스

다음으로 메모리 최적화의 인스턴스를 살펴보겠습니다  
이 유형의 인스턴스는 메모리에서 대규모 데이터셋을  
처리하는 유형의 작업에 빠른 성능을 제공합니다  
메모리는 RAM을 뜻하고 사용 사례를 살펴보면  
대부분 인 메모리 데이터베이스가 되는  
고성능의 관계형 또는 비관계형의 데이터베이스에 사용하고  
일래스틱 캐시를 예로 들 수 있는  
분산 웹스케일 캐시 저장소에도 사용합니다  
즉, BI에 최적화된 인 메모리 데이터베이스와  
대규모 비정형 데이터의 실시간 처리를 실행하는  
애플리케이션에도 사용합니다

### 스토리지 최적화 인스턴스

로컬 스토리지에서 대규모의 데이터셋에  
액세스할 때 적합한 인스턴스입니다  
스토리지 최적화 인스턴스의 사용 사례로는  
고주파 온라인 트랜잭션 처리인 OLTP 시스템에 사용되며
관계형과 비관계형인 NoSQL 데이터베이스에 사용합니다  
데이터베이스 섹션에서 더 자세히 살펴보겠습니다  
예를 들어, 레디스(Redis) 같은  
메모리 데이터베이스의 캐시나 데이터 웨어하우징 애플리케이션과 분산 파일 시스템에 사용됩니다

## 보안 그룹

`EC2 인스턴스에 들어오고 나가는 트래픽을 제어`합니다
보안 그룹은 간단한데요 허용 규칙만 포함합니다  
출입이 허용된 것이 무엇인지 확인할 수 있고  
IP 주소를 참조해 규칙을 만들 수 있습니다  

### SSH

시큐어 셸이라는 의미로 다음 강의에서 살펴봅니다  
포트는 22번 포트로 Linux에서 EC2 인스턴스로 로그인하도록 합니다  
파일 전송 프로토콜인 FTP의 포트는 21번 포트이며 파일 공유 시스템에 파일을 업로드하는데 사용됩니다

SFTP도 22번 포트를 사용하는 이유는 무엇일까요? SSH를 사용해서 업로드하기 때문이고 
보안 파일 전송 프로토콜이 되기 때문입니다

원격 데스크톱 프로토콜인 RDP의 3389번 포트이며
윈도우 인스턴스에 로그인할 때 사용됩니다

### SSH 연결하기

SSH는 명령줄 인터페이스 도구로  
Mac과 Linux에서 사용할 수 있고  
Windows10 이상의 버전에서 사용할 수 있습니다  
Windows10 이하의 버전이라면  
퍼티(PuTTY)를 사용하면 됩니다  
퍼티는 SSH와 동일한 것입니다  
SSH를 사용해야 할 때 Windows에서는 퍼티를 사용합니다  
퍼티는 모든 버전의 Windows에서 사용 가능합니다  

이제 머신에 접속하기 위해  
ssh ec2-user@와  
35.180.100.144를 입력하고 키를 참조하도록 하기 위해  
머신에 접속할 수 있는 키를 이 중간에 입력합니다  
키를 사용하려면 -i를 입력하고 EC2Tutorial.pem을 입력합니다  
그러면 ssh -i EC2Tutorial.pem가 되고  
그다음은 인스턴스 사용자 이름과 인스턴스 IP가 오게 됩니다  
Enter를 클릭하면 다른 경고문이 나타납니다  
비보호의 개인 키 파일이라는 경고가 나타났습니다    
이 부분이 시험에 정말 잘 나옵니다  
파일을 처음 다운로드하면  
`0644 라는 권한이 생기는데 권한이 너무 열려 있어서 개인 키가 유출될 수 있습니다`
다른 사람이 개인 키에 접근할 수 있어 bad permissions가 나타나고  
SSH를 머신에 연결할 수 없도록 합니다  
해결하는 방법이 자주 출제되며 `해결하려면 chmod 0400` 를 입력하고  
이렇게 키 이름을 참조합니다

## 온-디맨드 인스턴스

`사용한 만큼 지불하는 옵션`이죠  
비용이 초당 청구됩니다 EC2 인스턴스가 실행된  
초반 1분 이후부터 1초당 비용이 청구되죠  
온-디맨드는 클라우드에 가장 적합한 방식으로  
`가격은 높지만, 선결제나 장기 약정이 필요 없습니다`  
사용 해지, 중지, 시작이 언제든 가능하죠  
온-디맨드 방식은  
`애플리케이션 작동 방식을 예측할 수 없는`  
연속적인 단기 워크로드에 적합합니다  

간단 예시  
첫 번째로 온-디맨드는 원할 때면 언제든
리조트에 묵을 수 있는 겁니다
전액을 지불해야 하지만 원하면 언제나 방을 얻을 수 있죠

## 예약 인스턴스

온-디맨드와 비교하면 약 75%의 비용을 절약할 수 있고
`1년 혹은 3년 중에서 선택할 수 있죠`  
3년의 기간을 선택하면 해당 인스턴스를 더 오랜 기간동안  
사용할 의향이 있다고 AWS에 알리는 것과 같습니다  

종종 오랜 시간 동안 사용해야 하는 서버가 있는 경우에는
이를 AWS에 알림으로써 비용을 절감할 수 있는데요
이럴 때 사용 가능한 첫 번째 옵션이 바로 예약 인스턴스입니다
예약 인스턴스는 최소 1년 이상 사용해야 합니다
약속된 기간이죠
예약 인스턴스에는 세 가지 종류가 있는데
첫 번째로는 단순한 예약 인스턴스로
데이터베이스 같은 장기 워크로드에 사용됩니다
그리고 전환형 예약 인스턴스가 있는데
시간이 지난 후 다른 종류의
인스턴스로 바꿀 수 있는 유연형 인스턴스죠

예약 인스턴스가 적합한 곳으로는  
애플리케이션이 안정된 상태로 사용되는, 즉 데이터베이스 등이 해당되죠  
3년간 데이터베이스를 사용해야 하는 상황이라면  
이런 인스턴스를 예약함으로써 비용을 크게 절감할 수 있을 겁니다  

간단 예시  
예약 인스턴스는 오랜 기간 호텔에 머무는 것으로  
미리 계획을 세웁니다  
할인도 괜찮게 받습니다  
한 달 정도 길게 머무는 손님이니까요  

### 정기 예약 인스턴스

그리고 정기 예약 인스턴스가 있습니다
예를 들어 일 년 내내는 아니지만 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)
일 년 동안 매주 목요일 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)
오후 3시부터 6시까지 서버가 필요한 경우죠 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)

### 스팟 인스턴스

온-디맨드 인스턴스에 비교하면 최대 90%까지 할인이 되죠  
여러분이 지불하고자 하는 가격이  
현재 스팟 인스턴스의 가격보다 낮다면  
`인스턴스가 언제든 중단될 수 있다는 겁니다`

저렴한 단기 워크로드 용 인스턴스지만  
손실 가능성이 있으며 신뢰성이 낮습니다  

그럼 어떤 유형의 워크로드가 적합할까요?  
단발성 데이터 분석인 배치 로드  
그리고 이미지 프로세싱 이미지 변환이 중단되어  
한 이미지 변환에 실패해도 나중에 다시 시작하면 되니까요  
그리고 분산된 워크로드가 있는경우

간단 예시  
아시다시피 일부 호텔은 밤에 객실이 빌 때  
아주 공격적인 할인을 선보입니다  
객실을 비워 두면 손해를 볼 것이고 사업이 망할 수도 있죠  
하지만 이 호텔은 조금 이상합니다  
만약 호텔이 여러분보다 객실비를  
더 많이 지불할 수 있는 손님을 찾게 되면  
여러분을 쫓아낼 수 있거든요  
이러면 이상한 호텔이긴 하겠지만 스팟 인스턴스가  
이런 경우와 비슷하답니다

### 전용 호스트

Amazon 전용 호스트는 EC2 인스턴스를 갖춘 유저 중심의 물리적 서버입니다  
즉, AWS 데이터 센터 내 하나의 서버 전체를 임대하는 거죠  
`전용 호스트를 사용하면 준수 요건의 처리가 쉽고`   
기존의 `서버 결합 소프트웨어 라이센스`의 사용이 가능하기 때문에  
비용을 절감할 수 있습니다  

전체 서버를 독자적으로 이용하게 되니 비용은 더 올라갑니다  
만약 복잡한 라이센스 모델의 소프트웨어를 사용하거나  
자가 라이센스를 가진 경우, 혹은 강력한 규제나 규정 준수 요건이  
있을 때도 상당히 도움을 주는 옵션이죠  

간단 예시  
이 경우 리조트 전체를 혼자서 예약합니다  
규정 준수 관련 이유로 이웃이 없어야 하거나  
서버 결합 라이센스를 가지고 있는 등의 이유 때문이죠  

### 전용 인스턴스

여러분의 전용 하드웨어에서 실행되는 EC2 인스턴스를 의미합니다  
같은 계정의 다른 인스턴스와 하드웨어를 공유하며  
인스턴스가 어떻게 배치될지에 대해서는 여러분이 간섭할 수 없습니다  
다시 말해, 전용 하드웨어가 있어도  
해당 하드웨어의 근본에는 접근할 수가 없습니다  
전용 호스트의 약한 버전이라고 할까요

# EBS 볼륨

EBS 볼륨은 일래스틱 블록 스토어의 줄임말입니다  
네트워크 USB 스틱이라고 생각하시면 됩니다  
USB 스틱처럼 한 컴퓨터에서 꺼내, 다른 컴퓨터에 꽂는  
그런 장치는 맞지만 실제 물리적 연결은 없으며  
네트워크를 통해 연결되는 거죠  

EBS 볼륨은 특정한 가용 영역에 고정되어 있으므로  
us-east-1a에 생성된 볼륨은  
us-east-1b로 연결이 불가능합니다

## 스냅샷

언제든 원하는 시점에 EBS 볼륨을 가지고 와서  
`백업이라고 불리기도 하는 스냅샷(Snapshot)`을 생성할 수 있습니다

스냅샷을 생성하는 이유는 무엇일까요? 복원 목적도 있으나  
가용 영역(AZ) 또는 리전(Region)에 걸친 스냅샷을 복사할 수 있기 때문입니다

더불어서 AWS의 다른 리전에 데이터를 전송하여 글로벌 인프라를 활용하는 것이죠  
또 다른 가용 영역에 새로운 EBS 볼륨을 복원할 수 있습니다

## AMI

AMI는 Amazon Machine Image의 약자로 사용자 지정 EC2 인스턴스를 나타냅니다  
각자의 소프트웨어 구성에 대해 운영 체제를 정의 및 설정하며 모니터링 도구를 설정할 수도 있는데  
이때 자체적으로 AMI를 생성하면 부팅과 구성에 시간이 단축됩니다

다른 사용자가 만들어서 판매하는 AMI로 자주 찾아볼 수 있습니다 AWS의 공급 업체가  
자체적으로 AMI나 구성이 훌륭한 소프트웨어를 생성하고  
여러분은 시간 절약을 위해 `마켓 플레이스 AMI에서 이들을 구매`할 수 있습니다

`AMI는 특정 AWS 지역용으로 구축되며 각 AWS 지역마다 고유`합니다.   
다른 AWS 지역의 AMI를 사용하여 EC2 인스턴스를 시작할 수는 없지만   
AMI를 대상 AWS 지역에 복사한 다음 이를 사용하여 EC2 인스턴스를 생성할 수 있습니다.

## 인스턴스 스토어

EC2 인스턴스는 가상 머신이지만 `실제로는 하드웨어 서버에 연결`되어 있습니다  
EC2 인스턴스 스토어는 I/O 성능 향상을 위해 활용할 수 있습니다  
이들이 훌륭한 처리량을 갖추고 있어서 매우 향상된 디스크 성능을  
요할 때에 활용할 수 있도록 확보할 필요가 있습니다

이때 주의할 점은 여러분이  
EC2 인스턴스, 즉 인스턴스 스토어를 중지 또는 종료하면  
해당 스토리지 또한 손실된다는 것입니다  
이 같은 이유로 이를 임시 스토리지라고 부르며  
EC2 인스턴스 스토어가  
`장기적으로 데이터를 보관할 만한 장소가 될 수 없음을 보여 줍니다`

그러면 언제 사용하는 것이 좋을까요?  
버퍼나 캐시 스크래치 데이터 또는 임시 콘텐츠를 사용하려는 경우  
이들을 보관할 좋은 장소가 되지만 장기적인 스토리지는 될 수 없습니다  
장기 스토리지의 경우에는 EBS 가 적합합니다

마지막으로 EC2 인스턴스의 기본 서버에 장애가 발생할 시에는  
해당 EC2 인스턴스가 연결된 하드웨어에도  
장애가 발생하므로 데이터 손실에 대한 위험이 존재합니다  
따라서 EC2 인스턴스 스토어를 사용할 때에는  
여러분의 필요에 따라 데이터를 백업해 두거나  
복제해 둬야 합니다

## EBS 볼륨

총 여섯 개의 유형이 있고
이들을 여러 범주로 나눌 수 있습니다

`gp2/gp3`가 있는데 이는 범용 SSD 볼륨으로
`다양한 워크로드에 대해 가격과 성능의 절충안이 되어 줍니다`

`io1과 io2`가 있습니다  
최고 성능을 자랑하는 SSD 볼륨으로  
`미션 크리티컬이자 지연 시간이 낮고 대용량의 워크로드`에 쓰입니다

`st1` 볼륨이 있는데 이는 저비용의 HDD 볼륨으로  
`잦은 접근과 처리량이 많은 워크로드`에 쓰이죠

`sc1` 볼륨은 가장 비용이 적게 드는 HDD 볼륨으로  
`접근 빈도가 낮은 워크로드`를 위해 설계되었습니다

EBS 볼륨은 어떻게 정의하는 걸까요?  
가령 크기, 처리량과 IOPS가 있죠  
`IOPS는 초당 I/O 작업 수`를 뜻합니다

EC2 인스턴스에는  
`gp2/gp3와 io1/io2만이 부팅 볼륨`으로 사용될 수 있습니다  

gp2 는 짧은 지연 시간을 자랑하며 효율적인 비용의 스토리지입니다  
시스템 부팅 볼륨에서 가상 데스크톱, 개발, 테스트 환경에서 사용할 수 있죠   
gp2는 좀 더 오래된 버전으로 볼륨이 더 작습니다 최대 3,000 IOPS에  
볼륨과 IOPS가 연결되어 있어서 IOPS가 증가할 때면  
즉 볼륨의 GB 수를 늘릴 때에 세 배 더 증가한 16,000 IOPS가 된다는 의미입니다

gp2와 gp3에는 차이가 있는데 gp3는 최신 세대의 볼륨으로  
기본 성능으로 3,000 IOPS와 초당 125MB의 처리량을 제공합니다  
각각 IOPS는 최대 16,000 처리량은 1,000MB/s까지 증가시킬 수 있습니다

gp2/gp3가 비용 효과적인 스토리지이며  
`gp3에서는 IOPS와 처리량을 독자적으로 설정`할 수 있는 반면  
`gp2에서는 그 둘이 연결되어 있다는 점`입니다

### IOPS

이는 IOPS 성능을 유지할 필요가 있는 주요 비즈니스 애플리케이션이나  
16,000 IOPS 이상을 요하는 애플리케이션에 적합합니다  
일반적으로 `데이터베이스 워크로드`에 알맞죠

### 스토리지

io1/io2에 중에서는 최신 세대를 고르는 것이 좋습니다 4에서 16TB에 달하며  
Nitro EC2 인스턴스에서는 최대 64,000 IOPS까지 가능합니다  
Nitro EC2 인스턴스의 경우 이를 통해 더 높은 IOPS까지 이용할 수 있습니다  
Nitro EC2 인스턴스가 아닌 경우에는  
최대 32,000 IOPS까지 지원됩니다  
또한 io1/io2를 이용하면 gp3 볼륨처럼 프로비저닝된 IOPS를  
스토리지 크기와 독자적으로 증가시킬 수 있습니다  
io2 이용 장점은 무엇일까요?
`io1과 동일한 비용으로 내구성과 기가 당 IOPS의 수가 더 높습니다`  
현재까지는 io2를 사용하는 것이 더 합리적인 거죠

### st1과 sc1

부팅 볼륨일 수 없습니다   
최대 16TB까지 확장

두 가지 종류의 볼륨을 제공합니다  
하나는 st1인 처리량 최적화 HDD로  
빅 데이터나 데이터 웨어하우징 로그 처리에 적합합니다

최대 처리량은 초당 500MB 그리고 최대 IOPS는 500에 달합니다  
다음으로는 sc1인 콜드 HDD가 있는데 이는 아카이브 데이터용으로  
접근 빈도가 낮은 데이터에 적합합니다  
최저 비용으로 데이터를 저장할 때에 사용하죠  
최대 처리량은 초당 250MB  
그리고 최대 IOPS도 250입니다

### EBS 다중 연결

앞서 EBS 볼륨은 단일한 EC2 인스턴스에만 연결할 수 있다고 했습니다  
EBS 다중 연결을 제외한 경우에 말이죠   
동일한 가용 영역 내의 여러 EC2 인스턴스에 연결하여 사용할 수 있습니다  
EBS는 `io1이나 io2 제품군일 때만 여러 EC2 인스턴스에 연결이 가능`합니다

## EFS 

Elastic File System 의 약자로  
다양한 가용 영역에 걸쳐 다수의 EC2 인스턴스에  
마운트 할 수 있는 관리형 NFS 혹은 네트워크 파일 시스템입니다  
즉 `다중 AZ에서 동작`하며   
이 점이 EFS와 EBS의 가장 큰 차이를 보여 줍니다  

EBS는 단일 가용 영역에 묶여 있는 반면  
`EFS는 다중 가용 영역에 걸쳐서 마운트가 가능`합니다

따라서 가용성이 매우 높죠   
확장성도 높으며 비용도 많이 듭니다

EBS는 한 번에 하나의 EC2 인스턴스에만 연결되어 있어서  
데이터가 다중의 EC2 인스턴스 간 공유되지 않지만

EFS 에서는 네트워크 파일 시스템으로  
`EFS 드라이브의 모든 EC2 인스턴스가 동일한 파일에 대한 접근 권한`을 갖습니다

EFS는 콘텐츠 관리, 웹 서비스  
데이터 공유 또는 WordPress 웹사이트에서 쓰입니다  
`표준 NFSv4.1 프로토콜`이 사용되며  
이는 네트워크 드라이브 마운트 시 기본적인 방법입니다  

EFS는 Windows가 아닌 `Linux 기반 AMI에서만 작동`합니다

EFS 옵션에 대해서는 어떤 사항을 알고 있어야 할까요? 먼저 그 규모를 알아야 합니다
EFS는 수천 명의 동시 클라이언트와  
초당 최대 10GB의 처리량을 자랑합니다   
성능이 아주 우수한 거죠  
또한 파일 시스템 자체가 페타바이트(PB) 정도까지  
확장될 수 있으므로 용량을 따로 관리할 필요가 없습니다  
자동으로 수행되죠

### 성능 모드

웹 서버 운영이나 지연 시간에 민감한 파일이 있는 경우  
범용 성능 모드를 사용합니다

EFS에서 대규모 데이터 워크로드를 처리하는 경우  
Max I/O 성능 모드가 적합합니다    
지연 시간은 더 길겠지만 처리량은 더 향상됩니다

### 처리량 모드
 
기본적으로는 버스팅(Bursting) 처리량 모드로 설정되어 있습니다
1TB의 스토리지에 대해  
초당 50MB를 저장할 수 있으며  
여기에 초당 100MB까지 확장이 가능하다는 겁니다  
일반적으로는 파일 시스템의 크기에 따라  
처리량이 증가하므로 EFS 파일 시스템의  
크지는 줄이면서 처리량을 높이기 위해서는  
프로비저닝 된 처리량 모드로 설정을 바꿀 수 있습니다  
이 모드에서는 스토리지 크기와 상관없이 처리량을 설정할 수 있죠  
1TB의 스토리지에 불과하더라도  
초당 1GB의 처리량을 요청할 수 있습니다

접근 빈도가 높은 파일에 대해 표준으로 설정되어 있으며  
EFS-IA라고 부르며 저비용의 빈도가 낮은 접근에 대한 티어가 있습니다  
이와 같은 파일을 저장할 저비용의 장소인 거죠

## EBS vs EFS

### EBS

EBS 볼륨은 한 번에 하나의 인스턴스에만 연결이 가능하고  
특정 가용 영역에 한정됩니다  

gp2에서는 디스크 크기가 늘어나면 IO도 함께 증가하죠  

io 1은 IO를 볼륨 크기와 관계 없이 독립적으로 증가시킬 수 있죠  
중요한 데이터베이스를 실행할 때 좋은 방법입니다

EBS를 다른 가용 영역으로 옮기고자 할 때는  
가장 먼저 스냅샷을 찍어야 합니다  
스냅샷을 찍었다면  
다른 AZ에서 그 스냅샷을 복원시키죠

EBS의 스냅샷이나 백업을 만들 때에는  
EBS 볼륨 내의 IO를 전부 사용하게 되니  
`인스턴스가 EBS를 사용 중이 아닐 때에만 실행`하셔야 합니다

EBS의 경우에는 실제 사용한 양이 아니라  
EBS 드라이브의 크기에 따라  
실제 사용량이 아니라 정해진 사용량을 지불하는 식이었죠

반면 EBS는 네트워크 볼륨을 한 번에 하나의 인스턴스에  
연결할 수 있고 특정 AZ 내로 한정이 되죠  
인스턴스 스토어는 EC2 인스턴스에 IO를 최대로 사용하게끔 해주지만,
`인스턴스가 망가지면 함께 망가지는`  
임시 드라이브인 거죠

### EFS

EFS는 여러 개의 가용 영역에 걸쳐  
`무수히 많은 인스턴스들에 연결`될 수 있습니다

이는 Linux 인스턴스에서만, 가능한데 POSIX 파일 시스템이라  
Windows에서 구동되지 않기 때문입니다

`EFS 는 EBS 보다 훨씬 비쌉니다`  
거의 세 배 정도 더 비싸죠

# ELB

## 고가용성과 확장성

### 확장성

확장성은 애플리케이션 시스템이  
`조정을 통해 더 많은 양을 처리`할 수 있다는 의미입니다  

우선 `수직 확장성`이 있고  
탄력성이라고 불리기도 하는 `수평 확장성`이 있습니다  

확장성과 고가용성은 서로 다른 개념입니다

먼저 수직 확장성입니다  
수직 확장성은 인스턴스의 크기(T2.small -> T2.lage) 처럼 `사양을 확장하는 것을 의미`합니다
그러면 이런 수직 확장성을 언제 사용하게 되는 걸까요?  
데이터베이스와 같이 분산되지 않은 시스템에서 흔히 사용됩니다   
하지만 일반적으로 확장할 수 있는 정도에는 한계가 있는데요  
하드웨어 제한이 걸려 있죠  

수평 확장성이란  
애플리케이션에서 `인스턴스나 시스템의 수`를 늘리는 방법입니다  
T2.small T2.small T2.small ...

`수평 확장은 인스턴스의 수를 늘린다는 뜻`인데  
AWS 용어로는 스케일 아웃과 스케일 인이라고 합니다  
인스턴스의 수가 `늘어나면 스케일 아웃`이고요  
`수를 줄이면 스케일 인`이죠  
다른 스케일링 그룹이나 로드 밸런서에도 사용합니다

고가용성은 `동일 애플리케이션의 동일 인스턴스를 다수의 AZ에 걸쳐 실행하는 경우`를 의미하죠   
다중 AZ가 활성화된 자동 스케일러 그룹이나 로드 밸런서에서도 사용됩니다  

## 로드 밸런싱

부하를 다수의 다운스트림 인스턴스로 분산하기 위해서죠  
다운스트림 인스턴스의 장애를 원활히 처리할 수 있죠  
로드 밸런서가 상태 확인 메커니즘으로  
어떤 인스턴스로 트래픽을 보낼 수 없는지 확인해 주거든요  

해당 인스턴스로는 트래픽을 보낼 수 없기 때문에  
로드 밸런서에겐 인스턴스의 상태가  
아주 중요하죠 그리고 상태 확인은  
포트와 라우트에서 이뤄집니다  

### Classic Load Balancers

이 로드 밸런서는 TCP나 트래픽 아니면 HTTP와 HTTPS를 지원합니다  
TCP는 4계층으로 HTTP/HTTPS는 7계층인데요

상태 확인은 TCP 또는 HTTP 기반으로 이루어집니다

### 애플리케이션 로드 밸런서

7계층, 즉 `HTTP 전용 로드 밸런서`로  
머신 간 다수 HTTP 애플리케이션의 라우팅에 사용이 되죠  
이러한 머신들은 대상 그룹이라는 그룹으로 묶이게 되는데요
동일 EC2 인스턴스 상의 여러 애플리케이션에 부하를 분산합니다  

컨테이너와 ECS를 사용하게 되죠  
HTTP/2와 WebSocket을 지원하며 리다이렉트도 지원하므로  
HTTP에서 HTTPS로 트래픽을 자동 리다이렉트하려는 경우  
로드 밸런서 레벨에서 가능하다는 의미가 되겠죠  

EC2 인스턴스가 대상 그룹이 될 수 있습니다

Application Load Balancer를 사용하여 EC2 인스턴스로 트래픽을   
분산할 때 요청을 수신하는 IP 주소는 ALB의 프라이빗 IP 주소가 됩니다.   
클라이언트의 IP 주소를 가져오기 위해 ALB는 클라이언트의 IP 주소를 포함하는  
X-Forwarded-For라는 추가 헤더를 추가합니다.

ALB는 URL 경로, 호스트 이름, HTTP 헤더 및 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다.

### 네트워크 로드 밸런서

layer 4(L4) 밸런서로  
TCP나 UDP 기반의 트래픽을  
인스턴스로 전달하는 것입니다  
낮은 계층의 밸런서죠  
초당 수백만 건의 요청을 처리할 수 있어 매우 고성능입니다  
ALB보다 지연 시간이 훨씬 짧습니다

밸런서 `애플리케이션의 평균 지연 시간은 400ms` 이고
반면에 `NLB의 지연 시간은 약 100ms` 입니다

NLB의 사용 사례를 살펴보면 고성능이나 TCP 또는 UDP 수준의  
트래픽을 원할 때 사용합니다

그렇다면 NLB는 무엇을 트래픽에 보낼까요?

여러 대상 그룹인데  
첫 번째는 EC2 인스턴스로  
대상 그룹에 EC2 인스턴스를 등록하면  
NLB에서 트래픽 전송 방법을 파악합니다  

두 번째는 IP 주소입니다  
고정 IP와 개인 IP를 지정해서  
NLB에서 직접 트래픽을 보내도록 합니다  
이유가 무엇일까요?  
약간 과하지만 EC2 인스턴스의 경우  
자체 데이터 센터에 서버가 있는 경우에는  
가급적이면 그대로 개인 IP가 있는 서버의 로드 밸런서를 사용합니다

세 번째 옵션은 ALB입니다  
`NLB와 ALB를 결합`하는 것이 가능하죠  
왜 결합할까요?  
NLB의 기능을 활용해서 고정 IP를 가질 수 있기 때문입니다  
따라서 NLB 수준의 고정 IP를 가지면서  
규칙과 같은 HTTP 관련 기능에  
ALB를 활용할 수 있는 것이죠  

Network Load Balancer에는 AZ당 하나의 static IP 주소가 있으며 
Elastic IP 주소를 연결할 수 있습니다. 
Application Load Balancer 및 Classic Load Balancer는 
static DNS 이름입니다.

### 게이트웨이 로드 밸런서

GWLB는 네트워크의 모든 트래픽이  
방화벽을 통과하게 하거나  
침입 탐지 및 방지 시스템에 사용합니다  
그래서 IDPS나 심층 패킷 분석 시스템 또는  
일부 페이로드를 수정할 수 있지만  
네트워크 수준에서 가능합니다

모든 로드 밸런서보다 낮은 수준에서 실행됩니다  
IP 패킷의 네트워크 계층인 L3입니다  
이제 GWLB는 2가지 기능을 갖게 됩니다

첫 번째는 투명 네트워크 게이트웨이입니다  
VCP의 모든 트래픽이 GWLB가 되는  
단일 엔트리와 출구를 통과하기 때문입니다  
그리고 대상 그룹의 가상 어플라이언스 집합에  
전반적으로 그 트래픽을 분산해 로드 밸런서가 됩니다  
이 부분이 GWLB에 관해 꼭 알아야 할 부분입니다  
마지막으로 시험 볼 때  
6081번 포트의 GENEVE 프로토콜을 사용하세요  
바로 GWLB가 됩니다

## Sticky Sessions

중요한 정보를 취하는  
세션 데이터를 잃지 않기 위해  
사용자가 동일한 백엔드 인스턴스에 연결됩니다  
고정성을 활성화하면  
백엔드 EC2 인스턴스 부하에 불균형을 초래할 수 있습니다  
일부 인스턴스는 고정 사용자를 갖게 됩니다  

### 애플리케이션 기반 쿠키

대상으로 생성된 사용자 정의 쿠키로  
애플리케이션에서 생성됩니다  
그리고 애플리케이션에 필요한 모든 사용자 정의 속성을 포함할 수 있죠  
쿠키 이름은 각 대상 그룹별로 개별적으로 지정해야 하는데  
이런 이름은 사용하면 안 됩니다  
AWSALB, AWSALBAPP 혹은 AWSALBTG 같은 이름이죠  
ELB에서 사용하기 때문입니다

애플리케이션 쿠키가 될 수도 있는데  
지금은 로드 밸런서 자체에서 생성됩니다  
그리고 ALB의 쿠키 이름은 AWSALBAPP입니다 

### 기간 기반 쿠키

로드 밸런서에서 생성되는 쿠키로  
ALB에서는 이름이 AWSALB이며 CLB에서는 AWSELB입니다  
특정 기간을 기반으로 만료되며 그 기간이 로드 밸런서 자체에서  
생성되는 것입니다  
애플리케이션 기반의 쿠키는  
애플리케이션에서 기간을 지정할 수 있습니다

## 교차 영역 로드 밸런싱

교차 영역 로드 밸런싱은 ALB에서 늘 활성화되어 있고
비활성화할 수 없습니다  
보통 데이터가 한 가용 영역에서 다른 가용 영역으로 이동하면  
비용을 지불해야 합니다  
하지만 활성화되어 비활성화할 수 없으니  
AZ 간 데이터 전송에 관한 비용이 없습니다  

네트워크 로드 밸런서에는 기본으로 비활성화되어 있어서  
교차 영역 로드 밸런싱 활성화에 비용을 지불해야 합니다  
가용 영역 간 데이터 전송에 비용을 지불해야 하는 것이죠

마지막으로 클래식 로드 밸런서에는  
교차 영역 로드 밸런싱이 기본으로 비활성화되어 있습니다  
활성화하면 가용 영역 간 데이터 전송에 비용이 발생하지 않습니다  
모든 로드 밸런서에서 사용할 수 있는 것이죠

`ALB에는 기본적으로 활성화`되어 있고  
`NLB에서 활성화하려면 비용`을 내야 합니다  
그리고 `CLB 에는 비용 없이 활성화`할 수 있습니다

## SSL

SSL 인증서를 사용하면 클라이언트와 로드 밸런서  
사이에서 전송 중에 있는 트래픽을 암호화할 수 있습니다  
인-플라이트 암호화라고 불리는 과정으로  
`즉 데이터가 네트워크를 통과하는 중에 암호화되고  
발신자와 수신자만이 이를 해독할 수 있는 거죠`  
SSL은 보안 소켓 계층을 뜻하며 연결을 암호화하는 데에 사용됩니다  
그리고 TLS는 SSL의 최신 버전으로써 전송 계층 보안을 의미하죠  
요즘에 주로 사용되는 건 TLC 인증서지만  
저를 포함한 많은 사람들은 이를 여전히 SSL이라고 부르고 있습니다  

공용 SSL 인증서는 Comodo, Symantec GoDaddy, GlobalSign  
Letsencrypt 등의 인증 기관에서 발급됩니다  
로드 밸런서와 연결된 공용 SSL 인증서를 사용하면  
클라이언트와 로드 밸런서 사이의 연결을 암호화할 수 있습니다

유저가 HTTPS를 통해 연결됩니다  
이때 S는 SSL 인증서를 사용하고 있다는 의미이며  
암호화되어 안전한 상태죠  
그리고 공용 인터넷을 통해 로드 밸런서와 연결되죠  
그리고 이때 로드 밸런서는 내부적으로  
SSL 인증서 종료라는 작업을 수행합니다  
그리고 백엔드에서는 EC2 인스턴스와 통신할 수 있는데, HTTP를 사용하기  
때문에 암호화는 되어 있지 않죠 하지만 트래픽은 어느 정도의 안전성을  
보장하는 사설 네트워크인 VPC를 통해 전송됩니다  
그럼 로드 밸런서가 X.509 인증서를 불러옵니다  
SSL 혹은 TLS 서버 인증서라고 불리는 인증서죠  
그리고 AWS에서 ACM을 사용해 SSL 인증서를 관리할 수 있습니다  
ACM은 AWS 인증서 관리자의 약자죠

SNI, 즉 서버 이름 표시  
CLB는 구형 버전으로 SNI를 지원하지 않는다는 점  
반면 ALB와 NLB는, SNI 및 다중 SSL 인증서를 지원하죠

## 등록 취소 지연

클래식 로드 밸런서를 사용할 경우에는 연결 드레이닝이라 부르고  
애플리케이션 밸런서나 네트워크 로드 밸런서를 사용하는 경우에는 등록 취소 지연 이라 부른다.

인스턴스가 등록 취소, 혹은 비정상인 상태에 있을 때  
인스턴스에 어느 정도의 시간을 주어  
인-플라이트 요청, 즉 활성 요청을 완료할 수 있도록 하는 기능이죠  
연결이 드레이닝되면 즉 인스턴스가 드레이닝되면  
ELB는 등록 취소 중인 EC2 인스턴스로  
새로운 요청을 보내지 않는 거죠

연결 드레이닝 파라미터는 매개변수로 표시할 수 있습니다  
1부터 3,600초 사이의 값으로 설정할 수 있는데  
`기본적으로는 300초, 즉 5분`입니다

## 오토스케일링 AGS

스케일 아웃이 있습니다  
부하가 증가하면 거기 맞춰서 EC2 인스턴스를 추가하는 거죠  
반면 스케일 인은 줄어든 부하에 맞춰 EC2 인스턴스를 제거하는 작업입니다  
그리고 오토 스케일링 그룹은 EC2 인스턴스가 일정량만큼만  
증가하거나 줄어들도록 만들 수도 있는데요  
그렇게 되면 ASG에서 실행되는  
머신의 최소 및 최대 숫자를 설정할 수 있습니다
마지막으로 ASG에는 굉장히 좋은 기능이 있는데요  
`로드 밸런서에 자동으로 새 인스턴스를 등록해 주는 기능입니다`

### 오토 스케일링 그룹의 스케일링 정책

먼저 동적 스케일링 정책부터 보겠습니다  
동적 스케일링 정책은 세 가지 유형이 있습니다  

첫 번째는 대상 추적 스케일링으로 가장 단순하고 설정하기도 쉽죠  
예를 들면 모든 EC2 인스턴스에서  
오토 스케일링 그룹의 평균 CPU 사용률을 추적하여  
이 수치가 40%대에 머무를 수 있도록 할 때에 사용합니다  
이처럼 기본 기준선을 세우고  
상시 가용이 가능하도록 하는 거죠  

단순과 단계 스케일링은 좀 더 복잡합니다  
CloudWatch 경보를 설정하고  
가령 다음과 같이  
전체 ASG에 대한 CPU 사용률이 70%를 초과하는 경우  
용량을 두 유닛 추가하도록 설정할 수 있죠  
그리고 전체 ASG 내의  
CPU 사용률이 30% 이하로 떨어지면 유닛 하나를 제거한다는  
설정도 추가할 수 있습니다

예약된 작업이 있습니다  
나와 있는 사용 패턴을 바탕으로 스케일링을 예상하는 거죠  
예를 들어서  
금요일 오후 5시에 큰 이벤트가 예정되어 있으니  
여러 사람들이 애플리케이션을 사용하는 데에 대비해  
여러분의 ASG 최소 용량을  
매주 금요일 오후 5시마다 자동으로 10까지 늘리도록 하는 겁니다  

제 생각에는 머신 러닝을 기반으로 하며  
손쉬운 ASG 오토 스케일링 중 하나인 예측 스케일링이 향후 더욱 대두될 겁니다
따라서 스케일링 기반이 될 훌륭한 지표가 있어야겠죠  
여러분의 애플리케이션의 목적과 작동 방식에 따라 달라지긴 하지만  
대표적인 것들을 살펴보겠습니다  
첫째로는 CPU 사용률을 들 수 있습니다  
일반적으로 인스턴스에 요청이 갈 때마다  
일종의 연산이 수행되어야 하므로  
이 과정에서 일부 CPU가 사용됩니다  
모든 인스턴스의 평균 CPU 사용률을 봤을 때  
이 수치가 올라가면  
인스턴스가 잘 사용되고 있다는 의미이니  
스케일링에 있어서 좋은 지표가 될 겁니다  
또 다른 지표를 보겠습니다  
애플리케이션에 따라 다를 수 있습니다만  
테스트를 기반으로 하는 대상별 요청의 수를 들 수 있습니다  
EC2 인스턴스는 한 번에 대상별로  
1,000개의 요청까지만 최적으로 작동하므로  
바로 이 대상을 스케일링에 활용할 수 있겠습니다  
예를 들어서 업로드와 다운로드가 많아  
EC2 인스턴스에 대해 해당 네트워크에서 병목 현상이 발생할 것으로 판단된다면  
평균 네트워크 입출력량을 기반으로 스케일링을 수행해서  
특정 임계값에 도달할 때  
스케일링을 수행하도록 설정할 수 있습니다  
또는 여러분이 직접 CloudWatch에서  
애플리케이션 별로 지표를 설정하고  
이를 기반으로 스케일링 정책을 바꿀 수 있습니다

스케일링 휴지(Scaling Cooldown)
인스턴스의 추가 또는 삭제를 막론하고  
기본적으로 5분 혹은 300초의 휴지 기간을 갖는 것입니다  
휴지 기간에는 ASG가 추가 인스턴스를 실행 또는 종료할 수 없습니다 

EC2 Health Checks(기본값) 대신 Application Load Balancer Health Checks을 기반으로 EC2 인스턴스의 상태를 확인하도록 ASG을 구성할 수 있습니다. EC2 인스턴스가 ALB Health Checks에 실패하면 비정상으로 표시되고 ASG가 새 EC2 인스턴스를 시작하는 동안 종료됩니다.

# RDS

`RDS는 관계형 데이터베이스 서비스`를 나타내며  
이는 SQL을 쿼리 언어로 사용하는  
데이터베이스를 위한 관리형 데이터베이스를 뜻합니다

EC2 인스턴스 상에 자체 데이터베이스 서비스를 배포하지 않고    
RDS를 사용하는 이유는 무엇일까요?
RDS는 관리형 서비스로  
AWS가 데이터베이스뿐만 아니라  
여러 기타 서비스 또한 제공하고 있습니다  
가령 해당 데이터베이스의 프로비저닝은 완전히 자동화되어 있고  
기본 운영 체제 패치 또한 자동으로 이루어집니다  
또한 지속적인 백업이 수행되며  
특정 타임스탬프도 복구할 수 있습니다  
이를 지정 시간 복구 PITR이라고 합니다

다중 AZ를 설정할 수 있고  
재해 복구 시 유용하게 이용하는  
다중 AZ에 대한 강의 섹션 또한 찾아보실 수 있습니다  
업그레이드를 위한 유지 보수도 존재하고  
인스턴스 유형을 늘려서  
읽기 전용 복제본을 추가함으로써 인스턴스 유형의  
수직 및 수평 확장성을 증가시킬 수도 있습니다  
끝으로 스토리지가 EBS를 기반으로 하는데  
gp2 볼륨 또는 io1을 뜻한다는 것은 전에 다룬 바 있어서 다들 알고 계시겠죠

단 RDS 인스턴스에는  
SSH를 따로 가질 수 없습니다
이는 `관리형 서비스로 AWS에서 제공되므로 기본 EC2 인스턴스에 대해서는  
사용자가 따로 접근 권한을 갖지 않기 때문`이죠

## 백업

백업은 RDS에서 자동으로 활성화되며 자동으로 생성됩니다  
정의해 놓은 유지 관리 기간 동안  
매일 수행되는 데이터베이스 전체에 대한 백업과  
트랜잭션 로그, 즉 일일 트랜잭션 로그가  
매 `5분 마다 RDS에 백업`되죠

자동 백업은 기본적으로는 7일간 보관되지만  
`최대 35일까지로 보관 기간을 설정`할 수 있습니다  
또한 데이터베이스 스냅샷이 있는데  
스냅샷은 백업과 약간 다릅니다  
스냅샷은 사용자가 수동으로 발동시키는 백업으로  
백업 보관 기간을  
사용자 임의로 설정할 수 있습니다

### 오토스케일링

RDS 데이터베이스를 생성할 때는 원하는 스토리지 용량을 지정해야 합니다  
스토리지를 20GB로 지정하는 것과 같이 말이죠  
단 데이터베이스 사용이 많고  
사용 가능한 공간이 부족해지는 경우  
바로 이 기능
`RDS 스토리지 오토 스케일링`이 활성화되어 있으면  
RDS가 자동으로 스토리지에 대한 스케일링을 수행하죠  
따라서 스토리지 확장을 위해  
데이터베이스를 중단하는 등의 작업을 따로 수행할 필요가 없습니다  
즉 애플리케이션이  
RDS 데이터에 다량의 읽기 및 쓰기 작업을 수행할 때에  
자동으로 특정한 임계값을 확인해서  
스토리지에 대한 오토 스케일링 작업이 수행되는 RDS 기능입니다

## RDS 다중 AZ (Multi AZ)

다중 AZ는 `주로 재해 복구에 사용`됩니다    
만약 RDS DB를 만들고, DB에 특정 레코드를 인서트 할 시, 다른 AZ(Availability Zone)에 똑같은 복제본이 만들어집니다.  
Multi AZ는 AWS 에 의해서 자동으로 관리가 이뤄집니다.  
직접 번거로운 과정을 거치지 않아도 되고, 유사시 우리가 현재 사용하고 있는 메인 DB에 문제가 생길 경우  
RDS 는 이를 즉시 발견하고 다른 AZ에 만들어진 복제본을 그대로 사용합니다.  
이를 Disaster Recovery 라고 부릅니다. Multi AZ는 복제본을 만든다고 해서 성능이 더 좋아지는 건 아니지만, 만약 성능개선이 주목적이라면,  
Read Replicas 를 사용해야 합니다.

만약 Amazon RDS Active에 어떤 문제가 생긴다면,  
RDS는 자동으로 Amazon RDS back-up으로 fail over를 합니다.   
뭔가 새로 만들거나, 헤비 워크가 필요 없기 때문에 재해가 생길 시, 재해복구 시간이 현저히 감소됩니다.

재해 복구를 대비해서 `읽기 전용 복제본을 다중 AZ로 설정할 수 있다.`    
원하는 경우에는 읽기 전용 복제본을 다중 AZ로도 설정할 수 있습니다

단일 AZ에서 다중 AZ로 RDS 데이터베이스 전환이 가능할지 물을 수 있습니다  
이 작업에는 다운타임이 전혀 없는 점을 염두에 둬야 합니다  
즉 단일 AZ에서 다중 AZ로  
전환할 때에 데이터베이스를 중지할 필요가 없는 겁니다

## 읽기 전용 복제본 (Read Replica)

읽기 전용 복제본은 이름에서 알 수 있듯 `읽기를 스케일`링합니다

- 생성과정
  1. 원본 스냅샷 생성
  2. 스냅샷을 통해 복제본 인스턴스 생성
  3. 변경사항 발생 시 비동기식 복제

Replication 이란 `백업과 성능 향상을 위해서 데이터베이스를 여러 대의 서버에 복제`하는 행위를 뜻합니다.   
원본 데이터가 위치하는 서버를 마스터라고 하고, 그 원본을 복제한 서버를 슬레이브라고 합니다.  
마스터와 슬레이브를 `구분할 때는 읽기와 쓰기`를 이용합니다.  
데이터베이스의 작업은 읽기와 쓰기로 구분할 수 있습니다.  
SQL 로 말하면 읽기는 SELECT 구문이고, 쓰기는 INSERT, UPDATE, DELETE입니다.   
그런데 쓰기 작업은 저장된 데이터가 변경되기 때문에 복제된 서버들 간에 동일한 형태를 유지하는 것이 어렵습니다.  
그래서 보통 한대의 서버에만 쓰기 작업을 하고, `그 서버의 데이터를 복제해서 여러 대의 슬레이브 서버를 만든 후에 슬레이브에서는 읽기 작업만을 수행`합니다.   
read replica란 바로 이런 작업을 RDS에서 할 수 있도록 해주는 서비스입니다.

즉, Read Replica 는 RDS DB 인스턴스의 읽기 전용 인스턴스입니다.   
`서비스에서 읽기 위주의 작업이 많은 경우 Read Replica 를 여러 개 만들어서 부하를 분산`할 수 있습니다.   
즉, 쓰기 작업은 마스터 DB 인스턴스에 하고 읽기 작업은 Read Replica 에 할당하면 마스터 DB 인스턴스의 부하를 줄일 수 있습니다.   
만약 마스터 DB 인스턴스에 쓰기를 하면 자동으로 Read Replica DB 인스턴스로 데이터가 복제됩니다.   
단, 즉시 복제되는 것은 아니며 약간의 시간차가 있습니다.

Read Replica 는 성능 극대화를 위해 존재하기에, `Read heavy work 가 많을 시 Read Replica 를 사용`해야 합니다.   
만약 트래픽이 많아진다면, 서버 다운이 일어날 수 있는데, 이를 방지하기 위해 Read Replicas를 사용한다고 이해하면 좋습니다.   
앞서 배운 Multi AZ 와는 달리 이 기능은 Disaster Recovery 용도가 아닙니다.  
Read Replica 는 하나의 RDS DB에 대해 최대 5개까지 생성 가능합니다.  
또한 Read Replica 의 Read Replica 를 생성할 수 있습니다.  
하지만 생성 혹은 사용 시 약간의 latency 가 존재할 수 있습니다.  
그리고 마지막으로 Read Replica 는 고유의 앤드포인트가 존재합니다.   
RDS DB는 앤드포인트로 정체를 가려낼 수 있습니다.

RDS 읽기 전용 복제본과 관련된 네트워킹 비용을 한번 살펴보겠습니다  
AWS에서는 하나의 가용 영역에서 다른 가용 영역으로  
데이터가 이동할 때에 비용이 발생합니다  
하지만 예외가 존재하며 이 예외는 보통 관리형 서비스에서 나타납니다  
RDS 읽기 전용 복제본은 관리형 서비스입니다  
읽기 전용 복제본이 다른 AZ 상이지만  
`동일한 리전 내에 있을 때는 비용이 발생하지 않습니다`

하지만 서로 다른 리전에 복제본이 존재하는 경우  
즉 us-east-1에 대해서  
복제본이 eu-west-1에 존재하는 경우에는  
RDS DB 인스턴스와 읽기 전용 복제본이  
`여러 리전을 넘나들어야 하기 때문에 네트워크에 대한 복제 비용이 발생합니다`

## 암호화

먼저, 사용하지 않는 데이터인 미사용 데이터 암호화는  
AES 256비트 암호화를 사용하는  
AWS의 키 매니지먼트 서비스인 AWS KMS로  
마스터 데이터베이스와 읽기 전용 복제본을 암호화할 수 있습니다  
따라서 암호화 실행 시 실행 시간을 정의해야 하며  
마스터 데이터베이스를 암호화하지 않으면  
복제본도 암호화할 수 없습니다

또, 늘 SSL 인증서가 필요한 전송 중 암호화도 있고  
이는 데이터 전송 중에 RDS로 암호화를 사용하는데  
클라이언트에서 데이터베이스로 전송 중인 것을 말합니다

모든 클라이언트가 SSL을 사용하도록 하려면

PostgreSQL 에서는  
rds.force_ssl=I인 콘솔 매개변수 그룹을 설정해야 하며 꽤 명시적입니다

MySQL 사용 시  
GRANT USAGE ON *.* TO 'mysqluser'@%'REQUIRE SSL이라는  
명령문을 데이터베이스 내부에서 실행해야 합니다  
이 또한 꽤 명시적이죠

RDS 백업을 암호화하는 방법입니다  
여기서 알아야 할 것은  
암호화 되지 않은 RDS 데이터베이스에서 스냅샷을 생성하면  
`스냅샷 자체는 암호화되지 않는 것`입니다  
마찬가지로 암호화된 RDS 데이터베이스에서 스냅샷을 생성하면  
모든 스냅샷이 기본으로 암호화되는데 이는 항상 기본 값은 아닙니다  
그래서 암호화되지 않은 스냅샷을  
암호화된 스냅샷으로 복제해야 합니다  
암호화되지 않은 RDS 데이터베이스의 스냅샷을 생성해 복제한 뒤  
이 스냅샷의 암호화된 버전을 쉽게 만들 수 있는 것이죠

다음은 암호화되지 않은 RDS 데이터베이스의 암호화 방법입니다  
지금까지 배운 것으로  
암호화 되지 않은 RDS 데이터베이스의  
스냅샷을 생성해야 하고 이는 암호화되지 않습니다
그리고 스냅샷을 복제하고  
`복제한 스냅샷의 암호화를 활성화`합니다  
이제 복제된 암호화 스냅샷이 생겼습니다  
이 암호화된 스냅샷으로  
암호화된 스냅샷에서 데이터베이스를 복원할 수 있으며  
이는 암호화된 RDS 데이터베이스를 제공합니다  
이제 모든 애플리케이션을 이전의 암호화되지 않은  
RDS 데이터베이스에서 새 암호화된 RDS 데이터베이스로 옮기고  
이전 데이터 베이스를 삭제합니다

정리하자면  
미사용 데이터 암호화는  
데이터베이스 인스턴스를 처음 생성할 때만 실행되며  
암호화되지 않았으면 스냅샷을 생성해야 합니다  
그리고 스냅샷을 복제해 암호화 한 다음에  
암호화된 스냅샷에서 새 데이터베이스를 생성하면  
데이터베이스를 암호화하죠

## 인증

이제 IAM 인증을 사용한 RDS 연결법을 살펴보겠습니다  
말씀드린 대로 `MySQL과 PostgreSQL에서만 실행`되며  
암호는 필요하지 않고  
`인증 토큰`이라는 것이 필요한데   
RDS API 호출을 사용해서 IAM으로 직접 얻을 수 있습니다

## Amazon 오로라(Aurora)

오로라는 AWS의 사유 기술입니다  
오픈 소스가 아니죠  
하지만 Postgres와 MySQL과 호환됩니다

오로라에서는 장애 조치도 즉각적입니다  
MySQL RDS의 다중 AZ에서 장애 조치보다 속도가 훨씬 빠르죠  
기본적으로 클라우드 네이티브라서 가용성이 높기 때문입니다  
RDS보다 비용이 20% 정도 비싸지만  
규모 면에서 더 효율적이어서  
비용을 많이 절약할 수 있습니다

오로라가 특별한 이유는 3개 AZ에 걸쳐 기록하는 것은 무엇이든  
6개의 데이터 복제본을 저장하기 때문입니다  
6개의 복제본을 저장할 수 있는데  
쓰기에는 6개 중 4개만 필요합니다  
이는 한 개의 AZ가 다운돼도 괜찮다는 것을 말하며  
읽기에는 6개 중 3개만 필요하다는 의미입니다  
읽기에 아주 적합한 것이죠  
또한, 정말 훌륭한 자가 복구 과정이 있는데  
일부 데이터가 손상되거나 잘못된 경우  
백엔드에서 P2P 복제로  
자가 복구를 하는 것입니다  
하나가 아니라 수백 개의 볼륨에  
의지할 수 있는 것입니다

또, 읽기 전용 복제본에 오토 스케일링을 적용할 수 있습니다  
그래서 `최대 15개의 읽기 전용 복제본에 일정 수의 읽기 전용 복제본을 `
오토 스케일링을 통해 설정할 수 있습니다  
오토 스케일링으로 애플리케이션이 읽기 전용 복제본과 URL을  
추적하는 것이 어려워지고 연결하기도 어려워집니다  
이를 해결하는 방법이 시험에 자주 출제됩니다

`리더 엔드 포인트(Reader Endpoint)`라는 것은  
라이터 엔드 포인트와 동일한 기능이 있는데  
로드 밸런싱의 연결을 돕고  
`모든 읽기 전용 복제본에 자동으로 연결`합니다  
클라이언트가 리더 엔드 포인트에 연결할 때마다  
읽기 전용 복제본 중 하나가 연결돼  
이런 식으로 로드 밸런싱 됩니다  
한 가지 알아야 할 것은 로드 밸런싱은  
명령문 수준이 아니라 연결의 수준에서 발생합니다

## Amazon 일래스틱 캐시

캐시란 무엇일까요? 캐시는 높은 성능과  
`낮은 지연 시간을 가진 인 메모리 데이터베이스`입니다  
그리고 일래스틱 캐시를 사용하면  
읽기 집약적인 워크로드의 부하를 줄이는데 도움이 됩니다

일반적인 데이터베이스(RDBMS)는 디스크(HDD,SSD)에 데이터를 영구적으로 저장해 놓고, 필요한 데이터만 메모리에 읽어서 사용합니다.  
인 메모리 캐시는 `디스크에 접근하지 않고 메모리로만 모든 처리를 하기 떄문에 데이터 저장 및 검색 속도가 매우 빠릅니다.`   
단 데이터는 딱 메모리 크기까지만 저장할 수 있습니다.  
또한, 메모리에만 저장되어 있기 때문에 `서버의 전원 공급이 중단되면 데이터는 소멸`됩니다.

일래스틱 캐시와 RDS 데이터베이스 그리고 애플리케이션이 있고  
애플리케이션은 일래스틱 캐시를 쿼리합니다  
쿼리가 이미 생성됐는지  
이미 생성되어 일래스틱 캐시에 저장됐는지 확인하는 것은  
`캐시 히트(cache hit)`고  
이는 일래스틱 캐시에서 바로 응답을 얻어서  
쿼리하기 위해 데이터베이스로 이동하는 동선을 줄여줍니다

`캐시 미스(cache miss)`의 경우에는 데이터베이스에서 데이터를 가져와서  
데이터베이스에서 읽습니다  
동일한 쿼리가 발생하는 다른 애플리케이션이나 인스턴스에서는  
데이터를 캐시에 다시 기록하여  
다음에는 `같은 쿼리로 캐시 히트를 얻도록 합니다`  
이는 RDS 데이터베이스에서 부하를 줄이는데 도움을 주는데  
데이터를 캐시에 저장하기 때문에  
캐시 무효화 전략이 있어야 하며  
가장 최근 데이터만 사용하는지 확인해야 합니다  
이것이 캐싱 기술 사용과 연관된 어려움이라고 할 수 있죠

`레디스(Redis)`는 자동 장애 조치로 다중 AZ를 수행하는 기술이며  
읽기 전용 복제본은 읽기 스케일링에 사용되며 가용성이 높습니다  
약간 RDS와 비슷합니다  
그리고 지속성으로 인해 데이터 내구성도 있으며  
백업과 기능 복원 기능도 있습니다  
RDS와 많이 유사합니다

`멤캐시트(Memcached)`는 `데이터 분할에 다중 노드를 사용하고 이를 샤딩(sharding)` 이라고 합니다    
가용성이 높지 않고 복제도 발생하지 않습니다   
`지속적인 캐시가 아닙니다`  
백업과 복원 기능도 없죠  
그리고 다중 스레드 아키텍처로  
몇몇 샤딩과 함께 캐시에서 함께 실행되는  
여러 인스턴스가 있습니다  
여기서 기억해야 할 것은
`레디스는 고가용성과 백업읽기 전용 복제본 등이 있고`

`멤캐시트는 데이터를 손실할 수 없는 단순한 분산 캐시`입니다  
`가용성이 높지 않고 백업과 복원 기능도 없습니다`  
바로 이것이 두 기술의 가장 큰 차이점입니다

### Memcached 를 선택

`상대적으로 작고 정적인 데이터를 캐싱`하는 경우  
여러 코어 또는 스레드가 있는 멀티 스레드의 경우  
메모리 관리가 redis 만큼 정교하지는 않지만, `메타 데이터에 대한 메모리 리소스를 비교적 적게 소비하여 간단한 사용에 적합`하다.  
쉽게 확장할 수 있지만 해싱 사용 여부에 따라 캐시된 데이터의 일부 또는 전부를 잃는다.

### Redis 를 선택

문자열, 해시, 목록, 세트, 정렬된 세트 및 비트맵과 같은 `복잡한 데이터 유형이 필요한 경우`  
인 메모리 데이터 세트를 정렬하거나 순위를 지정해야 하는 경우  
키 저장소의 속성을 원할 경우  
읽기 집약적 애플리케이션을 위해 기본 항목에서 하나 이상의 읽기 전용 복제본으로 데이터를 복제해야 하는 경우  
`기본 노드가 실패할 때 자동 장애 조치가 필요한 경우`  
서버에 대한 `이벤트를 클라이언트에 알리기 위해 게시 및 구독(게시/구독) 기능이 필요한 경우`   
`백업 및 복원 기능이 필요한 경우`  
`여러 데이터베이스를 지원`해야 하는 경우

## 일래스틱캐시 (ElastiCashe) 전략

어떤 캐싱 설계 패턴이 가장 적합한가? 입니다

### 레이지 로딩(Lazy Loading)

시험에서는 캐시 어사이드(Cache-Aside)나  
레이지 포퓰레이션(Lazy Population) 라고도 합니다  
모두 같은 것을 의미합니다

### 라이트 스루(Write Through)

라이트 스루는 `데이터베이스가 업데이트될 때 캐시를 추가하거나 업데이트하는 것을 의미`합니다    
살펴보죠 아까와 같이 애플리케이션, 일래스틱 캐시, RDS가 있습니다  
애플리케이션이 일래스틱 캐시와 통신할 때  
캐시 히트가 발생하면 좋죠  
그리고 RDS에서 쓰기를 할 때  
즉, 애플리케이션이 아마존 RDS 데이터베이스를 수정할 때  
먼저 캐시에 쓸 것입니다  
라이트 스루라고 부르는 이유는  
일래스틱 캐시를 통해 RDS에 쓰기 때문입니다  
이 구조에서 무엇을 얻을 수 있을까요?  
캐시 데이터는 절대 오래될 수 없습니다  
아마존 RDS가 바뀔 때마다  
캐시도 자동으로 바뀌게 됩니다

### 캐시 제거와 타임 투 리브(TTL)

즉, 캐시에 제한된 크기가 있습니다  
따라서 캐시 데이터를 제거하기 위해 Cache Eviction이란 방법을 사용합니다  
`예를 들어 항목을 캐시에서 명시적으로 삭제`하거나  
캐시 메모리가 꽉 찼을 때 사용합니다  
그러면 가장 최근에 사용되지 않은 항목이 제거됩니다  
이를 LRU 또는 최근 최소사용이라고 하거나  
항목을 타임 투 리브(TTL)로 설정할 수 있습니다  
예를 들어 이 항목은 5분 동안만 사용 가능하니  
5분이 되면 캐시에서 삭제될 것이라는 뜻입니다  
TTL은 리더보드, 코멘트, 활동 스트림 등등  
어떤 종류의 데이터에도 유용합니다

## Redis 클러스터 모드

레디스에서 할 수 있는 일래스틱 캐시 복제 방식은 2개이며 둘 다 알아야 합니다

### 클러스터 모드 비활성화입니다

샤드란  
샤드(shard)란 샤딩을 통해 나누어진 블록들의 구간(혹은 Epoch)을 말한다.   
샤드는 지분증명과 관련이 있는 것이 아니라 확장성 개선과 관련된 개념이다.   
샤딩(sharding)의 아이디어는 가능한 계정(계약도 계정)의 공간을 숫자 주소의 첫 번째 숫자를 기준으로 하위 공간으로 분할하는 것이다.   
샤드에 포함된 정보는 여전히 다른 노드와 공유할 수 있으며,   
모든 사람이 여전히 모든 원장 항목을 볼 수 있기 때문에 원장을 분산하고 안전하게 유지할 수 있다.   
그들은 단지 모든 정보를 처리하고 저장하지 않는다.

이 경우, 기본 노드는 1개이며  
`5개까지 노드를 복제`할 수 있습니다
레디스에는 샤드가 1개 있으며  
`모든 데이터가 이 샤드`에 있습니다  
기본 캐시 노드는 1개입니다  
선택적으로 `5개까지 캐시를 복제`할 수 있습니다  
즉, `노드의 복제본은 0개에서 5개`까지 가질 수 있습니다  
기본 노드와 복제본이 있을 때  
기본 노드에 실패가 발생하면  
복제본이 대신합니다  
`복제본은 캐시 간에 비동기적`이며  
기본 노드는 읽기와 쓰기에 사용됩니다  
다른 노드는 읽기 전용이죠  
장애 복구 외에도  
읽기 복제본을 활성화함으로써  
레디스용 일래스틱 캐시에서 읽기 성능을 올릴 수 있습니다  
즉, 샤드 1개가 있고  
모든 노드가 레디스 클러스에 있는 데이터를 갖게 될 것입니다  
이를 통해 노드 실패가 발생할 때 데이터의 손실을 대비합니다  
다중 AZ를 활성화할 수도 있습니다 다중 AZ 장애 조치를 위해  
기본값으로 활성화되어 있습니다  
다시 한번, 이것은 다중 AZ에 유용합니다  
또한 일래스틱 캐시 클러스터의  
읽기 성능을 올릴 때도 사용합니다

### 클러스터 모드 활성화

이 모드에서는 `데이터가 여러 샤드로 분할`되며  
`쓰기를 확장할 때 유용`합니다  
예시로 살펴보겠습니다 여기 샤드 1  
샤드 2, 샤드 3, 샤드 N이 있습니다  
기본 아이디어는 데이터의 일부분이  
샤드 1에,  
일부분은 샤드 2에, 이런 식으로 샤드 N까지 분할됩니다  
즉, 데이터는 모든 샤드에 걸쳐 분할됩니다  
각 샤드는 이전에 본 클러스터 모드 비활성화처럼  
똑같이 동작합니다  
즉, 기본 노드 1개가 있고  
노드의 복제본은 5개까지 있습니다  
데이터가 복제되고 모든 샤드에서  
복제본 수를 동일하게 설정합니다  
다중 AZ도 가능합니다 기본값으로 활성화되어 있습니다  
기본 노드와 복제본 사이에서  
장애가 발생했을 때 장애 조치가 가능합니다  
클러스터 당 최대 500개의 노드를 가질 수 있습니다  
즉 복제본을 만들지 않는다면  
단일 마스터에 500개의 샤드를 갖는다는 뜻입니다  
복제본을 설정하면  
예를 들어, 마스터 1개와 복제본 1개를 원한다면  
250개의 샤드를 갖습니다  
마스터 1개에 5개의 복제본을 원하면  
최대 83개의 샤드를 가질 수 있습니다  
클러스터 모드를 활성화하는 경우  
데이터 샤딩에 정말로 관심 있는 것입니다  
`즉, 쓰기를 확장하기 원하고 데이터는 분할될 것입니다`    
데이터가 여러 샤드에 걸쳐 분할되겠죠  
이것이 일래스틱 캐시에서 클러스터 모드 활성화와  
클러스터 모드 비활성화의 차이점입니다

# DNS

DNS은 `Domain Name System` 으로  
`사람에게 친숙한 호스트 이름을 대상 서버 IP 주소로 번역해` 줍니다  
예를 들어, 웹 브라우저에  
www.google.com을 입력하면  
IP 주소를 주고 웹 브라우저가 이면에서 여기에 접근하여  
구글로부터 데이터를 얻습니다

http://api.www.example.com.이 있습니다  
마지막 .을 루트라고 합니다  
전체 도메인 이름의 루트죠  
그리고 있는 .com 은 TLD 입니다  
바로 최상위 도메인입니다  
example.com 이 2단계 도메인이고  
www.example.com 이 서브 도메인입니다  
api.www.example.com 이 도메인 이름입니다
HTTP 부분은 사용하기를 원하는 프로토콜입니다  
전체를 `FQDN` 이라고 하는데  
전체 주소 도메인 이름의 약자입니다

## Route 53

고가용성, 확장성을 갖춘, 완전히 관리되며 권한있는 DNS입니다  
마지막으로 왜 Route 53이라고 할까요?    
53은 DNS 서비스, 즉, 이름에서 사용되는 `전통적인 DNS 포트`입니다

타임 투 리브(TTL) 은 DNS 리졸버(resolver)에서 레코드가 캐싱 되는 시간입니다  
Route 53 에서 지원하는 DNS 레코드 종류는 많은데 반드시 알아야 하는 것은 A, AAAA, CNAME, 그리고 NS

### A 레코드

호스트 이름과 `IPv4 IP를 매핑`하죠
예를 들어 example.com은 1.2.3.4로 바로 연결됩니다

### AAAA 레코드

AAAA은 A와 비슷한 아이디어입니다  
이번에는 호스트 이름을 `IPv6 주소에 매핑`합니다  

### CNAME 레코드

CNAME은 호스트 이름을 `다른 호스트 이름과 매핑`합니다  
물론 대상 호스트 이름은 A나 AAAA 레코드가 될 수 있죠  
Route 53에서 DNS 이름 공간 또는 Zone Apex의  
상위 노드에 대한 CNAMES를 생성할 수 없습니다  
예를 들어 example.com 에 CNAME 을 만들 수는 없지만  
www.example.com에 대한 CNAME 레코드는 만들 수 있습니다

### NS 레코드

NS 레코드는 네임 서버 레코드로 도메인에 대한 네임서버의 권한을 가지고 있는지 알려주는 레코드이다.  
쉽게 말해, 내가 example.kr 이라는 도메인을 aws 업체에서 구입해서 사용하고 있다고 하면,  
example.kr 도메인을 관리하는 네임 서버는 당연히 aws 의 ns2.aws.co.kr 가 되게 된다.  
즉 NS 레코드는 어떤 도메인에 대한 처리를 다른 도메인 네임 서버에게 위임하는 기능을 가진 레코드이다.  

### 호스팅 존

도메인과 서브도메인으로 가는 트래픽의 라우팅 방식을 정의합니다  
호스팅 존에 두 종류가 있는데  
퍼블릭 호스팅 존과 프라이빗 호스팅 존이 있습니다  

- Public Hosted Zones 
  - 특정 도메인(예: example.com)과 그 하위 도메인(acme.example.com, zenith.example.com)의 트래픽을 인터넷에서 라우팅하는 방식에 대한 정보를 담고 있는 컨테이너이다.
  - Route 53에 도메인을 등록하면 호스팅 영역이 자동으로 생성된다.
  - 기존 도메인에 대한 DNS 서비스를 Route 53로 전송하는 경우 도메인에 대한 호스팅 영역 생성부터 시작한다.
- Private Hosted Zones
  - Amazon VPC 서비스로 생성한 하나 이상의 VPC 내에 있는 도메인과 그 하위 도메인에 대하여 Amazon Route 53의 DNS 쿼리 응답 정보가 담긴 컨테이너이다.
  - 회사 내부에서만 접근할 수 있는 비공개 URL 이 필요로 할 때 사용한다.
  - 비공개 URL 이기 때문에 private DNS 레코드가 존재한다.

## 레코드 TTL(Time To Live)

예시에서 클라이언트가 DNS route 53와 웹 서버에 접속한다고 해봅시다  
myapp.example.com 에서 DNS 요청을 보내면  
DNS로부터 회신을 받는데요  
회신 내용으로는 A 레코드와 IP 주소  
그리고 TTL이 있으며 TTL은 300초 정도 된다고 합시다  
TTL은 클라이언트에게 이 결과를 캐시하도록 요청합니다  
300초의 TTL 동안 말이죠    
300초 동안 클라이언트는 결과를 캐시합니다  
이 말인즉슨, 
`클라이언트가 재요청을 보내거나 같은 호스트 이름으로 접속할 경우  
클라이언트는 DNS 시스템에게 쿼리를 보내지 않아도 된다는 의미죠`  
이미 답변을 캐시에 저장했기 때문에 답을 알고 있으니까요  
하지만 캐시에도 시간이 소요되니 캐시 TTL이 발생합니다  
DNS 요청 쿼리를 계속해서 자주 보내는 상황을 원치 않는 겁니다  
레코드는 그렇게 자주 바뀌지 않거든요  
이미 저장된 답변을 이용함으로써  
웹 서버에 접속이 가능하며 HTTP 요청 및 회신을 보낼 수 있겠죠  
두 가지의 극단적인 경우를 봅시다  
예를 들어 TTL을 24시간으로 높게 설정한다면  
Route 53의 트래픽은 현저히 적겠죠  
결과가 24시간 동안 캐시될 테니  
클라이언트는 요청을 적게 보낼 겁니다  
하지만 클라이언트가 오래된 레코드를 받을 가능성도 있죠  
따라서 만약 레코드를 바꾸고자 한다면  
모든 클라이언트들이 새 레코드를 캐시에 저장할 때까지  
24시간을 기다려야 한다는 뜻입니다  
반대로 TTL을 60초 정도로 짧게 설정한다면  
DNS에는 트래픽의 양이 많아져서  
비용이 많이 들게 됩니다  
Route 53에 들어오는 요청의 양에 따라 요금이 책정되거든요
하지만 오래된 레코드의 보관 시간은 짧아지겠죠  
따라서 레코드 변경이 빨라집니다  
레코드 변경 전반이 더욱 편리하죠  
어떤 TTL 설정이 더 적합할지는 상황에 따라 달라집니다  
레코드를 변경하려는 경우
예를 들어 TTL을 24시간으로 늦춘 다음  
모든 클라이언트가 느린 새 TTL을 가지고 있다는 점을   
확인한 후, 레코드 값을 바꿔서 모두에게 업데이트가 되면 TTL을 올리는 식이죠  
그런 전략을 사용합니다  
TTL은 모든 레코드에 있어 필수적인데요  
다음 강의에서 다룰 별칭 레코드는 제외됩니다

## CNAME 과 별칭의 차이

CNAME 은 `호스트 이름이 다른 호스트 이름으로 향하도록` 할 수 있습니다  
예를 들어 app.mydomain.com이   
blabla.anything.com으로 향하는 식이죠  
`이건 루트 도메인 이름이 아닌 경우에만 가능`해서  
mydomain.com 앞에 뭔가 붙어야 하죠

반면 별칭 레코드도 있습니다  
이건 Route 53에 한정되지만  
`호스트 이름이 특정 AWS 리소스로 향하도록` 할 수 있습니다
가령 app.mydomain.com이  
blabla.amazonaws.com를 향할 수 있는 거죠  
`별칭 레코드는 루트 및 비루트 도메인 모두에 작동`합니다  
mydomain.com을 별칭으로 사용해  
AWS 리소스로 향하도록 할 수 있기 때문에, 아주 유용하죠  
그 외에도 `별칭의 장점으로는 무료`이고    
자체적으로 상태 확인이 가능하다는 점이 있습니다

AWS 리소스를 위한 `별칭 레코드의 타입은 항상 A 또는 AAAA` 인데  
리소스는 IPv4나 IPv6 중 하나죠  
`별칭 레코드를 사용하면 TTL을 설정할 수 없습니다`  
Route 53에 의해 `자동으로 설정`이 되죠

일라스틱 로드 밸런서(Elastic Load Balancer)가 될 수도 있고  
CloudFront 배포도 가능해요  
ELB 와 CloudFront 배포 API Gateway  
일래스틱 빈스톡 환경, S3 웹사이트도 가능하고요  
`S3 버킷은 안 되고` 
버킷들이 웹사이트로 활성화될 시 S3 웹사이트는 가능하죠  
VPC 인터페이스 엔드포인트 Global Accelerator 가속기  
동일 호스트 존의 Route 53이 대상으로 가능합니다  

`EC2의 DNS 이름에 대해서는 별칭 레코드를 설정할 수 없습니다`

## 라우팅 정책

라우팅 정책은 Route 53가 DNS 쿼리에 응답하는 것을 돕습니다  
여기서 라우팅이라는 단어를 혼동하셔서는 안 됩니다  
로드 밸런서가 트래픽을  
백엔드 EC2 인스턴스로 라우팅하는 것과는 다른 상황이죠  
여기서의 라우팅은 DNS 관점입니다  
`DNS는 트래픽을 라우팅하지 않죠` 
트래픽은 DNS를 통과하지 않아요  
DNS는 DNS 쿼리에만 응답하게 되고  
클라이언트들은 이를 통해 HTTP 쿼리 등을  
어떻게 처리해야 하는지를 알 수 있게 되는 거죠  
`DNS는 호스트 이름들을 클라이언트가 실제 사용 가능한 엔드 포인트로 변환하는 것을 돕죠`

### 단순 라우팅 정책

`일반적으로 트래픽을 단일 리소스로 보내는 방식`입니다  
예를 들어 클라이언트가  
foo.example.com 으로 가고자 한다고 하면  
Route 53이 IP 주소를 알려주는 거죠  
이는 A 레코드 주소입니다  
동일한 레코드에 여러 개의 값을 지정하는 것도 가능한데요  
이렇게 `DNS에 의해 다중 값의 받은 경우에는 클라이언트 쪽에서 그 중 하나를 무작위`로 고르게 됩니다  
이 예시의 경우에는 클라이언트가 foo.example.com로   
가기를 요청하고, Route 53은 세 개의 IP 주소로 답합니다  
A 레코드에 임베딩된 주소들이죠

### 가중치 기반 라우팅 정책

EC2 인스턴스가 세 개 있는데  
70, 20, 그리고 10의 각각 다른 가중치를 할당받아  
이 예시에서는 가중치의 합이 100이 되는데  
실제로는 이럴 필요는 없습니다  
Amazon Route 53에서 오는 DNS 응답의 70%가  
첫 번째 EC2 인스턴스로 리다이렉팅된다는 의미죠  
20퍼센트는 두 번째로 10퍼센트는 세 번째 인스턴스로 갑니다  

가중치 기반 정책이 사용되는 경우는 제법 명확한데요  
`서로 다른 지역들에 걸쳐 로드 밸런싱을 할 때나 적은 양의 트래픽을 보내 새 애플리케이션을 테스트하는 경우`에도 사용합니다

### 지연 시간 기반 라우팅 정책

지연 시간이 가장 짧은, 즉  
`가장 가까운 리소스로 리다이렉팅을 하는 정책`입니다  
지연 시간에 민감한 웹사이트나 애플리케이션이  
있는 경우에 아주 유용한 정책이죠

### 상태 확인 정책

만약 한 지역이 사용 불가능 상태가 되면  
당연히 그곳으로는 유저를 보내고 싶지 않겠죠  
그러기 위해선 Route 53에서 상태 확인을 생성해야 합니다
이 상태 확인들은 각자의 메트릭을 사용하는데  
CloudWatch의 지표에서도 확인이 가능합니다  

간격도 설정 가능한데 두 개의 선택지가 있죠  
`30초마다 정기적으로 확인할 수도 있고  
비용이 더 들지만 10초마다 할 수도 있죠`  
빠른 상태 확인이라고 불립니다  
HTTP, HTTPS와 TCP 등 많은 프로토콜을 지원합니다  

위치도 선택할 수 있습니다  
상태 확인은 로드 밸런서로부터  
`2xx나 3xx의 코드를 받아야만 통과`가 됩니다  
텍스트 기반 응답일 경우  
상태 확인은 응답의 처음 5,120바이트를 확인합니다  
`응답 자체에 해당 텍스트가 있는지 보기` 위해서죠  

`여러 개의 상태 확인 결과를 하나로 합쳐주는 기능`입니다  
Route 53을 보면 EC2 인스턴스가 세 개 있고  
상태 확인을 세 개 생성할 수 있죠  
이들은 EC2 인스턴스를  
하나씩 확인해 주는 하위 상태 확인이 될 겁니다  
이제 이 하위 상태 확인을 바탕으로  
상위 상태 확인을 정의할 수 있습니다  
이 상태 확인들을 모두 합치기 위한 조건은   
OR와 AND 또는 NOT입니다  
하위 상태 확인을 256개까지 모니터링할 수 있고  
상위 상태 확인이 통과하기 위해 몇 개의  
상태 확인을 통과해야 하는지도 지정할 수 있죠  

### 장애 조치 정책

장애 조치 라우팅 정책은 첫 번째, 두 번째 리소스를 정해두고 첫 번째 리소스가 비정상일 경우 두 번째 리소스로 라우팅합니다.   
로드밸런싱 용도로 사용하기에는 어려움이 있습니다.   
첫 번째 리소스가 비정상인 경우에만 두 번째 리소스로 라우팅을 하기 때문입니다.   
레코드를 정의할 때 특이한 점은,   
Failover record type을 'Primary'로 지정할 때 Health check 부분은 정상여부를 확인하기 위해 필수로 기입해야 한다는 점입니다.

하나는 기본 EC2 인스턴스이고  
두 번째는 보조 EC2 인스턴스 혹은 재해 복구 EC2 인스턴스입니다

상태 확인이 비정상이면  
자동으로 Route 53은 2번째의 EC2 인스턴스로 장애 조치하며 결과를 보내기 시작합니다

클라이언트의 DNS 요청은  
정상으로 생각되는 리소스를 자동으로 얻습니다  
기본 인스턴스가 정상이면 Route 53도 기본 레코드로 응답합니다  
하지만 상태 확인이 비정상이면 장애 조치에 도움이 되는  
두 번째 레코드의 응답을 자동으로 얻게 됩니다

### 지리 위치(Geolocation) 라우팅 정책

지연 시간 기반의 정책과는 매우 다르게
사용자의 `실제 위치를 기반`으로 합니다  
예를 들어 사용자가  
특정 대륙이나 국가 혹은 더 정확하게  
미국의 경우에는 어떤 주에 있는지 지정하는 것이며  
`가장 정확한 위치가 선택`되어  
그 IP로 라우팅 되는 것입니다  
일치하는 위치가 없는 경우는  
기본 레코드를 생성해야 합니다  
사용 사례로는 콘텐츠 분산을 제한하고  
로드 밸런싱 등을 실행하는 웹사이트 현지화가 있습니다  
이런 레코드는 상태 확인과 연결할 수 있습니다  

## 지리 근접 라우팅

이는 사용자와 `리소스의 지리적 위치를 기반`으로  
트래픽을 리소스로 라우팅하도록 합니다  
이 정책으로 편향값을 사용해 특정 위치를 기반으로  
리소스를 더 많은 트래픽을 이동하는 것입니다  

리소스는 AWS의 리소스로  
속한 특정 리전을 지정하면  
목록에서 자동으로 올바른 라우팅을 계산하거나  
AWS 리소스가 아닌 온프레미스 데이터 센터인 경우  
위도와 경도를 지정해서  
AWS가 위치를 파악하도록 해야 합니다

### 트래픽 플로우

트래픽 플로우라는 기능으로  
복잡한 지리 근접 레코드를 설계하는 방법에 관해  
살펴보겠습니다  
이는 지리 근접성뿐만 아니라 모든 것에 적용됩니다  
UI라는 비주얼 에디터로  
복잡한 라우팅 의사 결정 트리를 관리하는 것입니다  
이것이 바로 UI이고 다른 규칙을 지정해 여러 가지를  
시도가능하다.

## 다중 응답 라우팅 정책 (Multivalue answer)

다중 응답 라우팅 정책은 요청에 대해 여러 리소스 값을 반환할 수 있습니다. 
로드밸런서 역할을 할 수 있지만 몇 가지 제약사항이 있습니다.(해당 정책으로만 로드밸런싱을 구현하는건 추천드리지 않는 방법입니다.)
Record type을 지정할 때 CNAME, NS 를 지원하지 않으며 리소스 값으로 alb 등의 값을 줄 수 없고 오로지 'IP address or another value' 로만 지정이 가능합니다.

# VPC

Virtual Private Cloud(VPC) 사설 네트워크를 의미합니다.

논리적인 구조인 VPC 내부에는  
서브넷이 있고 이것이 VPC 안에 있는 네트워크를 분할하게 해줍니다  
서브넷은 가용 영역 수준에서 정의됩니다  
즉 1개의 AZ가 있습니다 예시에 AZ A가 있죠  
서브넷은 여러 개가 될 수 있는데  
첫 번째 서브넷은 공용 서브넷입니다  
보이는 것처럼 공용 서브넷은  
인터넷으로부터 접근됩니다  
즉, 서브넷은 월드 와이드 웹(www)에 접근할 수 있고  
월드 와이드 웹으로부터 접근될 수 있죠  
또 다른 서브넷은  
사설 서브넷이라고 합니다 사설 서브넷은  
인터넷에서 접근할 수 없습니다  

인터넷으로의 접근과 서브넷 사이의 접근을 정의하기 위해  
라우팅 테이블을 사용할 것입니다  
VPC 내에서 여러 라우팅 테이블을 정의하여  
다른 서브넷 사이에서 네트워크가  
어떻게 흐를지 정의합니다

큰 범위의 VPC 다이어그램을 살펴보면  
클라우드 인프라가 있고  
리전이 하나 있습니다 리전 안에 VPC가 있죠  
VPC는 IP 범위를 갖고 있습니다  
이를 CIDR 범위라고 합니다 VPC에서 허용하는 IP 범위입니다

공용 서브넷에 EC2 인스턴스가 있다고 했는데요  
무엇이 서브넷을 공개적으로 만드는 걸까요?  
어떻게 인터넷에 접근할까요?  
이를 위해 `인터넷 게이트웨이`를 사용합니다  
인터넷 게이트웨이가 서브넷에 있는 VPC 인스턴스가  
인터넷에 연결되도록 지원합니다  
여기 인터넷 게이트웨이가 있고 VPC에 있습니다  
공용 서브넷은 인터넷 게이트웨이로 라우팅 되고  
예를 들어 공용 서브넷에 있는 EC2 인스턴스는  
인터넷 게이트웨이로 라우팅 됩니다  
인터넷 게이트웨이가 인터넷과 통신하는 법을 알고 있어서  
공용 서브넷을 공개적으로 만들어줍니다  
즉, 공용 서브넷은 인터넷 게이트웨이로 직접 라우팅 됩니다  
다른 예시를 살펴보겠습니다  
사설 서브넷에 EC2 인스턴스가 있고  
이것도 인터넷에 접근하게 만들고 싶습니다

## 네트워크 ACL의 개념과 보안 그룹

NACL 또는 네트워크 ACL을 만들 수 있는데  
이것은 서브넷에서 들어오고  
나가는 트래픽을 제어하는 방화벽입니다  
어떤 규칙을 허용하거나 거부할 수 있죠  
즉, 트래픽을 허용하거나 거부할 수 있습니다  
NACL을 서브넷 수준에서 만들고  
규칙은 오직 IP 주소를 포함합니다  
즉, 이 IP 주소에서 오는 모든 트래픽을 허용하거나  
이 IP 주소에서 오는 모든 트래픽을  
거부하는 등이 될 수 있습니다

다른 강의에서 보안 그룹을 자세히 다뤄봤지만  
NACL을 다루지는 않았습니다 왜일까요?  
기본 VPC에서  
기본 NACL은 들어오고 나가는  
모든 것을 허용하기 때문입니다  

## VPC 플로우 로그

서브넷 플로우 로그, ENI 플로우 로그,  
일래스틱 네트워크 인터페이스, 플로우 로그가 있습니다  
즉, 네트워크가 VPC를 통과할 때마다  
플로우 로그에 기록될 것입니다  
연결 문제를 모니터링하고 해결할 때 도움 됩니다  
예를 들어 여러분의 서브넷이  
왜 인터넷에 접근할 수 없는지 또는 왜 서브넷이 다른 서브넷과  
또는 인터넷에서 서브넷에  
왜 통신하거나 통신하지 못하는지 등을 알 수 있습니다  
네트워크에 문제가 있을 때  
이를 해결하기 위해  
VPC 플로우 로그를 살펴봐야 합니다  
여기에 허용되고 거부된 트래픽 관련  
모든 정보가 있기 때문입니다  
네트워크 정보가 캡처될 뿐만 아니라  
AWS에 의해 관리되는 모든 것이 있습니다  
즉, 일래스틱 로드 밸런서, 일래스틱 캐시, RDS, 오로라가  
VPC 플로우 로그에 나타날 것입니다 따라서 연결 문제가 있을 때  
여기를 바로 살펴보면 됩니다  
VPC 플로우 로그 데이터는 S3나  
CloudWatch 로그에 보내서 저장할 수 있죠  
이렇게 AWS 환경에 저장할 수 있습니다

## VPC 피어링

2개의 가상 사설 클라우드가 있고  
이들은 2개의 다른 계정이나 2개의 다른 지역에 있습니다  
이들을 `같은 네트워크에 있는 것처럼 만들기 위해 연결`하고자 합니다  
즉, AWS의 V 네트워크를 이용하여  
VPC를 비공개로 연결하고자 합니다  
이것은 그들이 같은 네트워크에 있는 것처럼 행동하게 만들어 줍니다  
VPC A와 VPC B가 있고  
이 둘이 서로 통신하게 하기 위해  
`A로부터 B로의 VPC 피어링 연결을 설정`해야 합니다  
VPC 연결을 확실하게 하기 위해  
각 VPC에 정의된 IP 범위가  
겹치지 않는지 확인해야 합니다  
다른 VPC에 네트워크를 지정하려면  
IP 주소를 사용하여 통신해야 하는데  
만약 네트워크 범위가 겹치면  
네트워크는 어디로 가야 할지 모릅니다  
따라서 VPC를 연결하기 위해 VPC가 작동하는  
IP 주소 범위가 다르고 겹치지 않는지 확인해야 합니다  
VPC 피어링은 전이되지 않기 때문에  
서로 통신해야 하는 VPC마다 설정해야 합니다  
즉, VPC C를  
VPC 피어링을 통해 A와 C를 연결하려면  
B와 C는 서로 통신할 수 없습니다  
VPC 피어링이 전이되지 않기 때문이죠  
즉, VPC B와 VPC C 사이에서  
통신하기 원한다면  
B와 C 사이에 VPC 피어링 연결을 해야 합니다  
이 말은 VPC 피어링이 많아질수록, 즉, 더 많은 VPC를 추가할수록  
더 많은 피어링 연결 추가가 필요하다는 것입니다  

엔드 포인트는 사설 네트워크를 이용하여 AWS 서비스를 연결하게 해줍니다  
공용 인터넷 네트워크를 이용하는 대신에 말이죠  
여러분이 모를 수 있는 것은  
모든 AWS 서비스는 공개라는 점입니다  
즉, EC2 인스턴스가  
AWS 서비스를 사용할 때마다 공개적으로 AWS와 소통합니다  
때때로 EC2 인스턴스는 공용 서브넷에 연결되지 않을 수 있는데  
이때는 AWS 서비스에 비공개로 접근하기 원합니다  
이때 VPC 엔드 포인트를 사용합니다  
이를 통해 AWS 서비스에 접근할 때  
보안 수준을 향상하고 지연 시간을 단축합니다  
예시를 살펴보면, 사설 서브넷과 그 안에 EC2 인스턴스가 있습니다  
이제 Amazon S3와 DynamoDB에 접근하고자 합니다  
VPC를 벗어나 공용 영역으로 들어가고자 하는 것입니다  
이때 VPC 엔드 포인트 게이트웨이를 생성합니다  
이것은 오직 S3와 DynamoDB를 위한 것입니다

`EC2 인스턴스가 VPC 엔드 포인트에 통신`하고  
`S3와 DynamoDB에 비공개로 접근`합니다  
보이는 것처럼 트래픽은 인터넷을 통하지 않습니다    
VPC 엔드 포인트 인터페이스는  
서비스의 나머지 부분으로 여러분의 VPC에서만 사용됩니다

온프레미스 데이터 센터 사이의 연결을 어떻게 설정할까요?  
사무실 건물일 수도 있고 클라우드 VPC일 수도 있습니다  
첫 번째 방법은 `Site-to-Site VPN` 으로  
`온프레미스 VPN 장치를 AWS 에 연결`합니다  
연결은 `자동으로 암호화되어 인터넷에 공개 연결`됩니다  
예시에서는 온프레미스 데이터 센터와  
VPC 사이의  
`가상 사설 네트워크 (VPN)로 인터넷`에 공개됩니다  
`설정하기 쉽고 빠릅니다 몇 분 안에 설정할 수 있죠`  
`비공개 연결이 아니죠, 암호화하여 공개 인터넷을 통해 VPC에 연결`됩니다

같은 목적으로 사용 가능한 것으로 `Direct Connect(DX)`가 있습니다  
온프레미스 데이터 센터와 VPC를 연결하기 위해 사용되는데    
이 경우에는 `물리적으로 연결`됩니다  
즉, `비공개 연결`이기 때문에  
`공개된 인터넷을 통하지 않을 것이며 안전하고 빠릅니다`  
`사설 네트워크`를 통하죠  
그리고 `VPC 와의 비공개 회선이기 때문에 설정하는 데 적어도 한 달이 걸리죠`  
AWS와 비공개 연결을 위해서  
할 일이 있기 때문입니다  
이름이 Direct Connect 인 이유는 비공개 라우팅이기 때문입니다  
VPN과 Direct Connect는  
같은 목적을 달성하지만, 방법이 다르고 타임라인이 다릅니다  

만약 Site-to-Site VPN을 사용하거나  
Direct Connect를 사용한다면  
이전에 이야기한 VPC 엔드 포인트에 접근할 수 없다는 것을 알아두세요   
VPC 엔드 포인트는 VPC에 있는 AWS 서비스로  
비공개로 접근하게 하지 온프레미스 데이터 센터로  
접근하게 하는 것이 아닙니다

## NAT 게이트웨이

IPv4를 사용하여 프라이빗 서브넷의 EC2 인스턴스에 대한 인터넷 액세스를 제공하는 동시에 이 솔루션에 최소한의 관리가 필요하고 원활하게 확장되도록 하고 싶습니다.

# S3

`S3은 객체를 저장하게 해주는 시스템이자 서비스`입니다  
즉, 파일이 버킷 또는 디렉터리에 있고  
각 버킷은 전역적으로 고유한 이름을 갖습니다  

S3은 전역 서비스이지만  
`버킷은 리전 리소스`입니다  
명명 규칙으로는 `대문자나 소문자를 포함하지 말 것`,  
`밑줄을 사용하지 말 것 길이는 3에서 63자일 것`,  
`IP 주소가 아닐 것 소문자 또는 숫자`로 시작할 것이 있습니다  

`버킷 내에는 디렉터리 개념 없이 키 이름만 아주 깁니다`  
UI는 여러분이 디렉터리를 생각하도록 만들 것이지만요  
왜냐하면 S3 내에서  
디렉터리를 생성할 수 있기 때문입니다  
S3에서 가질 수 있는 것은  
'/'를 가진 매우 긴 이름의 키뿐입니다  

Amazon S3에서 `객체의 최대 크기는 5TB, 5,000GB` 로 매우 큽니다

그러나 한 번에 5GB 이상 업로드할 수 없습니다  
즉, 5TB의 큰 객체를 업로드하기 원한다면  
객체를 5GB 미만으로 나누어서  
각각 업로드해야 합니다  
이것을 멀티파트 업로드라고 합니다  

## 버전 관리

즉, 같은 키로 파일 버전을 다시 업로드하는 경우에  
기존 파일을 덮어쓰게 되는데 사실은 덮어쓰는 게 아니라  
해당 파일의 새로운 버전을 생성하는 겁니다  
`따라서 기존의 파일을 덮어쓰는 것이 아니라 새로운 파일 버전을 생성하는 거죠`   
여기서는 간단하게 표현해서  
버전 1, 2, 3 등이 되겠습니다  
Amazon S3에서 버킷을 버저닝하여  
모든 파일 버전을 어느 정도 유지하는 것이  
가장 좋은 방법이라고 할 수 있는데요  
원치 않은 삭제로부터 보호받을 수 있기 때문입니다  
이전 버전을 복원할 수 있거든요  
또한 필요한 이전 버전으로 손쉽게 되돌릴 수도 있습니다

## 객체 암호화

Amazon S3에 객체를 업로드할 경우  
이들은 AWS 내의 서버가 되므로  
`객체로 접근이 불가능하게끔` 
보호하려 할 겁니다  
예를 들어 누군가가 Amazon 서버에 들어올 때  
혹은 회사에서 설정한 보안 기준을  
확실히 준수하려는 경우 등이 있겠죠  

### SSE-S3

`AWS 가 처리 및 관리하는 키`를 사용해 S3 객체를 암호화하는 방법이죠

객체는 `서버 측에서 암호화`됩니다  
SSE가 서버 측 암호화를 뜻하죠  
그리고 암호화 유형은 `AES-256 알고리즘`입니다  
따라서 이렇게 객체를 업로드하고  
SSE S3 암호화를 설정하려면  
`"x-amz-server-side-encryption":"AE256"`로  
헤더를 설정합니다 x-amz는 x Amazon이며  
x Amazon 서버 측 암호화 AES-256, 이런 식으로  
헤더 이름을 기억할 수 있겠죠

Amazon S3로 해당 객체를 업로드해서  
SSE-S3 암호화를 하려 합니다  
그러면 우선 Amazon S3에 객체를 업로드합니다  
HTTP 혹은 HTTPS 프로토콜을 사용할 수 있습니다  
그리고 방금 언급했던 헤더를 추가합니다  
"x-amz-server-side- encryption":"AES256"  
그러면 Amazon S3는 이 헤더를 통해 고유의 S3 관리 데이터 키를  
사용해야 한다는 사실을 인식하고 S3 관리 데이터 키와 객체를 사용해서  
암호화가 이루어집니다 그 후 객체는 암호화되어  
Amazon S3 버킷에 저장이 되죠  
아주 간단합니다 하지만 이 인스턴스에서는  
`Amazon S3에서 데이터 키를 전부 소유 및 관리`하고 있는 거죠 

### SSE-KMS

`AWS 키 관리 서비스를 사용`해서 암호화 키를 관리하는 방법입니다

`누가 어떤 키에 접근할 수 있을지 제어 가능`하고 또한 `감사 추적`을 할 수 있기 때문입니다  
이를 위해서는 헤더를 설정할 때  
`x Amazon 서버 측 암호화 값을 "aws:kms"로 지정`해야 합니다  
역시 서버 측 암호화이므로 원리는 이전과 동일합니다

객체가 있고, HTTPS와 헤더를 사용해 업로드가 되어 있죠  
그리고 이 헤더를 통해서  
Amazon S3은 미리 정의해 둔  
KMS 고객 마스터 키를 사용하게 됩니다  
고객 마스터 키를 사용하면  
즉 지정된 키와 객체를 사용하면  
암호화가 이루어지고 파일은 SSE-KMS 암호화 방식 하에  
S3 버킷에 저장됩니다

### SSE-C

`사용자가 만든 암호화 키`를 관리할 때 쓰이는 방식이죠

서버 측 암호화 방식을 뜻하며  
AWS 가 `외부에서 고객이 관리하는 키를 사용`하죠  
이런 경우에 Amazon S3은  
`고객이 제공한 암호화 키를 저장하지 않습니다`  
암호화를 위해서는 당연히 키를 사용하겠지만  
그 후에는 키를 폐기합니다  
그리고 데이터를 AWS로 전송할 때에는  
`HTTPS를 사용`해야 합니다 AWS로 암호를 전달할 테니  
전송되는 동안 암호화가 반드시 필요하겠죠  
암호화 키가 HTTP의 헤더에 제공되어야 하는데, 모든 HTTP  
요청마다 매번 제공되어야 합니다 항상 사용 후 폐기되기 때문이죠

만약 SSE-C를 통해 Amazon S3으로부터 파일을  
다시 받으려면 사용된 것과 동일한  
클라이언트 측 데이터 키를 제공해야만 합니다  
그러니 `클라이언트 측에서 관리할 것이 더 많겠죠`  
클라이언트가 데이터 키를 관리하는데 Amazon 측인 AWS는  
사용자가 어떤 데이터 키를 사용했는지를 알 수 없기 때문입니다  
우리가 해야 할 일이 좀 더 많죠

### 클라이언트 측 암호화

이 방법은 Amazon S3에 객체를 업로드하기 전  
클라이언트, 즉 `여러분이 객체를 암호화`하는 겁니다  
클라이언트 라이브러리를 사용할 수 있는데  
`Amazon S3 Encryption Client`  
등으로 클라이언트 측 암호화를 수행할 수 있습니다  
클라이언트는 데이터를 `S3로 보내기 전에 암호화`해야 합니다  
만약 전달받은 데이터가  
클라이언트 측 암호화, 즉 CSE를 사용해 암호화되었다면  
데이터를 해독할 책임도  
전적으로 사용자에 달려있습니다  
따라서 올바른 키가 준비되어 있어야겠죠  
즉 클라이언트 측 암호화에서는  
키와 암호화 주기 전체를  
클라이언트가 전부 관리하게 됩니다

## 보안

### 사용자 기반 보안

IAM 사용자는 IAM 정책을 가지고 있는데  
이들의 `정책은 어떤 API 호출이 허용될지를 결정`합니다  
만약 유저가 IAM 정책을 통해 Amazon S3 버킷으로의  
액세스 방법을 승인받게 되면 실행이 가능해집니다  

### 리소스 기반 보안

S3 콘솔에서 설정 가능한 버킷 전반의 규칙이며  
S3 버킷에서 보안 주체가 무엇을 할 수 있는지  
혹은 할 수 없는지를 결정하는 정책이죠  
그리고 이를 통해 S3 버킷으로의 교차 계정 액세스가 활성화됩니다  

사용자가 IAM을 통해 S3 버킷에 액세스할 수 있다 해도  
`버킷 정책이 사용자 액세스를 명시적으로 거부한다면 액세스가 불가능합니다`

### S3 버킷 정책

이는 JSON 기반 정책인데요  
JSON 버킷 정책이 있습니다 이 버킷 정책을 사용하면  
S3 버킷 상에서 퍼블릭 읽기가 허가됩니다  

~~~
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicRead",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": ["arn:aws:s3:::mybuckey/*"]
        }
    ]
}
~~~

"Effect"는 "Allow" "Principal"의 "*"은 누구나  
"Action"은 "s3:GetObject"  
"Resource"는 examplebucket/*  
즉 S3 버킷의 어떤 객체도 가능하다는 의미죠  
좋습니다, 이를 통해 S3 버킷에 퍼블릭 액세스가 가능해지죠  
이러한 버킷 정책은 사용자의 버킷이나 객체  
둘 다에 적용할 수 있습니다  
Action은 API가 허가 및 거부를 하도록 설정하고  
Effect는 허용이나 거부 Principal은 해당 S3 버킷의  
정책을 적용할 계정 혹은 유저입니다  
흔히 S3 버킷 정책을 사용하는 경우의 예로는  
버킷에 퍼블릭 액세스 권한을 승인하거나  
업로드 시점에 객체를 암호화시킬 경우, 혹은  
교차 계정 S3 버킷 정책을 사용해서  
다른 계정에 액세스 권한을 주는 경우 등이 있습니다  

그리고 블록 퍼블릭 액세스 버킷 설정이 있죠  
`객체가 퍼블릭화 되는 것을 차단하는 새로운 설정`이었죠
계정에 제한이 있을 경우에 사용됩니다

네트워킹에서는 VPC 엔드 포인트로 S3에 비공개 액세스가 가능합니다  
즉 VPC에 EC2 인스턴스가 있고 인터넷 액세스는 없는 경우  
VPC 엔드 포인트를 통해 비공개로 S3에 액세스할 수 있는 거죠  
로깅 및 감사에서는 S3 액세스 로그를 사용하면  
다른 S3 버킷에 해당 로그가 저장됩니다  
API 호출은 CloudTrail, 계정에  
API 호출을 로깅할 수 있는 서비스에도 로깅이 가능합니다

사용자 보안에는 MFA 삭제라는 것이 있는데  
멀티 팩터 인증을 뜻하죠  
`특정 버전 객체를 버킷에서 삭제하고 싶은 경우에 MFA 삭제를 활성화`하면 됩니다  
그러면 `MFA로 인증이 되어야만 객체를 삭제`할 수 있습니다

### 사전 서명된 URL

AWS의 자격 증명으로 서명된 URL입니다  
`한정된 시간 동안만 유효`하고요  
사용 예시를 보면, 유저가 로그인한 서비스로부터  
프리미엄 영상을 구매하여 다운로드하는 경우 등입니다  
그러므로 만약 시험에서 제한된 시간 내에  
특정 사용자가 특정 파일에 액세스하는 경우에 관련된 문제가 나오면  
사전 서명된 URL을 생각하시면 됩니다  

버킷 정책 생성 참고 사이트

~~~
{
    "Version": "2012-10-17",
    "Id": "bukit",
    "Statement": [
        {
            "Sid": "Statement1",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::버킷이름/*",
            "Condition": {
                "Null": {
                    "s3:x-amz-server-side-encryption": "true"
                }
            }
        },
        {
            "Sid": "Statement2",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::버킷이름/*",
            "Condition": {
                "StringNotEquals": {
                    "s3:x-amz-server-side-encryption": "AES256"
                }
            }
        }
    ]
}
~~~

https://aws.amazon.com/ko/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/

## 정적 웹사이트

`www 에서 접근이 가능하도록 허용`하며 웹사이트 URL도 아주 간단합니다  
HTTP 엔드 포인트로 이와 같은 모습이거나  
여러분이 속한 리전에 따라 다음과 같은 모습일 수 있습니다  
버킷 이름으로 먼저 시작해서  
.s3-website.AWS-리전  
.amazonaws.com으로 끝납니다  

## CORS 교차 오리진 리소스 공유

오리진(Origin)이란 뭘까요? 오리진은 체계, 즉 프로토콜이자  
호스트, 도메인, 그리고 포트입니다  
쉽게 설명하면  
가령 https://www.example.com는  
체계가 HTTP  
호스트가 www.example.com, 포트가 443인 오리진입니다  
포트는 어떻게 알까요? HTTP를 사용하는 경우 기본 포트가 443입니다  
CORS는 교차 오리진 리소스 공유라고 했습니다  
즉 리소스를 다른 오리진에서 얻을 수가 있다는 말이죠  
웹 브라우저에는 기본적인 보안으로  
CORS를 갖추고 있는데 이는 여러분이 웹사이트를  
방문했을 때 다른 오리진이  
허락할 때에만 요청을 보낼 수 있도록 허락하는 설정입니다  
브라우저 기반 보안인 거죠  
그럼 같은 오리진과 다른 오리진이란 무엇일까요?  
같은 오리진은 다음과 같습니다  
example.com/app1 또는 example.com/app2일 때  
같은 오리진이라고 할 수 있죠 이때는 첫 번째 URL에서  
두 번째 URL로 웹 브라우저 간 요청이 가능합니다  
오리진이 같기 때문이죠  
하지만 www.example.com를 방문한 다음 웹 브라우저에  
other.example.com에 대한 요청을 할 경우  
이를 교차 오리진 요청이라고 하며  
이때 올바른 CORS 헤더가 없으면 웹 브라우저가 해당 요청을 차단합니다  
CORS 헤더는 화면에서 보이는 것과 같이  
Access-Control-Allow-Origin 라고 합니다

# IAM 역할 및 정책

아래 링크에서 정책을 테스트 할 수 있습니다.
https://policysim.aws.amazon.com/home/index.jsp?#roles

## CLI

모종의 이유로 IAM 정책을 살펴볼 수 없는 경우가 발생합니다  
명령을 실행하고 싶은 것이 아니라  
권한이 있는지만 확인하고자 하는 경우 말이죠  
EC2 명령과 같은 일부 AWS CLI 명령은  
성공했을 시 그 비용이 상당하기도 합니다  
실제로 EC2 인스턴스를 생성해야 하기 때문입니다  
그저 제대로 작동하는 것만 확인하려면  
이들 명령 중 일부에 포함된  
--dry-run 옵션을 사용할 수 있습니다  
이 옵션은 API 호출에 대한 시뮬레이션을 실행해서  
권한이 없을 때는 예외적으로 거부되었다고 알 수 있을 테고  
권한이 있을 때는 명령이 실행되지 않습니다

테스트로 아래 명령어를 입력해 보자

~~~
aws ec2 run-instances 
--dry-run 
--image-id ami-03df3a7fd5e4f89c7
--instance-type t4g.micro
~~~

오류가 발생하며 이는 본 작업을 수행할 권한이 없음을 나타냅니다  
앞서 `dry-run 명령`을 설정해 뒀기 때문이죠  
dry-run 명령을 사용하면  
작업에 대한 권한이  
있는지를 테스트할 수 있는 겁니다  

실패

> An error occurred (AuthFailure) when calling the RunInstances operation: Not authorized for images: [ami-03df3a7fd5e4f89c7]

성공

> An error occurred (DryRunOperation) when calling the RunInstances operation: Request would have succeeded, but DryRun flag is set.

API 호출 실행 시  
장애가 발생하면  
크게 중요하지 않지만 긴 오류 메시지가 나타나는데  
이럴 때는 디코딩 하면 됩니다  
디코딩에 관련해서는 질문도 가장 많고  
시험에도 자주 출제되는데 STS 명령줄을 사용합니다  
`sts decode-authorization-message` 로  
메시지를 디코딩합니다  

https://docs.aws.amazon.com/cli/latest/reference/sts/decode-authorization-message.html

~~~
decode-authorization-message --encoded-message [error code]
~~~

## EC2 인스턴스 메타데이터

다이 기능은 EC2 인스턴스가 스스로 학습하도록 해서  
그 목적으로 IAM 역할이 필요하지 않습니다  
이해가 되지 않나요? EC2 인스턴스는 스스로 학습하니까요  
그리고 URL 관련해서  
꼭 기억해야 할 것은  
`169.254.169.254/latest/meta-data` 입니다

인스턴스 메타데이터 서비스를 사용하여 EC2 인스턴스에 연결된 IAM 역할 이름을 검색할 수 있지만 `IAM 정책 자체는 검색할 수 없습니다.`

## AWS CLI 프로필

~~~
cd ~/.aws

.aws % cat config
[default]
region = ap-northeast-2
.aws % cat credentials
[default]
aws_access_key_id = id
aws_secret_access_key = key
~~~

config를 입력하면 default 섹션이 나오는데  
credentials를 입력해도 동일한 섹션이 나오며  
AWS access key id와 secret access key를 포함합니다  
그러면 제 이전 AWS 계정과 연결되어 있는데  
계정이 여러 개일 경우에는 어떻게 해야 할까요?  

> aws configure --profile jjunpro

위 명령어로 추가 할 수 있습니다.

## MFA가 있는 AWS CLI

CLI 또는 SDK를 사용해  
다요소 인증을 사용하는 방법입니다  
CLI를 사용하려면 임시 세션을 생성해야 하고  
`API를 사용하려면 STS GetSession Token을 사용`해야 합니다  
꼭 외워야 하죠 GetSession Token은  
다요소 인증 장치로 자격 증명을 얻기 위해  
호출하는 API입니다  

~~~
aws sts get-session-token --serial-number arn:aws:iam::00000000000:mfa/user --token-code 542831

아래 토큰을 반환함

{
    "Credentials": {
        "AccessKeyId": "1234_1",
        "SecretAccessKey": "1234_2",
        "SessionToken": "1234_3",
        "Expiration": "2022-07-05T23:39:23+00:00"
    }
}
~~~

다음으로 ~/.aws/credentials로 파일을 여는데  
aws_session_token= 을 입력한 다음에  
전체 토큰을 복사하겠습니다

## AWS SDK 개요

만약 지금까지 사용했던 CLI를 사용하지 않고  
애플리케이션 코드에서 직접  
AWS 작업을 하려면 어떻게 해야 할까요?  
이때 소프트웨어 개발 키트인 SDK를 사용합니다    
그리고 다양한 언어의 AWS용 공식 SDK가 있습니다  
Java, .NET와 Node.js가 있고  
PHP, Python, Go, Ruby 그리고 C++ 등이 있습니다  
그리고 이 목록은 계속 늘어날 것입니다  
CLI를 사용할 때는 Python SDK를 사용했는데요  
CLI가 Phython 언어를 사용하고  
Boto3 SDK를 사용하기 때문입니다  
그래서 SDK는 DynamoDB나 Amazon S3와 같은  
Amazon 서비스에서 API 호출을 발행할 때 사용합니다  
하지만 CLI도 Phython SDK (boto3)를 사용합니다  
그래서 언제 SDK를 쓰는지가 시험에 출제됩니다  
Lamda 함수를 다룰 때 SDK를 살펴보고  

`기본 리전을 구성하지 않으면` API 호출을 위해서 SDK에서 `us-east-1`이 설정 됩니다.

## 지수 백오프 및 서비스 제한 증가

이제 할당량이라고도 부르는 AWS 제한에 관해 살펴봅니다  
제한에는 2가지가 있는데요 첫 번째는 API 비율 제한으로  
`AWS API를 연속으로 호출하는 횟수`를 말합니다  
예를 들어, Amazon EC2의 DescribeInstances API는  
초당 100회 호출의 제한이 있습니다  
그리고 Amazon S3의 GetObject는  
접두부와 초당 5,500GET의 제한이 있습니다  
그래서 진행하다 보면 간헐적 오류도 발생하는데  
제한되기 때문입니다  
그래서 지수 백오프 전략을 사용해야 합니다.

애플리케이션 사용량이 많아서  
계속 제한을 초과하는 경우에는  
API 제한 증가를 요청해 계속 사용하도록 합니다  
DescribeInstances의 제한을  
초당 100회 호출 이상 또는 300회 이상으로  
요청할 수도 있죠  
AWS에 문의해야 하죠

지수 백오프는 언제 사용할까요?  
`조절 오류(ThrottlingException)가 발생한 경우`입니다  
이 질문도 자주 출제되는데 조절 오류는  
API 호출을 많이 했기 때문이며

'지수 백오프를 사용하여 다시 시도' 는 최대 다시 시도 횟수에 도달할 때까지 대기 시간이 기하급수적으로 증가하면서 작업을 다시 시도하는 기술입니다(지수 백오프).   
이 기술은 클라우드 리소스가 어떤 이유로든 몇 초간 일시적으로 사용할 수 없다는 팩트를 포함합니다

자체 SDK를 실행하는 경우나  
자체 사용자 정의 HTTP 호출을 사용하는 경우  
500으로 시작하는 오류 코드의  
서버 오류가 발생하면 재시도 메커니즘을 실행해야 합니다  
503과 같이 5xx로 시작하는 오류입니다  
이러한 서버 오류와 조절 오류는  
재시도 가능하지만  
`4xx 클라이언트 오류에서는 재시도 혹은 지수 백오프를 실행해서는 안 됩니다`
400 오류의 경우에는 클라이언트를 통해  
뭔가 잘못 보내졌다는 의미로  
계속 재시도 하면 동일한 오류가 계속 발생합니다  

### 지수 백오프의 원리는 무엇일까요?

이제 1초 동안 첫 번째 요청을 시도하고  
다음 요청까지 대기 시간을 두 배로 늘리겠습니다  
그러면 2초가 되겠죠  
그리고 다음 시도에서 또 2배 늘립니다  
4초가 되면 다시 2배로 늘립니다  
다음 시도에서는 8초가 되겠죠?  
그리고 그다음 시도에서는 16초가 될 것입니다 
이러한 지수 백오프의 개념은 더 시도하고 대기하면서  
많은 클라이언트가 동시에 이 작업을 실행하면  
그 결과로 서버의 부하가 점점 줄어들어서  
서버에서 가능한 많이 응답할 수 있도록 합니다  
여기까지 지수 백오프의 전체 개념입니다

## 자격 증명 공급자 및 체인

CLI를 사용하면 이어지는 명령에서 자격 증명을 요청합니다  
명령줄 옵션을 찾는 것이죠  
그래서 명령줄 옵션에서 리전, 출력값, 프로파일  
혹은 액세스 키 ID와 비밀 액세스 키  
`그리고 세션 토큰을 지정하면 그 어떤 것보다 우선`이 됩니다

두 번째로 살펴볼 것은 환경 변수입니다
여기 있는 환경 변수 중 한 가지를 설정하고  
`명령줄 옵션을 설정하지 않으면 환경 변수를 우선 적용`합니다  
그리고 AWS configure를 실행할 때  
CLI 자격 증명 파일을 살펴보고  
CLI 구성 파일을 살펴보는데  
동일한 방식으로 설정됩니다  

그래서 최우선은 명령줄 옵션이고  
그다음이 환경 변수이며 마지막 우선순위는  
EC2 프로파일 자격 증명이나  
ECS 컨테이너 자격 증명입니다 

### SDK

이제 SDK를 살펴보죠 예를 들어, Java SDK는   
개념이 유사합니다   
최우선시 되는 것은  
`Java 시스템 속성`입니다    
그다음은 아주 중요한 `환경 변수`인데  
액세스 키 ID나 비밀 액세스 키 같은 것입니다  
Java 시스템 속성을 제외하면  
그 무엇보다 최우선시 되죠  
그리고 `기본 자격 증명 프로파일 파일`이 있고  
Amazon ECS 컨테이너 자격 증명과  
인스턴스 프로파일 자격 증명이 있습니다  
여기서 기억해야 할 것은  
환경 변수가 여전히 우선시 된다는 것인데  
예를 들면, EC2 인스턴스 프로파일 자격 증명입니다  

## AWS 서명 v4 서명

AWS HTTP API를 호출할 때  
해당 요청을 API로 인증해야 합니다  
즉 그 요청에 서명을 해야만 사용자 전용 AWS 자격 증명을 통해  
AWS가 사용자를 식별할 수 있게 되는 거죠  
AWS 자격 증명은 사용자의 액세스 키와 암호 키입니다  
참고로 Amazon S3로의 요청 중 일부에는 서명이 필요 없으나  
대부분의 경우는 서명을 필요로 합니다

CLI나 SDK를 사용하면 당연히 자동적으로  
사용자를 위해 모든 HTTP 요청이 서명됩니다  
하지만 SDK와 CLI를 사용하지 않으면  
사용자가 직접 서명해야 하죠  

Signature v4라는 것을 사용해서 서명합니다  
AWS 프로토콜이며, 웹사이트에서 서명 방법을 확인할 수 있죠  
`SigV4란, AWS로의 요청이 사용자 자격 증명을 이용해 서명`되었으며  
AWS로 인증을 받았다는 의미입니다

### SigV4의 작동 방식

첫 번째는 HTTP 헤더를 사용해 요청에 서명하는 경우입니다  
예를 들어 콘솔 상에서 HTTP 헤더 옵션을 사용해  
탐색을 하는 경우 SigV4를 사용하면  
올바른 권한 헤더를 표시해 줍니다  
콘솔에서 해주는 작업이며 Chrome의 개발자 도구에  
들어가도 볼 수 있습니다  
그리고 쿼리 문자열 옵션을 사용하는 경우가 있는데요  
S3 사전 서명된 URL을 사용해서 빠르게 작업할 때  
본 적이 있었던 작업이죠 아주 긴 URL이 생기고  
그 URL에는 많은 정보가 있는데  
SigV4 요청으로부터의 서명을 나타내는 정보죠  

# 고급 S3

## S3 사전 서명된 URL

사전 서명된 URL을 생성하면  
기본적인 만료 시간은 `3,600초, 즉 1시간`입니다  
시간초과를 변경하려면 명령어 `--expires-in` 에 파라미터, 인자, 그리고  
초 단위로 시간을 지정하면 됩니다  
사전 서명된 URL이 사용자에게 제공될 때는  
기본적으로 생성한 사람의 권한이 상속됩니다  
즉 객체를 만든 이의 권한이죠 따라서 사용자들은 상황에  
따라 GET이나 PUT 권한을 사용할 수 있습니다

이 기능의 사용에는 다양한 이유가 있죠
`로그인한 사용자만이 S3 버킷의 프리미엄 영상을 다운로드하도록 승인`하거나  
즉 로그인한 프리미엄 사용자에게만 약 15분 동안  
다운로드가 허용되도록 할 수 있겟죠  
또는 파일을 다운로드할 사용자들의 목록이  
지속적으로 변경될 경우  
사용자가 버킷에 직접 액세스하지 못 하게끔 해야할 겁니다  
굉장히 위험하고 유지 관리도 힘들거든요  
항상 새로운 사용자가 몰리기 때문입니다  
이런 경우에는 동적으로 URL을 생성해  
사전 서명을 한 뒤 시간이 지나면서 URL을  
URL을 제공하고자 할 수도 있겠죠  

아니면 `사용자가 버킷의 특정 위치에만 파일을 업로드`하도록  
일시적으로 승인할 수도 있습니다  
예를 들면 사용자가 여러분의 S3 버킷에  
프로필 사진을 직접 업로드하도록 하는 등이죠  
그럴 때 사전 서명된 URL을 생성합니다

### CLI 에서 서명된 URL 만들기

> aws s3 presign s3://mybucket/myobject --region my-region

> aws s3 presign s3://mybucket/myobject --expires-in 300 --region my-region

> aws configure set default.s3.signature_version s3v4 

## S3 스토리지 클래스 + Glacier

`범용으로 사용되는 Amazon S3 Standard` 입니다
물론 워크로드에 따라 최적화된 클래스들도 있죠    
이 범용 클래스 S3 Infrequent Access는 IA나 S3 IA로도 불립니다  
자주 액세스하지 않는 파일에 적합한 클래스로  

`데이터를 재생산할 수 있는 S3 One Zone IA` 가 있고요  
`S3 Intelligent Tiering 은 스토리지 클래스 간 데이터를 효율적으로 이동`할 수 있게 합니다  
`아카이브를 위한 Amazon Glacier` 와  
`즉시 필요하지 않은 아카이브를 위한 Amazon Glacier Deep Archives` 도 있습니다

### S3 Standard

내구성이 아주 좋아서 11개의 9라고도 불리는데  
다중 AZ에 걸친 객체의 내구성이 99.999999999%란 뜻이죠  
따라서 범용 Amazon S3에 10,000,000개의 객체를 저장하면  
평균적으로 10,000년에 한 번 하나의 객체 손실이 예상됩니다  
다시 말해, `S3 Standard 에서는 객체 손실이 생기지 않는다는 거죠`  
기능 장애를 동시에 두 개 버틸 수 있으므로  
AZ의 재해에 내성이 굉장히 강합니다  
범용 사용의 예로는 `빅 데이터 분석`이나  
모바일과 게임 `애플리케이션 콘텐츠 배포`가 있습니다

### S3 Standard Infrequent Access, IA

이름 그대로 자주 액세스하지 않지만 필요할 경우 빠르게 액세스해야 하는 데이터에 적합합니다  
역시 다중 AZ에 걸쳐 `높은 내구성`을 가지고 있으며
하지만 가용성 지수에 9가 하나 부족하죠
Amazon S3 Standard 에 비해 비용이 적게 듭니다  
즉, 객체에 `액세스 하는 일이 적으면 많은 비용이 들지 않는 겁니다`
두 개의 기능 장애를 동시에 버틸 수 있고요  
사용되는 사례로는 `재해 복구나 백업 또는 자주 액세스하지 않을 것으로 예상하는 파일들을 저장하는 데이터 스토리지`로 쓰입니다  
S3 One Zone IA 는 Infrequent Access 로도 불립니다  
IA와 동일하지만, 데이터가 다중 가용 영역에 저장되기 전  
`단일 가용 영역에 먼저 저장되는 방식`이죠  
`가용 영역이 다운되더라도 데이터가 여전히 사용 가능`하도록 하기 위함입니다  
단일 AZ에 대해서는 내구성이 같지만 만약 `그 AZ가 손상`되는 경우  
가령 폭발 등으로 손상될 경우에는 `데이터를 잃게 됩니다`  
가용성은 99.5%로 더 적지만 지연 시간이 짧고 높은 처리량을  
S3에서 기대해 볼 수 있습니다  
비용이 `비교적 저렴하며 모든 암호화에 SSL을 지원`합니다  
IA 대비 20% 정도 비용이 절감됩니다  
One Zone IA는 온프레미스 데이터를  
2차 백업하거나 재생성 가능한 데이터를 저장하는 데에 쓰입니다  
`재생성 가능한 데이터`란 뭘까요?  
예를 들면, `이미지의 썸네일을 재생성`할 수 있겠죠 이미지는 범용 S3에 저장하고
썸네일은 S3 One Zone Infrequent Access에 저장하는 식이죠
그리고 만약 썸네일을 재생성해야 하는 경우 메인 이미지에서 손쉽게 생성할 수 있습니다

### S3 Intelligent Tiering

S3 Standard 와 마찬가지로 지연 시간이 짧고 처리량이 높지만  
약간의 `월간 모니터링 비용과 자동 티어 비용`이 발생합니다   
이 옵션은 액세스 패턴에 기반하여 액세스 티어들 사이에서  
객체들을 자동으로 이동시켜 줍니다  
즉, `범용 S3와 S3 IA 사이에서 객체를 이동`시키는 겁니다  
`객체의 액세스 빈도를 파악해 자동으로 선택을 해주며 S3가 모니터링을 해주는 대가로 약간의 비용이 청구`되는 거죠
내구성은 9가 11개로 수치가 같고요  
가용성은 99.9%입니다  
즉, 가용 영역에 영향을 주는 모든 사건에 대응하여  
사용이 가능하도록 하는 거죠  
범용 S3 스토리지 티어 중 하나를 살펴봤습니다  

### Amazon Glacier

일종의 콜드 아카이브라고 생각하시면 됩니다  
`저렴한 비용의 객체 스토리지로 아카이빙과 백업`을 위해 존재합니다  
데이터는 장기간으로 보존됩니다  
여기서 장기간이란, 수십 년의 기간동안 데이터가 보존되는 겁니다  
온프레미스 자기 방식 스토리지에 대한 대안이 되는데요  
데이터를 저장한 자기 테이프들을 치워 두는 곳이 바로 여기죠  
따라서 데이터를 다시 회수하고 싶다면  
테이프를 수동으로 직접 찾아 
어딘가에서 데이터를 복원해야 하는 겁니다  
내구성은 역시 9가 11개라서 객체 손실이 없고요  
스토리지 당 드는 요금이 아주 저렴합니다  
GB 당 $0.004에 회수 비용이 추가됩니다  
비용은 잠시 후에 알아보도록 하죠  
`Glacier 내의 모든 항목은 객체가 아니라 아카이브`라고 불리며  
`각 아카이브의 크기는 40TB` 까지 가능합니다  
아카이브는 버킷이 아닌 금고에 저장되죠  
두 개가 비슷한 개념이긴 합니다  

#### 회수 옵션

`Expedited` 는 1-5분으로 파일을 요청하면 돌려받기까지 `1~5분이 소요`됩니다

`Standard 는 3 ~ 5시간`으로 훨씬 더 오래 걸립니다

`Bulk 는 동시에 여러 파일을 회수하는 방식`인데  
파일을 받는 데에 `5~12시간`이 걸립니다

보시다시피 Amazon Glacier에서는 `파일의 회수가 급하지 않은 경우`에 사용이 됩니다  
`긴급한 상황이라면 Expedited`를 사용할 수 있는데 Standard나 Bulk보다는 훨씬 비쌉니다  

`Glacier에 저장하는 최소 기간은 90일`입니다  
다시 강조 드리지만 Glacier 에는 파일을 장기간 보관하는 겁니다

`Deep Archive 라고 불리는 심층 스토리지`도 있는데요  
아주 장기간의 저장을 위한 스토리지로, 심지어 더 저렴합니다  
하지만 `회수 옵션의 경우 Standard 가 12시간`입니다  
12시간 이전에는 파일의 회수가 불가능한 거죠  
그리고 `Bulk 로 다수의 파일을 회수하려면 48시간`을 기다려야 하지만  
비용은 훨씬 저렴합니다

이처럼 Deep Archive는 아카이브한 파일을  
급히 회수할 필요가 없을 때에 적합한 스토리지입니다  
`Deep Archive 의 최소 저장 기간은 180일`입니다  
이 숫자들은 시험에 출제되니 기억해 두셔야 합니다  
Glacier와 Glacier Deep Archive 중  
어떤 것을 골라야 하는지를 시험에서 물어볼 겁니다  
예를 들어, 180일 보다 짧은 기간 동안 파일을 보관하려면 
Glacier 를 사용해야겠죠  
파일을 3~5시간 안에 아주 빠르게 회수해야 할 때도 Glacier를 쓰고요  
하지만 만약 회수에 72시간이 걸려도 되고  
1년 동안 Glacier의 저장소에 보관해도 되는 파일이라면  
Deep Archive를 쓰는 편이 비용을 절감해 주겠죠  

지금까지 살펴본 것들을 비교해 봅시다  

1. S3 Standard 
2. Intelligent Tiering
3. Standard IA
4. One Zone IA Glacier 
5. Glacier Deep Archive

내구성은 전부 9가 11개라서 객체 손실은 없습니다  
가용성의 측면에서 먼저 S3 IA를 살펴보면  
자주 액세스하지 않는 경우로 가용성이 조금 떨어지죠  
One Zone IA의 경우에는 가용성이 더 떨어집니다  
가용 영역을 하나만 사용하니 당연한 거죠  

SLA 는 Amazon 이 비용 변제를 보상하는 옵션입니다
굳이 알아두진 않으셔도 되지만 실제로 쓸 일이 있을 수도 있으니 표에 포함을 해뒀습니다

데이터가 저장되는 `AZ의 수는 One Zone IA만 제외`하고
`전부 3개` 인데요 `One Zone IA는 이름처럼 가용 영역을 하나`만 씁니다

`객체 당 최소 용량 제한`이 있는데 표준 범용 S3 나  
Intelligent Tiering 에는 제한이 없습니다  
하지만 `IA를 쓴다면 128KB`보다는 크기가 큰 객체만 저장이 가능합니다  
`Glacier는 40KB` 제한입니다

`Standard IA와 One Zone IA의 최소 저장 기간은 30일`이고요  
`Glacier는 90일`   
`Glacier Deep Archive는 180일`입니다  

회수 비용의 여부입니다
`Standard IA`의 경우 자주 액세스하지 않기 때문에 `데이터 회수를 할 때마다 비용을 지불`해야 합니다  
Glacier 와 Glacier Deep Archive 역시 회수하는 데이터의 용량과 원하는 회수 속도에 따라 발생하는 비용이 달라집니다
모든 숫자를 외우실 필요는 없지만  
어떤 스토리지 티어가 적합할지 판단이 가능할 수준으로는 알고 계셔야 합니다  
숫자를 좋아하시는 분들을 위해 표를 하나 더 준비했으니  
따로 살펴보시기 바랍니다 하지만 여기를 보시면  
S3 Standard 의 비용은 0.023달러로 비싸죠  
오른쪽에 Glacier를 보시면 Deep Archive 의 경우  
GB 당 한 달에 0.00099달러로 훨씬 저렴합니다  
데이터를 짧게 보관하는 경우  
Intelligent Tiering 은 0.0125~0.023달러입니다  
Standard IA도 동일하고요 One Zone IA는 더 저렴하죠  
회수 비용도 나와 있습니다  
Glacier 에서 Expedited 회수를 하려면  
요청 1000개 당 10달러가 청구됩니다  
반면, Standard나 Bulk는 비용이 훨씬 적게 듭니다  
Glacier Deep Archive도 마찬가지고요  
그리고 S3 Intelligent Tiering의 경우  
객체 모니터링 비용을 내면 S3 Standard와  
Standard IA 사이에서 객체 이동을 해줍니다  
비용은 비싸지 않습니다  
객체 1000개 당 한 달에 0.0025달러가 청구되죠  

## S3 수명 주기 규칙

그럼 수명 주기 규칙이란 뭘까요? 전환 작업은 객체를 한 스토리지  
클래스에서 다른 스토리지 클래스로 전환하는 데에 도움을 주는 작업입니다  
만약 객체를 생성 60일 후 Standard IA 클래스로 보내고  
6개월 후에는 아카이빙을 위해 Glacier로 옮긴다고 하면  
간단하고 자연스러운 과정이죠 만료 작업이란  
일정 기간이 지난 후 객체를 삭제하는 겁니다  
예를 들어 액세스 로그 파일들이  
일 년이 지나서 더 이상 필요가 없어지면  
파일들이 전부 일 년이 넘었으니  
만료, 즉 삭제해 달라고 요청하는 식이죠  
`파일의 오래된 버전을 삭제`하는 데에도 사용됩니다  
버저닝을 허용해 계속해서 새로운 파일을 덮어쓰기하고 있는데  
60일 이상 지난 이전의 버전은 필요가 없다면
만료 작업을 구성해서  
60일이 지난 오래된 버전의 파일이나 객체를 만료시키는 겁니다  
완료되지 않은 다중 파트 업로드를 정리하는 데에도 사용됩니다  
분할된 파트가 30일 동안 떠돌고 있고  
절대 완료되지 않을 거라면 말이죠  
이러한 파트를 제거하기 위해 만료 작업을 구성하는 겁니다  
`특정 접두어에 규칙을 적용`할 수도 있습니다  
만약 모든 MP3 파일이 'MP3'라는 폴더에 있거나, 접두어를   
가지고 있다면 수명 주기 규칙을 해당  
접두어에만 설정할 수도 있습니다  
이런 식으로 버킷 내의 다양한 접두어에  
수명 주기 규칙을 적용할 수 있죠  
특정 `객체 태그를 위해 규칙`을 생성할 수도 있습니다  
예를 들어 'Department: Finance'로 태그된 객체에만  
규칙을 적용하고 싶다면 그것도 가능하다는 거죠

예제를 보면서 함께 생각해 봅시다  
프로필 사진이 Amazon S3에 업로드된 후  
EC2의 애플리케이션이 썸네일을 생성합니다  
이 썸네일들은 손쉽게 재생성할 수 있으며  
45일간만 보관됩니다  
45일 동안은 원본 사진 파일을 즉시 회수할 수 있으며  
이후에는 유저가 최대 6시간까지 기다릴 수 있습니다  
이 솔루션을 어떻게 설계할 수 있을까요? 생각할 시간을 드릴 테니  
영상을 잠시 멈춘 뒤 솔루션을 함께 살펴봅시다  
`S3 원본 사진은 Standard` 클래스에 두고  
수명 주기 구성을 설정해 `45일 후 GLACIER` 로 보내면 됩니다, 왜 그럴까요?

이후에는 아카이브되어야 하기 때문에  
회수를 위해 6시간까지도 기다리게 될 수 있는 거죠  
썸네일은 ONEZONE_IA에 두면 되는데, 이유는 뭘까요?

재생성이 가능하기 때문입니다  
그리고 수명 주기 구성을 통해  
45일 후 만료, 혹은 삭제를 시킬 수도 있죠  
이해가 되시죠? 45일 후엔 썸네일이 필요 없으니  
삭제하는 거죠 원본 사진을 GLACIER로 보내고  
썸네일은 ONEZONE_IA에 저장됩니다  
비용이 절감될 테니까요  
AWS에서 전체 AZ를 잃을 상황에 대비해  
원본 사진으로부터 쉽게 썸네일을 재생성할 수 있습니다  
S3 버킷에 대한 비용 효율이 가장 높은 솔루션이 되겠죠  

두 번째 상황입니다  
회사에 일어나는 경우는 드물지만  
15일 동안은 삭제된 S3 객체를 즉시 복구할 수 있는  
규칙이 있다고 합니다  
그리고 그 이후 최대 1년까지는 삭제한 객체를 48시간 내에 복구할 수 있습니다  
이걸 경제적으로 설계하려면 어떻게 해야 할까요?  
한 번 해봅시다 S3 버저닝을 허용해야 할 겁니다  
왜냐하면 파일을 삭제는 하되 복구시키길 원하고 있으니까요  
S3 버저닝으로 객체 버전을 가질 수 있으며  
삭제된 객체는 삭제 마커를 달고 숨겨져  
쉽게 복구할 수 있기 때문입니다  
하지만 최신이 아닌 버전들, 즉  
객체의 이전 버전들도 가지게 될 겁니다  
그래서 이 `오래된 버전들은 S3_IA로 전환`을 시킵니다  
왜냐하면 오래된 버전에 액세스할 일은 아주 드물겠지만  
만약 액세스하는 경우에는 복구가 즉시 이뤄져야 하기 때문입니다  
그리고 이 오래된 버전들을 복구할 수 있는  
15일의 기간이 지나면  
이들을 DEEP_ARCHIVE 로 전환시켜서  
100일이나 365일 동안 보관하는 겁니다  
이들은 아카이브되어 48시간 내에 복구가 가능합니다  
왜 Glacier를 사용하지 않는 걸까요?   
Glacier는 비용이 좀 더 비싸며  
48시간이라는 시간이 주어졌기 때문에  
티어를 DEEP_ARCHIVE까지 올려서  
비용을 더 절약할 수 있습니다

## S3 퍼포먼스

기본적으로 `Amazon S3는 자동으로 아주 많은 수의 요청을 처리하도록 스케일링이 가능`하며  
S3에서 첫 바이트를 얻기까지 `100-200ms 정도로 지연 시간이 굉장히 짧습니다`
이를 초당 가능한 요청으로 환산하면  
접두어 및 초당 3,500개의 PUT/COPY/POST/DELETE 요청을 처리하며  
접두어 및 초당 5,500개의 GET/HEAD 요청을  
버킷 내에서 처리하는 속도입니다

접두부 및 초당의 의미는 결국 아주 고성능이라는 의미죠  
버킷 내의 `접두어의 개수에는 제한이 없습니다`  
그럼 file 이라는 이름의 객체 네 개를 예시로 들어  
해당 객체의 접두어를 분석해 보겠습니다  
첫 번째는 bucket 내의 folder1/sub1/file 에 있습니다  
이 경우에 접두어는  
bucket 과 file 사이의 뭐든 될 수 있습니다  
이 경우엔 /folder1/sub1 이 되는 거죠  
이 파일에 대해서 이 접두어는  
초당 3,500개의 PUT 과 5,500개의 GET 을 얻을 수 있습니다  
그리고 다른 파일은 folder1/sub2 에 있다고 하면  
bucket 과 file 사이의 뭐든 접두어가 될 수 있으니  
/folder1/sub2 가 되는 겁니다  
역시 3,500개의 PUT 과 5,500개의 GET 을  
한 접두부에 대해 얻을 수 있는 겁니다  
이렇게 1과 2가 있으면 접두어가 서로 다르죠  
이제 접두어에 대해서는 쉽게 이해가 되실 테니  
버킷 내의 접두어 및 초당 3,500개의 PUT 과 5,500개의 GET 을  
얻는다는 규칙도 이해가 가실 겁니다  
다시 말해 이 네 개의 접두어에 읽기 작업을 균일하게 분산시키면  
초당 22,000개의 HEAD 와 GET 요청을   
수행하는 셈이니 아주 좋은 거죠  

이제 S3 성능 제한인 KMS 를 알아 봅시다    
SSE-KMS 를 사용해 객체를  
KMS 암호화하는 경우 KMS 제한에 의해 영향을 받을 수 있는데요  
파일을 업로드하면 KMS 제한이 여러분을 대신해 S3에서  
GenerateDataKey KMS API를 호출할 것이고  
`SSE-KMS 를 통해 S3에서 파일을 다운로드하는 경우에는 Decrypt KMS-API 를 호출`하게 됩니다  
그리고 이 두 가지 요청은  
`KMS 할당량에 집계`가 되죠  
예를 들어 유저들이 S3 버킷에 연결하고  
SSE-KMS 암호화를 사용해 파일을  
업로드/다운로드하려 하는 상황입니다  
그러면 S3 버킷이 API 를 호출하고  
키를 생성하거나 KMS 키로 해독해  
그로부터 결과를 가지고 옵니다  
그래서 KMS 는 기본적으로  
초당 요청에 대한 할당량을 가지고 있죠  
리전에 따라 요청이 초당 5,500개 또는 10,000개 30,000개일 수도 있습니다    
이보다 `많은 양이 필요한 경우에는 서비스 할당량 콘솔을 통해 할댱량 증가를 요청`할 수 있습니다    
즉, 초당 10,000개 이상의 요청이  
초당 5,500개의 요청을 지원하는 특정 리전에 발생하면  
요청이 지나치게 몰리게 되겠죠  
그러므로 KMS가 S3의 성능을 방해하지 않게끔 주의해야겠죠  
이러한 할당량은 일반적인 사용량에 비하면 넉넉하지만  
파일이 아주 많을 때나 S3 버킷을 많이 쓸 때를 대비해 알아 두면 좋겠죠

이제 S3 성능을 살펴봅시다  
`최적화를 위한 첫 번째 방법은 분할 업로드`입니다  
100MB가 넘는 파일은 분할 업로드가 권장되며  
`5GB가 넘는다면 분할 업로드가 필수`입니다  
`분할 업로드는 병렬화를 통해 전송 속도를 높이고 대역폭을 극대화`합니다  
도면으로 보는 게 이해에 항상 도움이 되죠  
Amazon S3에 업로드하고자 하는 큰 파일이 있습니다  
이 파일을 작은 덩어리의 여러 파트로 나눠서  
각 파일을 Amazon S3에 병렬로 업로드합니다  
Amazon S3에서는 모든 파트가 업로드되면  
이들을 다시 모아 큰 파일로 합쳐 주는 겁니다  
아주 중요하죠 S3 Transfer Acceleration 은  
업로드와 다운로드를 위한 건데요  
파일을 `AWS의 엣지 로케이션`으로  
파일을 전송함으로써 전송 속도를 높입니다  
엣지 로케이션에서는 데이터를 대상 리전의 S3 버킷으로 보내 주죠  
리전보다 엣지 로케이션의 수가 더 많은데요  
200개가 넘고 계속 늘고 있죠  
그래프를 보면서 함께 살펴볼 겁니다  
Transfer Acceleration 은 분할 업로드와 호환됩니다

예시를 보시면 파일이 미국에 있는 상태에서  
호주에 있는 S3 버킷에 이 파일을 업로드하려 합니다  
이럴 때에는 파일을 미국에 있는  
엣지 로케이션에 업로드하는 겁니다  
공용 인터넷을 사용해 아주 빠르게 처리합니다  
그러면 해당 엣지 로케이션에서 호주의 Amazon S3 버킷으로  
고속 사설 AWS 네트워크를 통해 파일이 전송됩니다  
Transfer Acceleration이라고 불리는 이유는  
공용 인터넷을 최소한으로 거치면서  
사설 AWS 네트워크의 사용을 최대화하기 때문이죠    
`Transfer Acceleration 를 사용하면 전송 속도를 높일 수 있습니다`  

그렇다면 파일을 받는 경우에는 어떨까요?  
파일을 가장 효율적으로 읽는 법은 뭘까요?  
`S3 바이트 범위 가져오기라는 방법`이 있습니다  
`파일의 특정 바이트 범위를 얻어 GET 를 마비시키는 방식`이죠  
바이트 범위를 얻는 데 실패한 경우에도  
작은 바이트 범위를 얻는 작업을  
다시 시도함으로써 실패에 대한 복원성을 가지게 되므로  
이 방식은 다운로드의 속도를 높이는 데에 사용되죠

예를 들어 S3에 아주 큰 파일이 있는데  
파일의 첫 몇 바이트에 해당하는 파트를 요청한다고 합시다  
그리고 두 번째 파트에 이어 마지막 파트까지가 있겠죠  
이 모든 파트들을 특정 바이트 범위 가져오기로 요청할 겁니다  
바이트 범위라고 불리는 건 파일의 특정 범위만을  
요청할 것이기 때문이죠 그리고 이 요청은 전부  
병렬적으로 이루어집니다 즉, GET를  
`병렬화해서 다운로드를 가속화`시키는 원리인 거죠  

두 번째 사용 사례는 파일의 일부를 회수하는 경우로  
만약 S3에 있는 파일의 첫 50바이트가  
파일에 대한 정보를 제공하는  
헤더라는 사실을 알고 있다면 헤더 요청을 바로 보낼 수 있겠죠  
헤더에 해당하는 첫 50바이트를 바이트 범위 요청으로  
전송함으로써 해당 정보를 빠르게 얻을 수 있을 겁니다  

## S3 & Glacier Select

적은 데이터, 즉 요청한 데이터의 하위 세트를  
SQL을 통해 서버 측 필터링을 수행하여  
회수하려 하는 겁니다  
SQL의 쿼리는 꽤 간단하죠  
행과 열로 필터링하는 데에만 사용되며  
SQL 명령문은 굉장히 간단합니다  
집계 등의 기능은 수행할 수 없고요  
전체 파일을 회수하는 게 아니라서 클라이언트 측에서는  
네트워크와 CPU 비용이 절감되며
S3가 선택과 필터링을 해서  
필요한 것만을 전달합니다  
기존에는 Amazon S3에서 모든 데이터를  
애플리케이션으로 전송한 후 애플리케이션 측에서  
필터링을 한 뒤 원하는 행을 찾아내고  
필요한 열만 남기는 방식이었다면  

이후에 `S3 Select 를 사용해 데이터를 요청`함으로써  
`필요한 데이터만`을 받을 수 있는 거죠  
필요한 행과 열만을 제공받음으로써  
Amazon 에 따르면 400% 빠르고  
80%까지 저렴하다는 결과를 얻을 수 있죠  
`네트워크를 거치는 트래픽의 양이 적고`
`필터링이 서버 측`에서 일어나기 때문입니다  

클라이언트가 S3 Select를 통해  
CSV 파일에서 일부 행과 열을 요청하고 있습니다  
Amazon S3는 서버 측에서  
CSV 파일을 필터링해 원하는 행과 열을 찾고  
클라이언트에게 필터링 된 데이터를 회신합니다  
확실히 네트워크와 CPU 사용량이 줄고 속도가 빨라지죠  
아주 좋습니다 시험을 대비해 정리하자면  
S3에서의 서버 측 데이터 필터링을  
줄이려면 S3 Select와 Glacier Select를 떠올리세요  
Glacier에서도 작동하는 기능입니다 쿼리가 좀 더 복잡한 경우  
S3에서 무서버로 처리되는데 이후의 강의에서 다룰 Amazon Athena 죠

## S3 이벤트 알림

일부 이벤트는 S3 버킷 내에서 발생합니다  
예를 들어, 새로운 객체가 생성된 걸 수도 있고  
객체가 제거되거나 복원됐을 수도 있고  
S3 복제가 일어난 것일 수도 있죠  
이 모든 `이벤트들에 리액트 알림 하고자` 한다고 해봅시다  
`규칙을 생성할 수도 있는데 객체 이름에 따라 필터링하는 규칙을 만들 수도 있죠`    
jpeg 파일에만 리액트하려면 *.jpg가 되는 거고요  
이렇게 `이벤트 알림 규칙도 생성`할 수 있는데  
이 규칙을 통해 AWS 계정 안에 일종의 혁신을 일으킬 수도 있죠

전형적인 사용 사례로는  
Amazon S3에 업로드된 사진의 썸네일을 생성하는 겁니다  
S3 이벤트 알림으로 가능한 대상에는 뭐가 있을까요?  
세 가지가 있는데요 알림과 이메일을 보내는  
간단 알림 서비스인 SNS와 메시지를 대기열에 추가해 주는  
간단한 큐 서비스인 SQS가 있고  
마지막으로 커스텀 코드를 생성하는 람다 함수가 있습니다
S3 이벤트는 원하는 개수만큼 생성이 가능합니다  
대부분의 경우 몇 초 안에 전달이 되지만  
가끔 1분 이상 소요될 때도 있습니다  
그리고 주의할 점이 하나 있는데요 모든 이벤트에 대한 알림이  
전달되도록 하기 위해서는  
버킷의 버저닝을 활성화하셔야 합니다  
이 긴 두 문장이 설명하고 있는 내용이죠  
문서에서 가져온 내용입니다

## Amazon Athena

아테나에 데이터가 저장되어 있는 S3를 설정해두고, 테이블 생성후, 쿼리를 실행하면 -> 데이터를 가져올 수 있다

Amazon Athena 는 아마존 S3에 저장된  
`객체에 대해 분석을 수행하는 서버리스 쿼리 서비스`입니다  
즉, `SQL 언어로 이러한 파일들을 쿼리하지만 로드할 필요는 없는` 겁니다    
파일들은 S3에 있고 나머지는 Athena가 알아서 해주죠  
이러한 파일의 포맷은  
`CSV, JSON, ORC, Avro, Parquet 등` 다양합니다  
그리고 Athena는 `Presto 엔진 기반`이죠  
사용자들이 데이터들을 아마존 S3에 로드하면  
Amazon Athena는 이러한 데이터를 쿼리하고 분석합니다  
아주 간단하죠 원하시는 경우 Athena 와 더불어  
Amazon QuickSight 와 같은  
보고도 받아 볼 수 있습니다  
Athena의 가격은 스캔된 `데이터 TB당 5달러`입니다  
`압축되거나 컬럼형으로 저장된 데이터`를 사용할 경우  
비용을 절감할 수 있죠  
데이터를 `스캔하는 양이 적어지기 때문`입니다  
Athena는 다양한 경우에 사용되는데요  
`비즈니스 인텔리전스 분석, 보고 VPC나 ELB 로그의 Flow Logs 분석`  
`CloudTrail 로그, 플랫폼 로그 등의 AWS의 로그`를 사용할 경우   
Athena가 아주 유용하죠  
`시험에서 SQL 사용, 데이터 분석 서버리스 등의 키워드`가 나오면  
Amazon Athena를 생각해 보시면 됩니다  

https://aws.amazon.com/ko/premiumsupport/knowledge-center/analyze-logs-athena/

# CloudFront

클라우드 프론트는 `컨텐츠 전달 네트워크, 즉 CDN 으로 판독 능력을 향상`시키는데요  
컨텐츠가 `엣지 로케이션에서 분배 및 캐시가 되기 때문`입니다  
지금 전 세계적으로 216개의 엣지 로케이션이 존재하며  
지속적으로 새로운 지점이 추가되고 있죠  
AWS 내의 리전은 약 30개로 리전보다 훨씬 더 많으며  
전 세계에 펴져 있습니다  
클라우트 프론트는 엣지에서의 캐싱 외에  
`DDoS 보호도 제공`하는데요  
서비스 거부를 배포하는 이러한 공격으로부터  
보호막과 웹 애플리케이션 방화벽을 제공하죠  

그리고 인증서를 로드하여 외부 HTTPS 엔드 포인트를  
노출하고 해당 `트래픽을 암호화해야 하는 경우 내부 HTTPS에서 애플리케이션에 내부적으로 통신`하게끔 해줍니다

## CloudFront 캐싱 및 캐싱 무효화

헤더 값, 세션 쿠키 쿼리 문자열 파라미터 등  
`클라우드 프론트 내의 다양한 것들을 기반으로 캐시가 가능`한데요  
모든 캐시는 엣지 로케이션에 저장됩니다

클라이언트가 클라우드 프론트 엣지 로케이션에 요청을 보내고 있습니다  
그럼 헤더 값, 쿠키 및 캐시 문자열 파라미터를 기반으로 해서 캐시가 확인됩니다   
그리고 캐시는 `캐시 내의 타임 투 리브(TTL)를 기반으로 만료`가 되는데요  
`캐시에 값이 없는 경우에는 쿼리 또는 전체 HTTP 요청이 오리진으로 직접 전달`되며  
그 후 캐시가 쿼리 회신으로 채워지게 됩니다

따라서 `클라우드 프론트의 역할은 캐시 히트를 늘려서 오리진에서의 요청 수를 최소화`하는 겁니다  
`캐시 히트란 캐시에서 바로 제공되는 요청의 수`를 의미하죠  
이를 위해서는 캐시 내의 `TTL을 0초에서 1년 사이로 조정`할 수 있으며  
캐시 제어 헤더나 만료 헤더 등의  
몇 가지 헤더를 통해 이를 제어할 수 있죠  

이 방식의 장점은 `CreateInvalidation API 를 사용해 캐시의 일부를 무효화`할 수 있다는 겁니다  
캐시 히트를 늘린다는 것은 어떤 의미일까요?  
`클라우드 프론트는 정적 및 동적 분배를 구별`하는 데 뛰어납니다

즉 정적 요청은 클라우드 프론트를 통해   
정적 콘텐츠 홀더로 가게 되고  
`정적 콘텐츠 홀더는 보통 S3 버킷`이죠  
이 말인즉슨 이러한 요청이 있을 때  
적용되어야 할 헤더나 세션 캐싱 규칙은 없으며  
모든 정적 콘텐츠는 클라우드 프론트에 캐시되어  
캐시 히트가 최대화하게 됩니다

반면 동적 콘텐츠의 경우에는  
`클라우드 프론트를 통해 다른 분산`으로 가게 되는데요  
하지만 이때는 `애플리케이션 로드 밸런서나 EC2 인스턴스와 같은 HTTP 서버`로 전달이 됩니다  
헤더와 쿠키 값을 기반으로  
어떻게 캐시할지를 고려할 때에  
좀 더 주의를 기울여야겠죠  
이렇게 클라우드 프론트에서 캐시를  
동적 요청과 정적 요청으로 구별하는 것은  
흔히 사용되는 전략입니다

## CloudFront 보안

지리적 위치를 기반의 분산으로의 액세스    
허용 여부를 제한하는 방식이었습니다    
화이트리스트나 블랙리스트를 설정할 수 있고    
어떤 국가가 클라우드 프론트 분산에  
허용, 또는 거부되는지를 정의하는 방법이었죠  
그리고 이러한 국가의 식별에는  
IP에 국가가 매핑된 제3자 회사의 지리적 IP  
데이터베이스를 사용합니다  
지리적 제한을 사용하는 경우는  
콘텐츠로의 액세스 허용을 제어하는 저작권법 등의 예가 있었죠

클라우드 프론트에 보안을 활성화하는 두 번째 방법으로는 HTTPS가 있습니다  

첫 번째는 `HTTP 에서 HTTPS 로 리다이렉팅`하는 것이고  
아니면 `HTTPS 만 사용하는 것도 가능`합니다  
이 설정 중 하나를 사용하면  
`클라우드 프론트로 가는 트래픽은 암호화`되어야 합니다    
실무에서 사용을 하는 경우에는  
HTTP에서 HTTPS로 리다이렉팅하는 옵션을 추천드리고 싶은데요  
모든 단일 클라이언트가 실패할 일이 없게끔 하기 위해서죠

그리고 `오리진 프로토콜 정책`이 있습니다  
오리진은 HTTP 오리진일 수도 있고 S3 버킷일 수도 있습니다  
그리고 이 오리진 프로토콜 정책의 옵션으로는 
`HTTPS만 가능한 옵션과 뷰어 맞춤 옵션`이 있습니다  
즉, 클라이언트가 HTTP를 요청한 경우에는  
프로토콜 정책은 HTTP가 될 것이고  
HTTPS를 요청한 경우에는 정책이 HTTPS에 맞춰지는 거죠    
이름에서 알 수 있듯이 뷰어 맞춤 형식입니다  
하지만 뷰어의 프로토콜 정책이 HTTPS만 사용, 혹은  
HTTP를 HTTPS로 리다이렉팅하도록 설정했다면  
뷰어 맞춤 또한 당연히  
HTTPS로 맞춰질 겁니다  
따라서 `두 가지 정책인 뷰어 프로토콜 및 오리진 프로토콜 정책을 이용해  
HTTPS가 클라이언트와 엣지 로케이션 사이, 그리고 엣지 로케이션과 오리진 사이에서  
실행되는 방식을 결정`할 수 있습니다  

참고로 웹사이트 옵션을 활성화해서
`S3 버킷 웹사이트`를 사용하는 경우에는
오리진은 `HTTP 만 지원`하며 HTTPS는 지원하지 않습니다 알아 두시면 좋겠죠

## CloudFront 서명 URL/쿠키

클라우드 `프론트 분산을 비공개`로 만들기 위해서는 세계 각지의 사람들에게  
프리미엄 `유료 콘텐츠에 대한 액세스`를 주어야 하는데요   
하지만 누가, 어떤 클라우드 프론트 분산에 액세스하는지를 알기 위해서  
클라우드 프론트 `서명된 URL이나 쿠키`를 사용할 수 있습니다

URL 과 쿠키를 생성할 때에는  
정책을 연결해 해당 URL 이나 쿠키가  
`언제 만료되는지 이 데이터에 액세스할 수 있는 IP 범위는 어디인지`를 지정해야 합니다  
만약 클라이언트의 대상 IP를 알 경우에 사용이 가능하겠죠  
그리고 어떤 AWS 계정이 서명된 URL 을 생성할 수 있는지를 의미하는 신뢰할 수 있는 서명자도 지정해야 하죠  
그럼 URL 은 얼마나 오래 유효해야 하는 걸까요?  
영화나 음악과 같은 콘텐츠를 공유할 때는  
몇 분 정도로 짧아도 될 겁니다  
하지만 해당 사용자가 `장기간 액세스할 수 있어야 하는 비공개 콘텐츠`의 경우에는  
`URL 이나 서명된 쿠키가 수 년간 지속`되게 할 수도 있습니다

그럼 URL 과 쿠키의 차이는 무엇일까요?  
`서명된 URL은 개별 파일에 대한 액세스`를 줍니다  
`파일별로 하나의 URL` 이 있는 거죠  
파일이 백 개면 백 개의 URL이 있습니다  
서명된 쿠키로는 다수의 파일에 액세스를 주고  
해당 쿠키는 재사용이 가능합니다  
즉 `다수의 파일에 서명된 쿠키는 하나`인 거죠  
따라서 상황에 따라 적절히 선택하면 됩니다  

클라우드 프론트 분산이 있고 여러 개의 엣지 로케이션이 있습니다  
그리고 예를 들어 보안을 위해  
오리진 액세스 신분(OAI)을 이용해 S3 버킷에 액세스한다고 합시다  
즉 오직 클라우드 프론트를 이용해서만  
S3 버킷 내의 객체에 액세스할 수 있는 거죠  
하지만 여전히 클라우드 프론트를 통해 사람들에게  
객체에 대한 액세스를 제공하고자 합니다  
즉 클라이언트는 애플리케이션으로  
허가 및 승인을 보낼 것이며  
우리는 애플리케이션을 코딩해야겠죠    
그리고 애플리케이션은 `AWS SDK를 사용해 클라우드 프론트로부터 직접 서명된 URL을 생성`합니다    
서명된 URL은 클라이언트에게 반환될 것이고  
그럼 클라이언트는 이 서명된 URL을 이용해  
데이터와 파일과 객체 등 클라우드 프론트에서  
원하는 것을 직접 얻을 수 있게 됩니다  
서명된 URL뿐 아니라 서명된 쿠키도 방식은 동일합니다  
그러면 서명된 URL과 서명된 쿠키 중 어느 것을 사용해야 할까요?   
이 둘은 용도가 다릅니다 
클라우드 프론트 서명된 `URL 은 오리진에 상관 없이 경로`에 대한  
액세스를 허용하기 때문에 서명된 URL 은 S3 오리진뿐만 아니라  
원하시는 모든 HTTP 백엔드 오리진에 작동합니다  
이는 계정 내 키 페어이기 때문에 루트만 관리할 수 있고  
IP, 경로, 날짜, 만료 등으로 필터링할 수 있으며  
클라우드 프론트에 있는 모든 캐싱 기능을 활용할 수 있습니다  
클라우드 프론트 분산에 서명된 URL을 사용하는 클라이언트가 있고  
클라우드 프론트 분산은 오리진인 EC2 인스턴스로 통신을 보냅니다  
이런 방식으로 작동하는 거죠  

반면 S3 미리 서명된 URL은 URL에 미리 서명한  
사람으로서 요청을 발행합니다  
따라서 제가 저만의 IAM 원칙으로  
URL에 서명하고 서명을 위해 제 IAM 키를  
사용하게 되면 해당 URL을 가진 사람은  
저와 같은 권한을 가지게 됩니다  
수명이 제한적이죠 이 미리 서명된 URL을 사용해  
클라이언트가 직접 S3 버킷에 액세스할 수 있습니다  
만약 사람들이 여러분의 클라우드 프론트 분산에  
액세스하길 원하고 S3 앞에 있는 경우라면  
의도한 대로 S3 버킷에 액세스할 수 없으므로  
서명된 URL을 사용해야만 합니다  
이를 OAI로 제한하는 버킷 정책 때문이죠  
하지만 클라우드 프론트를 사용하지 않고  
사용자들이 직접 S3 버킷으로  
액세스해 파일을 사용하길 원하시면 미리 서명된 URL이 적합할 겁니다  

## CloudFront 서명된 URL - 키 그룹 + 실습

`API를 활용하여 이러한 키를 생성`하고 순환하게 할 수 있으며  
키 그룹 및 API 키의 관리를 위한  
`API 보안에 IAM을 활용`할 수 있죠 공용 키가 이 그룹에 속합니다

또 다른 방법은 최초이자 기존에 지원되었던 방법인데  
`클라우드 프론트 키 페어를 보유한 계정을 사용`하는 것이죠  
하지만 이 방법을 통한 키 관리에는 루트 계정 자격 증명이 필요하며  
AWS 콘솔도 사용을 해야 하는데 이 방법은 권장되지 않습니다  
이를 위해 루트 계정을 사용해선 안 되기 때문이죠  
또한 이 클라우드 프론트 키 페어를 관리할 API가 없기 때문에  
`자동화 또한 완전 불가능`하죠  
따라서 현재는 신뢰할 수 있는 `키 그룹의 사용이 권장`됩니다  
클라우트 프론트 분산에는 하나, 혹은 그 이상의  
신뢰할 수 있는 키 그룹 생성이 가능하며,  
공용 키와 개인 키를 생성할 수 있죠    
`개인 키`는 여러분의 애플리케이션에서  
`EC2 인스턴스가 URL에 서명하려는 경우 등에 사용`되죠  
반면 `클라우드 프론트가 업로드하는 공용 키`는  
`이러한 URL의 서명을 검증하는 데에 사용`됩니다  

Key 생성 사이트 주소  
https://travistidwell.com/jsencrypt/demo/  

혹은 ssh-keygen 명령어로 생성

## CloudFront 고급 개념

클라우드 `프론트 엣지 로케이션이 전 세계에 퍼져` 있다는 건 이미 알고 계시죠  
하지만 전 세계에 걸쳐 존재하기에 `엣지 로케이션에 따른 데이터 전송 비용도 다를 겁니다`

보시다시피 엣지 로케이션이 위치한 `대륙 또는 지리적 위치에 따라 요금이 달라집니다`  
멕시코 및 `미국, 캐나다의 경우 첫 10TB에 대한 요금은 1GB당 0.085달러`입니다  

하지만 `인도`에 있는 동일한 엣지 로케이션의 경우 `비용이 두 배`로  
전송된 데이터 `1GB당 0.17달러`를 지불하는 식입니다  
클라우드 프론트에서 더 많은 데이터가 전송될수록 요금은 낮아지므로  
만약 클라우드 프론트에서 5PB의 데이터를 전송하는 경우에  
미국의 경우에는 0.02달러만 지불하면 되는 거죠

전 세계에 걸쳐 클라우드 프론트 분산에 사용할  
`엣지 로케이션의 수를 줄여 가격을 낮출` 수 있습니다

가격 등급은 총 세 가지입니다  
`Price Class All 의 경우에는 모든 지역을 제공`하며  
당연히 최상의 성능을 보이지만  
비용이 다소 높습니다  
예를 들어
인도의 엣지 로케이션의 요금이  
미국의 엣지 로케이션보다 더 높은 것과 같은 이치죠  

`Price Class 200` 도 있는데요  
`가장 비싼 지역을 제외`한  
대부분의 지역을 제공해 줍니다  

`Price Class 100`은  
`가장 저렴한 지역`만을 제공하죠

전 세계에 굉장히 많은 엣지 로케이션이 있는데요
`Price Class 100`의 경우
`미국, 북미 및 유럽`을 제공하고

`Price Class All` 로는
`전 세계의 엣지 로케이션`을 이용할 수 있습니다  

이번에는 클라우드 프론트의 `다중 오리진과 오리진 그룹`을 살펴봅시다  
예를 들어, `콘텐츠의 유형이나 경로`에 따라  
클라우드 프론트를 거치는 `라우트나 경로`를  
`리다이렉팅해 다른 오리진으로 라우팅`하고 싶어질 수도 있습니다    
예를 들어, `이미지용 경로나 API 용 경로 또는 그 외의 모든 경로`가 있다고 한다면  
어느 경로건 `클라우드 프론트에서는 정해진 경로`를 통해 다양한  
캐시 작업을 설정할 수 있습니다  
예를 들어 API/* 경로를 사용 중인 경우  
애플리케이션 로드 밸런서가 되는 오리진으로부터의  
회신이 필요하다고 할 수 있습니다  
하지만 그 외의 모든 경로(/*)를 요청할 경우  
/*가 변함 없는 콘텐츠라면  
해당 콘텐츠를 S3 버킷에서 가져와야 할 겁니다  
이런 식으로  
Amazon 클라우드 프론트에서 사용되는  
경로를 기반으로 다중 오리진이 정의됩니다  

마찬가지로 `오리진 그룹`을 설정할 수도 있는데  
이 경우에는 용례가 다릅니다
`고가용성을 증가`시키고 한 `오리진에서 장애가 발생한 경우 장애 조치가 가능`하게 해주죠  
따라서 오리진 그룹은 `하나의 주 오리진과 하나의 보조 오리진`으로 구성됩니다  
만약 주 오리진에 장애가 발생하면  
클라우드 프론트가 보조 오리진으 사용하는 것으로  
대체를 하게 되는 거죠  
예시로 살펴봅시다 클라우드 프론트가 있고  
두 개의 EC2 인스턴스로 구성된 오리진 그룹이 있는데요  
첫 번째 인스턴스가 주 오리진  
두 번째 인스턴스가 보조 오리진이 됩니다  
그럼 Amazon 클라우드 프론트가  
첫 EC2 인스턴스로 요청을 보내고  
그리고 이 EC2 인스턴스로부터 에러가 돌아올 경우  
Amazon 클라우드 프론트는 동일한 요청을 B 오리진으로 다시 보낼 겁니다  
그러면 이 인스턴스는 okay 상태 코드로  
회신을 하는 식이죠  
이런 식으로 대체 작동이 가능합니다  
이를 Amazon S3와 함께 사용할 수도 있죠  
이 예시의 경우  
만약 S3와 클라우드 프론트를 오리진 그룹과 함께 사용한다면  
`지역 단위의 고가용성과 재해 복구`가 가능하게 됩니다

한 번 살펴보죠  
두 개의 S3 버킷으로 구성된 오리진 그룹이 있습니다  
첫 S3 버킷이 주 오리진이 되고  
두 번째 S3 버킷은 보조 오리진이 되겠죠  
만약 이 S3 버킷들이 다른 지역에 있을 경우  
이 버킷들 사이에 복제를 설정할 수 있습니다  
따라서 A 오리진의 모든 콘텐츠가  
B 오리진으로 복제되는 거죠  
만약 Amazon 클라우드 프론트가 요청을 보냈는데  
지역 단위의 정전 등의 이유로 인해  
첫 `S3 버킷에서 오류 회신을 받았다면클라우드 프론트는 동일한 요청을 다른 지역의 다른 S3 버킷으로 보낼 것`이고    
이 버킷은 복제 덕분에 첫 번째 버킷이  
가지고 있던 모든 데이터를 갖고 있겠죠  
따라서 이 S3은 okay 상태 메시지로  
회신을 보낼 겁니다  
이런 방식으로 `Amazon 클라우드 프론트와 S3 버킷에 대한 지역 단위 재해의 복구가 가능한 훌륭한 구조`를 구축할 수 있는 거죠

마지막으로 `필드 수준의 암호화`에 대해 살펴봅시다  
이는 애플리케이션 스택을 통해 민감한 정보를 보호하는 기능으로  
`HTTPS를 사용하는 인플라이트 암호화`와 더불어  
추가적인 보안을 더해 줍니다  
즉, `사용자가 민감한 정보를 전송할 때마다 엣지 로케이션이 이를 암호화`하고    
개인 키에 대한 `권한을 지닌 사용자만이 이 정보를 해독`할 수 있도록 하는 개념입니다  
따라서 이 기능은 비대칭 암호화를 사용하겠죠  
그럼 작동 원리는 뭘까요?  
Amazon 클라우드 프론트로 보내는 POST 요청의 경우  
`암호화를 원하는 필드를 최대 10개`까지 지정할 수 있습니다    
신용 카드 등을 예로 들 수 있겠죠  
그리고 이 필드를 해독할  
공용 키도 함께 지정됩니다  
예시를 한 번 살펴보죠  
HTTPS를 엣지 로케이션으로 전달하는 클라이언트가 있다고 가정합시다  
그럼 엣지 로케이션은  
다시 HTTPS를 통해 클라우드 프론트로 전달하고  
이는 애플리케이션 로드 밸런서를 통해  
HTTPS를 사용해 오리진까지 전달될 겁니다  
그 다음에는 모든 데이터가 HTTPS를 통해  
웹 서버로 전달되겠죠  
전송 과정에서 모든 정보는 암호화되어 있으나, 
우리는 필드 수준의 암호화를 설정하려 합니다  
예를 들어 한 사용자가  
우리에게 신용 카드 정보를 전달한다고 가정하겠습니다  
현재 주황색으로 표시된 정보입니다  
그리고 우리가 이 신용카드 정보에 대한  
필드 수준 암호화를 지정하려 하면  
엣지 로케이션이 공용 키를 이용해  
이 필드를 암호화하는 거죠  
그럼 엣지 로케이션을 지나 Amazon 클라우드 프론트  
그리고 `오리진으로 전달되는 데이터의 신용카드 정보는 공용키를 이용해 암호화`가 되어 있을 겁니다  
그렇게 암호화된 정보가 웹 서버까지 전해지겠죠    
`데이터가 도착하면 웹 서버는 개인 키에 대한 권한을 갖게 될 것이며  개인 키를 사용해 이 암호화된 단위를 해독`하여  
신용카드 번호를 얻게 될 겁니다  
스택 전반에 걸쳐 확인할 수 있듯  
`클라우드 프론트 지역과 애플리케이션 로드 밸런서는 이 필드를 해독할 수 없습니다`    
오직 웹 서버만이 필드를 해독할 수 있는  
커스텀 애플리케이션 논리를 가지고 있죠  

# ECS, ECR 및 Fargate-AWS 도커 (주의)

## ECS

EC2 인스턴스의 `논리적 그룹화를 의미하는 용어`로  
이런 클러스터를 바탕으로 서비스와 태스크를 운영합니다  
하지만 당장은 EC2 인스턴스를 그룹화한 것이라고만 알아 두세요  
우리가 실행하려 하는 EC2 인스턴스의 경우  
`ECS 에이전트라는 것을 실행`하게 됩니다  
ECS 에이전트는 그냥 `Docker 컨테이너`죠  
`ECS 에이전트는 EC2 인스턴스를 ECS 클러스터에 등록해 주는데 그게 EC2 에이전트의 역할`이죠  

EC2 인스턴스는 조금 특별한데  
평범한 Amazon Linux 2 AMI를 실행하는 게 아니라  
특수한 ECS AMI를 실행합니다  
EC2 인스턴스가 있고 ECM Docker 에이전트를 실행 중입니다  
이 에이전트들이 인스턴스를
ECS cluster에 등록합니다 아주 간단하죠  

## 태스크 정의

https://yoo11052.tistory.com/141

ECS 는 `AWS 에서 도커 컨테이너를 실행`할 때 사용하며 종류가 3개 있습니다

ECS Classic 은 EC2 인스턴스를  
`프로비저닝하여 EC2 인스턴스에서 컨테이너를 실행`할 수 있게 합니다  
그러나 인프라를 자체적으로 관리해야 합니다  

또는 `Fargate 를 사용할 수 있는데 이것은 ECS 에서 제공하는 서버리스로 프로비저닝이 필요 없습니다` 
EC2 인스턴스가 알아서 관리하죠

또는 EKS 가 있습니다 EKS 를 사용하는 단 하나의 경우는  
AWS 의 Managed Kubernetes 관련 질문을 볼 때입니다

다음으로 `ECS classic 에는 EC2 인스턴스가 반드시 생성`되어야 합니다    
올바른 클러스터 이름으로 된 ECS 설정 파일을 만들어야 합니다  
`EC2 인스턴스는 반드시 ECS 에이전트를 실행`해야 하며  
이는 EC2 인스턴스에 EC2 클러스터를 등록하게 해줍니다  
`EC2 인스턴스는 같은 종류의 여러 컨테이너를 실행`할 수 있습니다  
이를 위해서 호스트 포트 없이 오직 `컨테이너 포트만 지정`합니다  
호스트 포트는 동적이고 `동적 포트 매핑 기능과 함께 애플리케이션 밸런서`를 이용해서 `컨테이너로 트래픽을 유도`해야 합니다

마지막으로 EC2 인스턴스 보안 그룹은 반드시  
`ALB 로부터의 트래픽을 모든 포트에서 허용해야만 이 설정이 동작`합니다

마지막으로 보안 측면에서 `ECS 태스크는 AWS 관련 작업을 실행하기 위해 IAM 역할을 반드시 가져야만 합니다` 
즉, 여러 다른 서비스와  
태스크가 같은 EC2 인스턴스에서 실행 중인 경우  
많은 `ECS 태스크 IAM 역할을 만들어야 합니다`  
중요한 내용입니다  
보안 그룹은 인스턴스 수준에서 동작하지 태스크 수준이 아닙니다 
따라서 `보안 그룹을 연결할 때 EC2 인스턴스에 연결`해야 합니다  
ECS 태스크에 연결하면 동작하지 않죠
 
ECR 로 넘어가겠습니다 `AWS 에서 개인 도커 이미지를 저장하는 곳`으로 IAM 과 긴밀히 통합되어 있습니다  
ECR 로그인을 하는 방법에는 2개의 옵션이 있는데    
`CLI v1 login` 으로 시험에 나올 수 있습니다  
이 명령과 이 명령으로 실행해야 하며  
`aws ecr get-login` 명령은  
도커 로그인 명령을 생성하여  
해당 명령의 출력물을 실행합니다  
$ 기호와 괄호가 있는 이유입니다

`CLI v2 login` 명령은 pipe 명령을 이용하여  
`aws ecr get-login-password 명령을 실행합니다 이는 도커 로그인에 연결`합니다

도커 푸시 및 풀은  
같은 명령으로 docker push 와 docker pull 로  
전체 리포지토리(Repository) 이름을 지정하고  
도커 이미지 이름과 태그를 지정합니다  
만약 EC2 인스턴스나 여러분이  
도커 이미지를 가져오거나 주지 못한다면  
IAM 권한을 확인해야 합니다  
도커 컨테이너를 서버리스에서 실행하고 싶다면  
Fargate 를 이용할 수 있습니다 관리해야 할 EC2 인스턴스가 없고  
AWS가 자동으로 컨테이너를 프로비저닝해줍니다  
또한 일래스틱 네트워크 인터페이스,  
또는 `ENI` 를 이용하여  
설정된 컨테이너의 스펙에 따라 프로비저닝 될 것입니다  
즉,` 몇 개의 CPU 를 원하는지 컨테이너의 메모리 등을 지정하면 Fargate 가 알아서 해줄 것`입니다    
Fargate 태스크는 AWS에 대한  
작업을 실행하기 위해 IAM 역할을 가질 수 있습니다  
Fargate에서 도커 컨테이너를 실행하여  
Amazon S3에 접근하려 한다면  
S3에 접근할 수 있는 올바른 IAM 역할을 제공해야 합니다  
ECS에서 알아야 할 또 하나는  
`CloudWatch 로그와 ECS가 통합된다는 점`입니다  
태스크 정의 수준에서 로깅을 설정하여야 하며  
각 컨테이너는 다른 로그 스트림을 갖게 됩니다  
EC2 인스턴스 프로필은  
로그를 CloudWatch 로그에 보낼 수 있는 IAM 권한을 가져야 하죠  
태스크에 IAM 태스크 역할을 사용할 수 있죠  
많이 이야기했으니 이제 잘 알고 있길 바랍니다  
또한 여러 태스크 배치 전략이 있는데  
binpack, 랜덤, spread가 있었습니다  
`binpack 은 EC2 인스턴스 수를 최소화`하고  
`비용을 최소화`하기 위해 `하나의 EC2 인스턴스에서 모든 태스크를 수행`하려는 것을 의미합니다  
시험에 나올 수 있어요 `랜덤은 무작위`를 말하고, 
`spread 는  태스크를 여러 가용 영역에 분산시킬 경우에 사용`합니다

서비스 오토 스케일링에는 세 가지 방법이 있습니다
대상 추적, 단계 스케일링, 스케줄입니다
EC2 Auto Scaling에서 본
옵션과 유사합니다
서비스 오토 스케일링을 하는 것은
클러스터가 커지는 것을 반드시 의미하지 않습니다
이를 위해서는 Capacity Provider를 사용한
클러스터 오토 스케일링이 있습니다 실습에서 진행했습니다
시험에서 알아야 할 ECS 내용은 이것이 전부입니다

# 일래스틱 Beanstalk

지금까지 애플리케이션을 배포해 보았습니다
같은 아키텍처를 사용했는데
로드 밸런서가 사용자로부터 요청을 받아 처리하고
여러 가용 영역이 있는 오토 스케일링 그룹이 있습니다
각 AZ 에는 EC2 인스턴스가 배포되어 있습니다
백엔드에는 데이터 서브넷이 있는데
RDS 데이터베이스가 있고 읽기와 쓰기를 합니다
라우팅 복제본이 있을 수도 있죠
캐싱층이 필요하다면
일래스티 캐시를 살펴봐야 합니다
배포할 수 있는 애플리케이션이 많고 모두 같은 구조를 따릅니다
매번 새로 만들려면 힘들 거예요
개발자에게 인프라를 관리하고 코드를 배포하는 것이 복잡하겠죠
데이터베이스와 로드 밸런서 등등을 모두 구성하고 싶지 않습니다
물론 모든 것은 확장 가능해야 합니다
보이는 것처럼 대부분의 웹 애플리케이션의 아키텍처는 같습니다
로드 밸런서가 있고 오토 스케일링 그룹이 있죠
개발자로서 코드를 실행하고 싶을 거예요
다른 것을 걱정하고 싶진 않죠
따라서 다른 프로그래밍 언어로 개발하여
`애플리케이션과 환경이 다르더라도 애플리케이션을 배포하는 방법은 하나이길 바랄 것`입니다

Beanstalk 이 필요한 이유입니다
Beanstalk 은 AWS 에서 애플리케이션 배포에 관한
개발자 중심의 관점으로
기본적으로 `단일 인터페이스에서 EC2, ASG, ELB, RDS 와 같이 이전에 본 모든 요소를 재사용할 수 있게 만들어줍니다`
이 모든 것은 여러분을 위해 배포하는 `관리형 서비스`입니다
`용량 프로비저닝을 처리하고, 구성, 로드 밸런서, 스케일링, 애플리케이션, 상태 모니터링, 인스턴스 구성 등등을 처리`합니다  
여러분이 `개발자로서 책임져야 할 일은 코드`뿐입니다  
각 요소의 구성을 완전히 제어할 수 있지만
Beanstalk 이라는 하나의 인터페이스로 제공됩니다
또한 `Beanstalk 은 애플리케이션 업데이트`에도 좋습니다
`Beanstalk 서비스 그 자체는 무료`이나  
`Beanstalk 또는 ASG, ELB 등에서 사용하는 인스턴스에 대해서 비용을 지불`해야 합니다

Beanstalk의 구성 요소에는 애플리케이션이 있습니다
Beanstalk 요소의 집합으로 `환경, 버전, 구성`이 있습니다
애플리케이션의 버전은 애플리케이션 코드의 반복으로
버전 1, 버전 2, 버전 3 등등을 가질 수 있습니다
`환경은 특정 애플리케이션 버전에서 실행되는 리소스`입니다
하나의 애플리케이션 버전에
하나의 환경이 있습니다
해당 환경에서 애플리케이션을 버전 1에서 버전 2로
업데이트할 수 있는데 티어가 있습니다
Beanstalk에는 2개의 다른 티어가 있습니다
`웹 서버 환경 티어와 작업자 환경 티어`가 있습니다 곧 보게 될 거예요
Beanstalk에서 여러 환경을 만들 수 있는데
`개발자용, 테스트용, 프로덕션용 등 생각할 수 있는 환경 다 가능`합니다
프로세스는 먼저 애플리케이션을 만들고
버전을 업로드합니다 환경을 실행하고
그리고 환경의 수명 주기를 관리합니다
반복하기 원한다면 새 버전을 업로드하여 업데이트하고
해당 버전을 환경에 배포하여
애플리케이션 스택을 업데이트합니다
Beanstalk은 많은 프로그래밍 언어를 지원합니다
Go, Java SE, Java Tomcat, Linux용 .NET Core,
Windows용 .NET , Node.js, PHP,
Python, Ruby, Packer Builder, 단일 도커 컨테이너,
다중 도커 컨테이너, 사전 구성된 도커 등이 있습니다
여러분의 `언어가 여기 없다면 고급 사용자 정의 플랫폼을 직접 만들 수 있습니다`
Beanstalk을 이용하면 기본적으로 어떤 것이든 배포할 수 있습니다

마치기 전에 서버 티어와 작업자 티어가 무슨 뜻일까요?
웹 티어의 모습은 다음과 같습니다
전통적인 아키텍처입니다
로드 밸런서가 있고 웹 서버가 될 여러 EC2 인스턴스가 있는
오토 스케일링 그룹에 트래픽을 보냅니다
Beanstalk에 있는 첫 번째 아키텍처입니다
두 번째 아키텍처는 작업자 환경입니다
이번에는 EC2 인스턴스에
직접 접근하는 클라이언트가 없습니다 메시지 대기열인
SQS 대기열(SQS Queue)을 사용해서 메시지를 SQS 대기열에 보냅니다
EC2 인스턴스는 작업자에게 가는데
SQS 대기열로부터 메시지를 가져와서 처리하기 때문입니다
이 경우, 작업자 환경은 SQS 메시지의 숫자에 따라
크기를 조정합니다 즉, 메시지가 많을수록 EC2 인스턴스도 많습니다
좋은 점은
웹 환경에서 일부 메시지를 작업자 환경의 SQS 대기열에
푸시하여 웹 환경과 작업자 환경을 같이 배치할 수 있다는 것입니다
Beanstalk 개요였습니다

## Beanstalk 배포 모드

시험에서는 일래스틱 Beanstalk에서 특정 상황에서  
어떤 배포 모드가 더 나은지 고르는 것이 출제됩니다  
그래서 일래스틱 Beanstalk 배포의 모든 옵션을 이해해야 합니다  
꼭 알아야 이런 질문을 바로 맞출 수 있기 때문입니다

우리는 개발에 매우 도움이 되는  
`단일 인스턴스 배포`를 살펴봤습니다    
하나의 일래스틱 IP와 오토스케일링 그룹으로  
하나의 EC2 인스턴스를 얻으며  
데이터베이스와 통신할 수도 있고 모두 하나의 AZ에 있었습니다  
그래서 `추론하기 쉬우며 DNS 이름이 일래스틱 IP와 바로 매핑`됩니다  

두 번째 설정은 `로드 밸런서 혹은 로드 밸런서를 사용하지 않은 고가용성`이며  
이는 배포의 `프로덕션 유형`에 가장 적합합니다  
그래서 지금은 조금 복잡하지만  
이 아키텍처를 이전에 살펴봤습니다  
오토스케일링 그룹인 ASG를 살펴봤는데  
다양한 가용 영역 전반으로 이어질 것입니다  
그리고 `각 AZ 에서는 각각의 자체 보안 그룹이 있는 하나 또는 여러 EC2 인스턴스`를 얻습니다  
RDS와 통신할 수도 있고 하나의 마스터 혹은 하나의 대기 데이터베이스와 같은  
다중 AZ에 설정될 수도 있죠 모두 익숙한 내용이죠?  
그러면 `ELB 는 ASG 와 직접 통신하며 모든 EC2 인스턴스와 연결`하고  
ELB는 일래스틱 Beanstalk DNS 이름으로 랩핑(wrapping)될 DNS 이름을 노출합니다  

여기까지 살펴봤습니다 개발과 프로덕션이죠  
이제 원하는 대로 약간 변경할 수도 있습니다  
이제 `배포한 것을 업데이트`하려면 어떻게 해야 할까요?  
먼저, 여러분이 꼭 알아야 할 4~5개 유형의 배포 유형이 있습니다

첫 번째는 `모든 애플리케이션을 한 번에 배포하는 유형`입니다  
한 번에 배포하는 유형은 `가장 빠른 방식이지만`    
잠시 동안 `트래픽을 처리할 인스턴스가 없어서 가동중지시간이 발생`합니다  
`롤링 업데이트 방식`을 사용하면  
`한 번에 몇 개의 인스턴스가 업데이트` 되는데  
버킷이라고도 하며 `첫 번째 버킷이 정상`이면  
업데이트한 `뒤 다음 버킷`으로 넘어갑니다

그리고 조금 다른    
`추가 배치의 롤링 업데이트`가 있습니다    
롤링 업데이트와 비슷하지만 `애플리케이션이 사용 가능`하고  
늘 전체 용량을 사용할 수 있도록  
배치를 이동하기 위해 `새 인스턴스를 스핀 업`합니다

마지막은 `변경할 수 없는 배포 방식`입니다 
새 인스턴스와 ASG 를 스핀 업하면 
스핀 업 한 인스턴스에 버전 업데이트를 배포합니다  
그리고 모두 준비가 되면  
모두 정상일 경우에 전체 ASG를 교환합니다

한 번에 배포하는 것을 살펴보죠  
4개의 EC2 인스턴스가 있습니다  
그리고 모든 인스턴스는 파란색으로 표시된 애플리케이션 v1에서 실행됩니다  
이제 한 번에 배포해 보겠습니다  
v2를 배포하는 것이죠 그러면 일래스틱 Beanstalk은  
EC2 인스턴스의 애플리케이션을 중지시킵니다  
이쪽의 회색으로 표시했는데 아무것도 실행되지 않습니다  
그리고 새로운 v2를 실행합니다  
일래스틱 Beanstalk이 인스턴스로 v2를 배포하기 때문입니다  
무엇을 알 수 있을까요? 빠르다는 것입니다  
`애플리케이션에 다운타임이 있지만 가장 빠른 배포 방식`입니다  
이쪽 중간에 보이는 회색 부분에서 어떤 트래픽도 처리할 수 없기 때문입니다  
코드를 빠르고 신속하게 배포하고  
다운 타임은 신경 쓰지 않는다면  
빠른 반복과 개발 환경에  
적합하다고 생각합니다  
그리고 `이런 방식은 추가 비용이 없습니다`

`롤링 업데이트`를 살펴보죠
이런 방식에서는 애플리케이션이 낮은 용량에서 실행됩니다  
그리고 실행 용량처럼 용량을 얼마나 낮출지 설정할 수 있습니다  
그것을 버킷 크기라고 하는데 한 번 살펴보겠습니다  
v1에서 실행되는 4개의 인스턴스가 있고  
이 예시에서 버킷 사이즈를 2로 하면  
인스턴스에 있는 처음 두 개의 인스턴스가  
중지되는데 아주 좋습니다  
하지만 여전히 v1에서 실행되는 2개의 인스턴스가 있습니다  
그래서 이쪽에 절반의 용량이 있고  
처음 2개의 인스턴스는 업데이트되어  
v2에서 실행됩니다  
그리고 다음 버킷 혹은 배치로 롤링됩니다  
그래서 롤링 업데이트라고 부르죠  
보시는 것처럼 여기 2개의 인스턴스는  
v1의 애플리케이션을 갖고 회색으로 바뀌었다가  
v2로 업데이트됩니다  
결국 모든 EC2 인스턴스가  
v2 애플리케이션 코드를 실행하도록 업데이트됐습니다  
그래서 보시다시피 배포 중 어떤 시점에는  
애플리케이션이 동시에 두 가지 버전에서 실행됩니다  
그리고 추가 비용은 없습니다  
여전히 동일한 수의 EC2 인스턴스가  
인프라에서 실행되고 있습니다  
여기서 버킷 사이즈를 아주 작게 설정하면  
수백 개의 인스턴스를 갖게 되어  
배포에 시간이 오래 걸립니다  
이 예시에서는 버킷 사이즈가 2이고 4개의 인스턴스가 있지만  
버킷 사이즈가 2이고 100개의 인스턴스도 가능한데  
전체 업데이트에는 시간이 오래 걸립니다

이제 추가 모드인  
`추가 배치의 롤링 업데이트`를 살펴보겠습니다  
이 경우에는 전과 동일한 용량으로  
애플리케이션이 실행되지 않습니다  
이전에는 4개 중에 2개 인스턴스를 실행했죠?  
낮은 용량에서 실행했습니다  
이 모드에서는 최대 용량에서 실행되고  
버킷 크기도 설정할 수 있죠  
이번에도 애플리케이션은  
동시에 같은 버전에서 실행되지만  
비용이 조금 발생합니다  
곧 확인할 추가 배치는 `배포가 종료되면 삭제`됩니다    
그리고 `배포하는데 시간이 오래 걸립니다`  
프로덕션을 다룰 때 좋은 방법이죠 지금부터 살펴보겠습니다  
v1의 인스턴스가 4개 있습니다  
그리고 제일 먼저 새 EC2 인스턴스를 배포하면  
EC2 인스턴스에 v2가 생깁니다  
그래서 4개의 인스턴스에서  
일래스틱 Beanstalk이 자동으로 2개를 추가해 총 6개를 생성합니다  
그리고 2개의 추가 인스턴스는 새로운 버전에서 실행됩니다  
이제 2개의 첫 번째 버킷이 중지되고  
애플리케이션도 중지되며  
애플리케이션이 v2로 업데이트됩니다  
이 과정이 롤링 되는 것처럼 반복되어  
v1에서 실행되는 애플리케이션은 중지되고  
v2로 업데이트되는 것입니다  
그래서 v2에서 실행되는 6개의 EC2 인스턴스가 있는 것이죠  
그리고 마지막에는 추가 배치가 종료되고 제거됩니다  
왜 이렇게 할까요? 늘 최대 용량에서 실행되므로  
애플리케이션에서 실행되는  
가장 적은 수의 인스턴스는 4개입니다  
`그래서 가끔은 용량을 초과해 실행되는 것입니다 그래서 비용이 조금 발생하는 것입니다`  
많지 않지만 그래도 비용이 발생하죠  

이제 `변경할 수 없는 배포 방식`을 살펴보겠습니다  
이 배포 방식도 제로 다운타임이 있습니다  
하지만 새 인스턴스로 새 코드를 배포합니다  
전에는 이전 인스턴스에 배포했지만 지금은 새 인스턴스에 배포하죠  
그럼 인스턴스는 어디서 왔을까요?  
바로 임시 ASG에서 왔습니다    
`용량을 2배로 늘리는데 비용`이 많이 드는데  
`완전히 새로운 ASG를 얻고 배포가 오래 걸리기 때문`입니다  
보너스로 `배포에 실패한 경우 빠르게 롤백` 할 수 있습니다  
실패를 완화하기 위해서 일래스틱 Beanstalk은  
새로운 ASG를 종료하기 때문입니다  
그래서 비용 지불이 괜찮다면 프로덕션에 적합한 선택입니다  
개념을 정리해 보겠습니다  
3개의 인스턴스에서 실행되는 3개의 v1 애플리케이션의 ASG가 있습니다  
그리고 새로운 임시 ASG를 생성하겠습니다  
그러면 Beanstalk은 인스턴스 중 하나가 제대로 실행되는지 보기 위해  
인스턴스 중 하나를 시작합니다  
인스턴스가 잘 실행되면  
나머지 인스턴스도 시작합니다  
그래서 3개의 인스턴스가 있습니다  
인스턴스가 실행되면  
`임시 ASG와 병합`합니다  
전체 임시 ASG를 현재 ASG로 이동하는 것입니다  
그리고 현재 ASG에는 6개의 인스턴스가 있습니다  
이제 임시 ASG가 비면  
v1 애플리케이션을 종료할  
현재의 ASG를 가지면서  
v2 애플리케이션도 갖게 됩니다  
그리고 마지막으로 임시 ASG가 삭제되는 것입니다

마지막 `방식은 블루/그린 배포`입니다  
제로 다운타임이 있으며 릴리스(release) 기능이 있고  
더 많은 테스트 등을 할 수 있습니다  
새로운 스테이지(stage) 환경을 배포하는 개념이며  
또 다른 일래스틱 빈스토크 환경으로  
새 v2을 배포하는 것입니다  
이전의 모든 배포 전략은 동일한 환경이었지만  
지금은 새로운 환경을 생성합니다  
따라서 새로운 환경, 스테이지 또는 그린은  
준비가 되면 독립적으로 승인되며  
문제가 발생되면 롤백 됩니다  
그리고 예를 들어 Route 53을 사용해서  
트래픽이 두 방향으로 가는 것을 방지합니다  
그래서 가중치 정책을 설정하고  
약간의 트래픽을 스테이징 환경으로 리디렉션 해서 모두 테스트할 수 있습니다  
모두 완료하면 일래스틱 Beanstalk 콘솔을 사용해  
테스트 환경이 완료되면 URL을 교체할 수 있습니다  
따라서 직접적인 기능은 아니며 실제로는 수동으로 해야 합니다  
일래스틱 Beanstalk에 내장되어 있지 않죠  
그래서 어떤 문서에는 블루-그린이 있다고 하고  
어떤 문서에서는 없다고 하지만  
전반적으로는 수동으로 해야 합니다  
그래프로 간단하게 설명하겠습니다  
하나의 일래스틱 Beanstalk 환경에서 실행되는 블루 환경에서는  
모두 v1이며, 그 다음에 모든 v2의 그린 환경을 배포합니다    
그러면 동시에 모두 실행되는데 괜찮습니다  
이제 Route 53에서 90%의 트래픽을 블루 환경에 보내기 위해    
정책의 가중치 유형을 설정합니다  
그래서 대부분의 트래픽을 인스턴스로 가도록 하고  
10%의 트래픽만 그린 환경으로 보내서  
테스트하고 실행 여부를 확인하며  
사용자도 문제가 없는지 확인합니다  
웹 트래픽이 90%와 10%로 분할되는 것입니다  
원하는 가중치만큼 분할할 수 있습니다  
아제 테스트와 결과와  
v2 환경으로 모두 측정했을 때  
결과가 만족스러우면  
블루 환경을 종료하고 URL을 교체해서  
그린 환경이 주 환경이 되도록 합니다  
여기까지가 블루-그린 환경입니다 정말 복잡하죠?  
꽤 수동적인 일래스틱 Beanstalk이지만 방식이 이렇습니다

일래스틱 Beanstalk으로 가능한 다른 배포 유형은 트래픽 분할이며  
카나리(Canary) 테스트에 사용됩니다    
그래서 시험에 카나리 테스트가 나오면  
트래픽 분할을 생각하면 됩니다  
`카나리 테스트`는 무엇일까요? 같은 용량의 임시 ASG에  
새 애플리케이션 버전이 배포됩니다
그래서 같은 용량의 메인 ASG와
임시 ASG가 있는 것이며
메인 ASG에 3개의 인스턴스가 있고
임시 ASG에도 3개의 인스턴스가 있습니다
그러면 용량이 2배가 되는데 이렇게 되면
소량의 트래픽이 설정 가능한 시간 동안
임시 ASG로 이동합니다
이제 여기 ALB가 있는데
90%의 트래픽은 메인 ASG로 보내고
나머지 10%의 트래픽은 임시 ASG로 보내는데
모두 자동으로 가능합니다
그리고 새로운 임시 ASG의 상태가 모니터링 됩니다
배포에 실패한 경우나
척도에 문제가 발생하면
이미 메인 ASG가 있기 때문에
아주 빠르게 자동으로
롤백 하도록 합니다
롤백 하려면 임시 ASG로 가는 10%의 트래픽을 중지하면 됩니다
그리고 애플리케이션 다운타임이 없습니다
모두 안정적이고 올바르면
새로운 인스턴스는 임시 ASG에서
기존의 메인 ASG로 이동합니다
그러면 이전 애플리케이션 버전은 종료됩니다
모두 자동화되어 있어서 정말 편합니다
그리고 지난 강의에서 살펴본 블루/그린 배포 외에
큰 발전이라고 할 수 있습니다
모두를 비교해 보려면
설명한 모든 배포 방식 간의
차이점을 확인할 수 있는
Beanstalk 문서의 링크를 참고하시면 됩니다
모든 방식의 이름과
실패한 배포의 영향과 배포 시간을 볼 수 있고
제로 다운타임과 DNS 변경 여부
그리고 롤백 프로세스와 코드의 배포 위치를 확인할 수 있습니다
이 강의를 이해하셨다면 이 표도 이해하실 겁니다
그래서 이 링크로 이동해서 전체적으로 읽어 보시고
표를 이해하시는 것을 추천합니다
시험에는 배포 자체의 요구 사항을 기반으로
Beanstalk 배포 메커니즘의 유형에 관한
한두 가지의 시나리오가 출제되기 때문입니다

## Beanstalk CLI

일래스틱 `Beanstalk CLI` 라는 추가 CLI도 있습니다  
CLI에서 Beanstalk이 훨씬 쉽게 실행되도록 하죠  
다양한 명령이 있는데요 `eb create, status health, events, logs, open, deploy, config, terminate` 가 있고  
이 모든 명령과 더 많은 것들은  
일래스틱 Beanstalk 콘솔에서  
실행한 작업을 재실행 하도록 하는데  
CLI로 실행하도록 합니다  
이제 `개발 파이프라인을 자동화하려면 EB CLI 사용이 적합`합니다  
이 개발자 시험에서는  
이 명령을 몰라도 됩니다  
하지만 DevOps 시험에서는 알아야 하므로  
DevOps 시험에서 다루겠습니다  
그리고 EB CLI 실습은 없는데  
EB CLI는 일래스틱 Beanstalk에서  
CLI를 사용할 때 효율성을 높이는데 도움이 됩니다    
그리고 일래스틱 Beanstalk CLI는 Beanstalk 애플리케이션 배포에 도움이 됩니다  
그래서 Beanstalk 애플리케이션을 배포하기 위해서는  
`종속성을 설명`해야 합니다 예를 들어, `Python용 requirements.txt나 Node.js용 package.json을 생성`해야 하죠  
그리고 `모든 코드를 zip 파일로 패키징`하고  
파일에서 종속성을 알려줘야 합니다  
그리고 이 두 파일을  
Beanstalk에 zip 파일로 업로드하면  
새로운 앱 버전을 생성한 뒤 앱 버전이 업로드되면  
`콘솔이나 CLI를 사용해 배포`할 수 있습니다  
`EB CLI도 동일한 방식`입니다 zip 파일을 생성하고  
업로드한 뒤 배포하는 것이죠  
그리고 zip 파일을 Beanstalk에 업로드하면  
`Amazon S3에 업로드`되고  
Beanstalk 인터페이스에서 Amazon S3 번들을 참조합니다    
모두 완료되면 Beanstalk은 zip 파일을  
각 EC2 인스턴스에 배포하고  
Python이나 Node.js용 JSON 패키지의  
요구 사항에서 종속성을 해결하면  
애플리케이션이 시작됩니다  
여기까지 Beanstalk 원리의 백 엔드 프로세스를 설명했습니다  
다시 해 보시려면 문서 웹사이트에서  
EB CLI를 설치하세요  
하지만 시험 범위 밖의 내용이고  
강의 범위도 벗어난 내용이라 자세하게 알 필요는 없고  
이런 것이 있다는 것만 알아도 됩니다

## Beanstalk 수명 주기 정책 개요

Beanstalk은 계정 안에 `최대 1,000개의 애플리케이션`을 저장할 수 있습니다  
그리고 `이전 버전을 삭제하지 않으면 Beanstalk 애플리케이션을 배포할 수 없습니다`  
따라서 `이전 애플리케이션 버전을 단계적으로 삭제`해야 합니다  
`삭제하기 위해서는 Beanstalk 수명 주기 정책`을 사용합니다  
이 실습에서 확인할 Beanstalk 수명 주기 정책은  
이전 버전 삭제 시간이나 공간을 기반으로 할 수 있습니다  
`버전이 너무 많으면 이전 버전을 단계적으로 삭제`합니다  
현재 환경에서 사용하는 버전은  
오래됐고 공간을 많이 차지해도 삭제되지 않습니다  
Amazon S3에는 데이터 손실 방지를 위해 애플리케이션의 소스 번들이  
삭제되지 않는 옵션도 있는데  
나중에 버전을 복구하는데 도움이 됩니다  
지금은 수명 주기 정책으로  
Beanstalk 인터페이스에서 삭제할 수 있습니다

## Beanstalk 확장

일래스틱 `Beanstalk 확장자`를 살펴보겠습니다  
zip 파일을 생성하면 일래스틱 Beanstalk에 배포해야 하는  
코드가 포함되어 있는데  
EB 확장도 추가할 수 있습니다  
`UI 에서 설정한 모든 매개변수는 파일을 사용해서 코드로 구성`할 수 있는데  
이것이 `EB 확장`입니다  
요구 사항으로는 이러한 모든 구성 파일은  
`반드시 소스 코드의 루트의 .ebextensions/` 디렉터리에 있어야 한다는 것입니다  
그래서 `.ebextensions/라는 디렉터리에 있어야 하고`  
반드시 `YAML 또는 JSON 형식`이어야 합니다    
YAML 또는 JSON 형식이라도 
해당 파일의 `확장자는 반드시 .config` 로 끝나야 합니다  
logging.config 처럼  
.config 로 끝나야 합니다  
그리고 옵션 세팅을 사용해서  
기본값을 수정할 수 있는데  
잠시 후에 살펴보겠습니다  
그리고 `RDS 와 일래스티 캐시 DynamoDB와 같은 EB 확장자로 리소스를 추가하는 기능`이 있고    
그리고 설정할 수 없는 다른 모든 사항도  
일래스틱 Beanstalk 콘솔에서 설정 가능합니다  
따라서 `환경이 삭제되면 EB 확장자로 관리하던 모든 것도 삭제`됩니다  
예를 들어, 일래스티 캐시를 일래스틱 Beanstalk 환경의  
일부분으로 생성하고  
일래스틱 Beanstalk 환경을 삭제하면  
일래스티 캐시도 삭제되는 것입니다

## Beanstalk 및 CloudFormation

일래스틱 Beanstalk 의 작동 원리를 알아보겠습니다  
`Beanstalk은 이면에서 CloudFormation 을 기반`으로 합니다 
CloudFormation는 `다른 AWS 서비스를 프로비저닝 하는 코드형 인프라 서비스`입니다  
일래스틱 Beanstalk의 여러 동작은 CloudFormation을 기반으로 합니다  
이 내용이 왜 중요할까요?  
앞서 살펴본 .ebextensions 폴더의 CloudFormation 리소스를 사용하면  
모든 것을 프로비저닝 할 수 있습니다  
일래스티 캐시, S3 버킷 DynamoDB 테이블 등을  
프로비저닝할 수 있고 나중에 본 코스에서 살펴볼 겁니다  
일래스틱 Beanstalk의 훌륭한 점은  
`EB 확장자나 CloudFormation으로 구성할 수 있는 UI는 적으나 AWS 상에서는 원하는 모든 것을 구성할 수 있다는 겁니다`

## Beanstalk 복제

일래스틱 Beanstalk의 유용한 기능을 하나 살펴보죠  
`기존 환경을 새 환경으로 복제하는데 이때 정확히 같은 구성을 갖도록 할 수 있습니다`  
이미 애플리케이션에 대한  
프로덕션 버전이 있고  
`동일한 설정으로 테스트 버전을 배포`하고자 할 때에 아주 유용합니다  
이와 같은 경우에는 prod 환경을 테스트를 위한 새로운 환경에  
복사하기만 하면 되니 말이죠  
기존 환경의 모든 리소스와  
구성은 그대로 유지됩니다  
로드 밸런서 유형과 구성  
RDS 데이터베이스 유형도 유지되죠  
RDS 데이터베이스에 있는 데이터는 보존되지 않으나  
해당 RDS 데이터베이스의 구성은 그대로 유지됩니다  
환경 변수 등도 유지됩니다  
환경을 복제한 후에는 설정을 변경할 수 있습니다

## Beanstalk 마이그레이션

이번 시간에는 Elastic Beanstalk Migration 수행에 대한 이론을 살펴보겠습니다  
첫 번째는 로드 밸런서인데  
`Beanstalk 환경을 한번 생성하고 나면 일래스틱 로드 밸런서 유형은 변경이 불가능하고, 구성만 바꿀 수 있습니다`  
이전에도 본 바가 있죠 클래식 로드 밸런서를 생성하면  
해당 클래식 로드 밸런서의 설정만 바꿀 수 있고  
이를 애플리케이션 로드 밸런서로 업그레이드할 수는 없습니다  
따라서 클래식 로드 밸런서를  
애플리케이션 로드 밸런서로 업그레이드하거나  
애플리케이션 로드 밸런서를 네트워크 로드 밸런서로 업그레이드하려면  
`다음 단계에 따라서 마이그레이션(Migration)을 수행`해야 합니다

`먼저 동일한 구성으로 새로운 환경을 생성`합니다  
`로드 밸런서만 제외`하고 말이죠  
지난 시간에 본 복제 기능은  
동일한 로드 밸런서 유형과 구성을  
복제하므로 이 경우에는 사용할 수 없습니다  
따라서 `동일한 구성을 수동으로 다시 생성`해야 하며  
`이전 환경은 그대로 복사`됩니다  
새 환경으로 복제되는 것과는 다르죠 이제 이 새 환경에는  
애플리케이션 로드 밸런서가 있고  
`애플리케이션을 새 환경에 배포`하는 겁니다  
그리고 `이전 환경으로 가던 트래픽을 새 환경으로 이동`시켜 줘야겠죠    
이를 위해서 `CNAME 교체나 Route 53을 이용`해서  
DNS 업데이트를 수행합니다 이 내용이 잘 이해가 되셨다면 좋겠군요
다음으로 RDS Elastic Beanstalk을 보죠  
`RDS는 Beanstalk 애플리케이션을 이용해서 프로비저닝 가능`합니다  
개발이나 테스트를 하고자 하는 경우에 유용하죠

Beanstalk에 RDS 데이터베이스가 있죠  
단 프로덕션 개발을 위해서는 유용하지 못한데  
`데이터베이스의 수명 주기가 Beanstalk 환경의 수명 주기와 연결`되어 있기 때문입니다  
프로덕션 시에 이를 수행하는 최선의 방법은  
RDS 데이터베이스를 Beanstalk 환경에서  
분리한 다음 환경 변수 등을 이용하여  
이를 연결 문자열로 참조하는 겁니다  
`이미 Beanstalk 스택에 있는 RDS를 어떻게 분리할 수 있을까요?`  
먼저 문제가 발생할 경우에 대비해서  
`RDS 데이터베이스에 대한 스냅샷을 생성`합니다    
백업이나 데이터가 있으니 안심할 수 있겠죠  
다음으로는 RDS 콘솔로 이동하여  
`RDS 데이터베이스가 삭제되지 않도록 보호`해 줍니다    
어떤 상황이든 삭제되지 않도록 하는 거죠  
그리고 `새로운 일래스틱 Beanstalk 환경을 생성하는데 이번에는 RDS를 제외`하고  
환경 변수 등을 사용해서 애플리케이션을 `기존의 RDS 데이터베이스로 지정`합니다    
이제 동일한 데이터베이스가 지정된 새로운 환경이 생성되었습니다  
이제 CNAME 교체 즉 블루/그린 배포나  
Route 53 DNS 업데이트를 수행할 차례입니다  
제대로 작동하는지 확인하면  
`전체 트래픽을 기존 버전에서 새로운 버전으로 옮겨` 줍니다  
그리고 `기존 환경을 삭제`하는 거죠  
RDS 삭제 보호를 활성화했으니 RDS는 그대로 유지될 겁니다  
CloudFormation 스택을 이용하는  
`일래스틱 Beanstalk 환경에서는 삭제에 실패할 것이므로 DELETE_FAILED 상태가 표시`됩니다  
따라서 `CloudFormation 으로 이동해서 해당 스택을 수동으로 삭제`해야 하죠  
이렇게 Beanstalk 환경이  
아닐 때에도 자체적으로 RDS 데이터베이스를  
생성해 보았습니다  
유익한 시간이었길 바라며 그럼 다음 강의에서 뵙도록 하겠습니다

## Beanstalk 고급 개념

오늘은 Beanstalk에 대한 심화 개념 이론을 짧게 살펴볼 텐데  
먼저 `Beanstalk에서는 어떻게 HTTPS를 구현할까요?`  
간단히 `SSL 인증서를 로드 밸런서에 로드`하기만 하면 되는데 두 가지 방법이 있습니다    
첫 번째 방법은 SSL 인증서를   
`Elastic Beanstalk 콘솔에서 로드 밸런서 구성으로 직접 로드`하거나  
`securelistener-alb.config 라고 하는 .ebextensions 에서 직접 파일을 생성`합니다  
이 방법을 사용하면 인증서가 자동으로 프로그래밍되죠  
인증서 자체는 `ACM 즉 AWS Certificate Manager` 로  
프로비저닝되거나 추후 본 코스에서 살펴볼  
CLI로 프로비저닝됩니다  
또한 `포트 443의 로드 밸런서로 HTTP 트래픽을 허용하는 보안 그룹 규칙을 구성`해야 합니다  
그다음 `Beanstalk의 HTTPS 로 HTTP 를 리디렉트` 할 수 있는데  
이를 위해서는 여기 나와 있는 예시처럼 인스턴스를 구성하거나  
`ALB, 즉 애플리케이션 로드 밸런서만을 구성`해서  
ALB에만 HTTP를 HTTPS로 리디렉트하는 규칙을 설정합니다  
하나 유념할 점은  
상태 확인까지 리디렉트되지 않으며  
상태 확인에서 지속적으로 200 OK가 표시될 겁니다  
Beanstalk과 HTTPS에 대해서는 여기까지만 살펴보고  
다음으로는  
웹 서버와 작업자 환경에 대해 이야기해 보겠습니다  
DevOPS 시험에 응시하는 수강생분들이라면 아주 중요한 내용입니다  
개발자 시험에는 출제되지 않을 텐데  
혹시 모르니 알려 드리겠습니다  
완료까지 소요되는 시간이 아주 긴 작업을 수행하는 경우  
해당 태스크를 전용 환경으로  
오프로드 하고자 할 텐데 이때 이 환경을 작업자 환경이라고 합니다  
애플리케이션을 두 개의 티어로 분리하는 흔한 방법이죠  
긴 시간이 소요되는 태스크에는 어떤 것이 있을까요?  
`동영상을 처리하거나 zip 파일을 생성하는 등의 경우`가 있습니다  
이와 같은 `주기적 태스크를 cron.yaml 로 정의`하고  
애플리케이션에 해당 처리 태스크를 정의한다고 하면  
이와 같은 아키텍처가 나옵니다 로드 밸런서와  
오토 스케일링 그룹에 해당하는 웹 티어가 있고  
아직까지는 본 코스에서  
다룬 적 없는 SQS 대기열이라는 곳으로 메시지를 전송합니다  
작업자 티어는 SQS 대기열로부터 메시지를 읽어 들여서  
긴 시간이 소요되는 태스크를 수행하죠  
아주 흔한 아키텍처이며  
개괄적으로 알고만 있으면 됩니다  

마지막으로는 `사용자 지정 플랫폼`을 살펴볼 텐데, 꽤 심화된 내용입니다  
이를 통해서 여러분이 직접 운영 체제, 추가 소프트웨어  
Beanstalk이 실행하는 스크립트를  
정의할 수 있는데 사용자 지정 플랫폼은  
Beanstalk과 호환되지 않는  
애플리케이션 언어를 사용하며  
도커도 없는 경우에만 사용합니다  
Beanstalk과 호환되는  
애플리케이션 언어를 사용하거나 도커를 사용하는 경우에는  
`Beanstalk 플랫폼을 사용`합니다  
아닌 경우에만 사용자 지정 플랫폼을 생성하죠  
사용자 지정 플랫폼을 생성하려면  
`platform.yaml 파일을 사용해서 자체 AMI를 정의`해야 하고  
해당 플랫폼의 구축을 위해 AMI를 생성하는 오픈 소스 도구인  
Packer 소프트웨어를 사용하는데 Packer란 단어는  
지금을 제외하고 시험에서 나오지 않습니다  
`Packer가 나오면 사용자 지정 플랫폼`을 생각하세요  
제가 아는 바 시험에서 출제되는 유일한 경우입니다  
사용자 지정 플랫폼과 사용자 지정 AMI의 차이는 무엇일까요?  
기존 Beanstalk 플랫폼을 사용자 지정 AMI로 조정할 수 있습니다  
Python, Node.js Java 등을 말이죠  
반면에 사용자 지정 플랫폼은 완전히 새로운  
Beanstalk 플랫폼을 생성할 수 있어 좀 더 심화된 개념이죠  
이제 시험에 출제될 Beanstalk 관련 내용은 모두 다루었습니다  

# AWS CICD: CodeCommit, CodePipeline, CodeBuild, CodeDeploy

AWS 리소스를 수동으로 방법을 배웠죠 기본 원리를 살펴본 겁니다  
AWS 프로그래밍 방식도 배웠죠  
CLI를 사용했었습니다  
Beanstalk으로 AWS에 코드를 배포해 보기도 했습니다  
이 모든 과정을 수동으로 직접 했는데  
이렇게 하다 보면 `실수가 발생할 가능성이 아주 높습니다`  
따라서 결과적으로는 `대상 리포지토리까지 코드를 푸시`하고  
이로써 `자동으로 AWS에 배포되는 방법`을 찾고자 합니다  
배포 전 `모든 코드가 제대로 작동하는지 테스트`도 거쳐야 하며  
다음 단계로 넘어간다는 가능성도 생각해야 합니다  
개발에서 테스트, 사전 프로덕션 프로덕션 환경까지 말이죠  
종종 프로덕션에 배포 시에도  
수동 승인을 필요로 할 때가 있습니다  
이 모든 작업을 위해서는 AWS CICD를 학습해야 하죠  
이 모든 단계를 자동으로  
수행하게 될 테니 모든 단계를 잘 아는 것이 아주 중요하겠습니다  
지금까지의 본 코스에서 다룬 자동화는  
보안과 속도를 더하기 위해서 수행되었습니다  
이제부터 `코드를 저장하기 위한 CodeCommit`와  
코드에서 Beanstalk 등의 플랫폼까지 이르는  
`파이프라인을 자동화하는 Codepipeline`을 알아봅니다    
`CodeBuild는 코드를 구축 및 자동으로 테스트`하고  
`CodeDeploy는 Beanstalk가 아닌 다른 방법으로 EC2 인스턴스에 코드를 배포`합니다  
`CodeStar 는 개발을 위한 소프트웨어로 CodeCommit, CodeBuild, CodePipeline, CodeDeploy를 하나로 다시 그룹화하는 도구`입니다  
`CodeArtifact 는 소프트웨어 패키지를 저장, 게시, 공유`    
`CodeGuru 는 머신 러닝을 이용해서 자동화된 코드를 리뷰`하죠  

지금은 개요일 뿐이죠 CICD는 무엇일까요?  
먼저 `CI는 지속적 통합`을 뜻합니다  
`개발자들이 코드를 중앙 코드 리포지토리에 자주 푸시한다는 의미`입니다  
`리포지토리로는 AWS 의 타사 서비스인 GitHub AWS 서비스인 CodeCommit 또 다른 타사 서비스인 Bitbucket가 있죠`  
개발자들이 코드 리포지토리에 코드를 푸시하면  
해당 코드가 코드 리포지토리에 푸시되는 즉시 이 코드가  
올바른 `코드이며 작동하는지 확인하는 테스트 혹은 빌드 서버`가 있을 겁니다  
`AWS 인 경우에는 CodeBuild 오픈 소스 도구의 경우에는 Jenkins`가 되겠죠  
이제 빌드 서버가 코드를 테스트하면  
개발자는 해당 코드가 테스트나 점검을 통과 여부에 대한  
피드백들 받을 겁니다 테스트 결과를 얻는 거죠  
이 과정에서 시간이 절약됩니다 코드 리포지토리에 코드가 푸시 된 즉시  
코드를 테스트해서 버그를 조기에 발견하고 해결할 수 있기 때문이죠  
개발자가 따로 본인의 기기에서 코드를 테스트할 필요가 없는 겁니다  
코드를 푸시해 놓고 다른 일을 하는 동안 빌드 서버의 피드백을 기다리면 되죠  
따라서 테스트를 거친 코드는 더욱 빨리 제공될 것이며  
이 덕분에 더 자주 배포될 겁니다  
테스트를 마치고 준비 상태가 되면 바로 배포할 수 있기 때문이죠  
개발자들도 더 행복하겠죠 개발 주기가 더 튼튼해졌으니 말입니다  
지금까지 CI를 봤으니 이제 CD를 볼 차례입니다  
`지속적인 제공`이 되겠죠  
예시와 함께 살펴보겠습니다  
애플리케이션 버전 1이 있습니다  
개발자인 우리는 애플리케이션 서버로  
바로 코드를 푸시하고자 합니다  
지속적인 제공을 통해서  
코드를 코드 리포지토리에 푸시할 때마다  
적절히 테스트를 거치기만 하면 애플리케이션 서버에  
배포되도록 하는 겁니다  
개발자가 코드를 푸시했습니다  
코드는 빌드 서버로 가서 테스트를 거치겠죠  
지속적인 통합에 해당하는 부분이죠  
빌드 서버를 통과합니다  
초록색이니 테스트가 끝났다는 뜻이죠  
이제 배포 서버로 넘어갑니다  
배포 서버에서는 애플리케이션 서버로 애플리케이션을 배포합니다  
처음에는 버전 1이었지만 다시 코드를 푸시하면  
새로운 버전의 코드가 코드 리포지토리로 들어가고  
이로써 애플리케이션 서버 2가 생성됩니다  
지속적인 제공을 통해서 배포가 더 자주 발생하고  
신속히 이루어질 수 있도록 합니다  
그리고 3개월마다 한 번씩 릴리스해야 한다는  
고루한 사고방식에서도 벗어날 수 있죠  
오류도 발생하기 쉽습니다 자주 하는 일이 아니니 말이죠  
이를 자동화해서 하루에도 다섯 번씩 릴리스하도록 하는 겁니다  
코드 리포지토리에 코드를 푸시 할 때마다  
애플리케이션에 활성화되는 거죠  
따라서 지속적인 제공을 위해서는  
AWS 가 서비스하는 CodeDeploy처럼  
자동화된 배포 도구가 필요합니다 Jenkins CD, Spinnaker 등도 있죠  
AWS의 CICD 기술 스택을 한번 살펴보면  
코드와 더불어서 `자체 제공하는 CodeCommits 타사 서비스인 GitHub, Bitbucket 코드 리포지토리`가 있습니다  
그리고 구축 단계가 있죠 구축 단계와 테스트 단계는  
`AWS의 CodeBuild 또는 CodeBuild의 경쟁사인 오픈 소스 Jenkins CI에서 수행`합니다  
혹은 다른 타사의 CI 서버에서도 가능하죠  
그리고 배포 단계로 넘어갑니다 CodeDeploy를 사용하면  
`CodeDeploy가 EC2 인스턴스 온프레미스 서버람다 함수 역할, ECS 등을 검색하고 이들을 직접 배포`합니다  
인프라를 프로비저닝 하고자 하는 경우  
CodeDeploy 대신 Elastic Beanstalk 을 사용해서  
배포와 인프라 프로비저닝 작업을 수행할 수도 있습니다  
이 모든 단계를 조정하고` CICD 처리를 정의하기 위해서는 AWS CodePipeline 을 사용`할 수 있습니다

## CodeCommit 개요

AWS CodeCommit을 살펴볼 시간입니다  
`버전 관리`라는 개념을 알아볼 텐데  
이는 시간이 지남에 따라 코드에 발생하는 다양한  
`변경 사항을 이해하고 롤백 할 수 있는 기능`입니다  
버전 관리를 통해서 과거에 어떤 작업이 수행됐고  
누가 어떤 코드를 커밋(Commit)했고 변경 사항은 무엇이며  
추가 및 제거된 사항은 무엇인지 그리고 롤백까지 가능합니다  
버전 관리의 바탕이 되는 기술로는 요즘 그 인기가 높은  
Git이 있습니다  
Git 리포지토리는 사용자의 컴퓨터에 동기화되기도 하지만  
일반적으로는 중앙 온라인 리포지토리에 업로드되는 형식입니다  
Git 리포지토리가 중앙 온라인 리포티토리 일 때의 이점은  
`여러 개발자들과 협업`이 가능하다는 데에 있습니다  
수십만에 달하는 개발자가 동일한 코드에 대해  
동시에 작업할 수 있다니 대단한 일이죠  
또한 코드가 백업되기도 합니다  
`컴퓨터뿐만 아니라 클라우드에 백업`되고 있죠  
`또한 누가, 언제, 어떤 코드를 커밋했는지 볼 수 있으며 작업을 되돌릴 수도 있습니다`  
롤백이 가능한 거죠, 코드 리포지토리에 여러 유용한 작업을 할 수 있습니다  
CodeCommit의 코드 리포지토리는 AWS와 개발자에게 있습니다  
Emma와 John은 협업하여 코드 리포지토리에 코드를 푸시하고 풀(Pull)합니다  
왜 CodeCommit를 사용하는 걸까요?  
`Git 리포지토리는 비용`이 듭니다  
`Github, GitLab Bitbucket 등 제3자 서비스가 있으나 사용하는 비용이 상당`할 수 있죠  
하지만 `AWS 의 CodeCommit 을 사용하면 여러분의 코드가 AWS 클라우드의 개인 VPC 내에 있기 때문에 개인 Git 리포지토리가 생기는 것과 마찬가지`입니다  
`리포지토리 크기에 제한도 없죠`  
따라서 원하는 경우 코드를 기가 크기까지 확장할 수도 있습니다  
완전 관리형에 가용성도 높죠  
방금 언급한 대로 `코드는 AWS 클라우드 내에만 저장`됩니다  
`보안도 높고 형식도 일관`된다는 뜻이죠  
AWS 외에는 다른 위치에 코드를 입력할 수 없는 겁니다  
`보안도 유지됩니다 암호화되므로 IAM을 이용한 액세스 제어가 가능`하죠  
`Jenkins, CodeBuild 또는 기타 CI 도구 등 업계 표준 도구와 잘 통합`됩니다  
원하는 경우에는 코드를 저장하기에도 좋죠  
CodeCommit은 훌륭한 보안을 자랑합니다  
표준 Git 명령어를 사용할 수 있지만  
인증이 따릅니다  
SSH 키를 사용하는 경우가 있는데 사용자는  
본인의 SSH 키를 구성해서 Git 리포지토리에 접근할 수 있습니다  
표준 로그인 방식으로 비밀번호를 사용해서 액세스하려면  
HTTPS를 사용할 수도 있습니다 인증을 위해  
`IAM 정책을 이용해서 사용자와 특정 리포지토리에 대한 역할 권한을 관리`할 수 있습니다  
AWS에서 보안을 확보할 수 있는 좋은 방법이 되어 줍니다  
`여러분의 코드는 KMS를 이용해서 암호화`됩니다  
즉 누구도 아닌 여러분만이 코드를 불러들일 수 있는 거죠  
또한 코드를 CodeCommit로 푸시 할 때  
안전한 `HTTPS 또는 SSH 프로토콜을 이용하여 암호화된 채로 전송`됩니다  
또한 계정 간 액세스의 경우  
`SSH 키 또는 자격 증명을 다른 사용자와 공유해서는 안 됩니다`  
대신 `계정에 IAM 역할을 생성해서 STS 또는 AssumeRoleAPI를 이용하여 CodeCommit 리포지토리에 액세스`하도록 합니다  
여러분에게 익숙할 GitHub와 비교하여 개괄적으로 요약해 보자면  
일대일로 비교하는 모양새네요  
CodeCommit 과 GitHub 는 모두 Pull Requests 라는 코드 리뷰를 지원합니다  
모두 CodeBuild 와 통합되고  
SSH 및 HTTPS 인증을 제공합니다  
보안은 현재 아주 다른 모습을 보이는데  
Github 는 Github 사용자와 기업체의 경우 SSO 를 지원하나  
`CodeCommit 은 AWS 와 완벽히 통합`됩니다  
IAM 사용자와 역할을 지정할 수 있죠 호스팅 면에 있어서는  
CodeCommit 은 오직 AWS 에서만 가능하며  
Github 는 Github 자체나  
Github Enterprise 또는 사용자 서버에서 가능합니다  
CodeCommit 의 UI는 최소한만 구축되어 있으며  
GitHub UI 는 저도 개인적으로 좋아할 정도로 잘 구축되어 있죠  
하지만 코드 리포지토리로만 사용하려면  
CodeCommit 이 여러 방면에서  
더 나은 선택일 겁니다 앞서 말한 이유로 말이죠

## CodePipeline 개요

이제 CodePipeline 을 살펴봅시다  
`AWS 내에서 CICD 를 조정해주는 비주얼 워크플로 도구`죠  
CodePipeline 으로 여러분은 CodeCommit,   
ECR Amazon S3 뿐 아니라 Bitbucket, GitHub 같은
외부 도구에서도 소스나 도커 이미지를 가져올 수 있어요  
코드를 가져왔으면 이제 빌드 단계로 갑니다  
CodeBuild, Jenkins, CloudBees, TeamCity 등을 선택할 수 있죠  
빌드 단계가 지나면 테스트 단계입니다  
다시 코드를 테스트하는 거죠 CodeBuild나 Device Farm  
iOS나 Android 앱 또는 여러분이 원하는  
다른 어떤 도구로든 테스트 가능합니다  
코드 테스트가 끝나면 이제 배포를 해야겠죠  
`CodeDeploy, Beanstalk CloudFormation, ECS, S3까지 모두 CodePipeline 에서 사용 가능`합니다    
지금까지 이야기한 이 `모든 것들로 단계들을 구축`할 수 있습니다  
각 단계는 순차적 작업 또는 병행되는 작업들로 이뤄지는데요  
많은 것들을 할 수 있는데 여기 간단한 예시를 보면  
빌드, 테스트를 거쳐 스테이징으로 배포  
`스테이징이 괜찮은지 부하 테스트`를 하고  
부하 테스트가 끝나면 다시 프로덕션으로 배포합니다  
참고로 파이프라인의 어느 단계에서라도  
수동 승인을 정의할 수 있습니다  
예를 들어 프로덕션 배포 직전에  
`부하 테스트의 결과를 누군가 검토하게 해서 검토 결과가 좋을 때에만 프로덕션으로 배포`하게 하는 거죠  
`CodePipeline 은 이렇게 전 과정을 조정하며 모든 구성 요소들로써 유연한 작업`을 가능하게 해줍니다

CodePipeline 내부는 어떻게 작동할까요?  
여기 소스, 빌드 그리고 배포 단계가 있습니다  
소스는 CodeCommit 빌드는 CodeBuild  
각 파이프라인은 아티팩트를 만듭니다  
`파이프라인에서 생성되는 모든 걸 아티팩트`라고 부르죠  
`아티팩트는 S3 버킷에 저장되고 그 다음 단계로 전달`됩니다  
그렇게 해서 다음 단계가 진행될 수 있는 거죠  
구체적인 예를 보여드릴게요  
`개발자가 CodeCommit 에 코드를 푸시`합니다  
그럼 CodePipeline 에 의해 CodeCommit 이 모든 코드를 추출해 내고
그로부터 아티팩트를 생성해요  
그리고 그걸 S3 버킷에 저장합니다  
이제 CodeBuild가 작동하면  
아까 추출됐던 그 아티팩트가  
CodeBuild에 바로 입력됩니다  
그렇기 때문에 CodeBuild가  
CodeCommit에 직접 액세스할 필요가 없죠  
사실 `CodePipeline 이 Amazon S3를 통해 CodeBuild 로 코드를 푸시`하는 겁니다  
CodeBuild 가 코드를 빌드할 때  
`배포 아티팩트를 생성`하는데  
이 `아티팩트는 다시 CodePipeline 에 의해 S3 버킷에 저장`됩니다  
그리고 CodePipeline 이 이 아티팩트를 다시  
CodeDeploy 로 푸시하면  
전달된 아티팩트를 CodeDeploy 가  
배포하는 거예요  
보다시피 Amazon S3를 통해 각 단계가 상호작용하고  
그 과정에서 CodePipeline 에 아티팩트가 생기는 거죠  

이제 문제 해결을 봅시다  
예를 들어 CodePipeline 작동이나 단계 실행 상태 변화 등  
이런 걸 다 살펴보려면 EventBridge 인  
CloudWatch Events 를 사용하면 됩니다  
그러면 실패한 파이프라인 혹은 취소된 단계에 대한  
이벤트를 생성할 수 있고 메일 알림도 수신할 수 있어요  
CodePipeline의 어떤 단계에 만약 failure 오류가 생기면  
콘솔을 통해 시각적으로 확인하고 정보를 얻을 수 있죠  
CodePipeline이 만약 CodeBuild에 코드 호출하기나  
CodeCommit에서 코드 가져오기 등  
특정 작업을 수행할 수 없을 때는  
'IAM Service Role'을 보고  
IAM 권한이 올바른지 확인합니다  
또한 거부된 API 호출 등을  
인프라에서 살펴봐야 하는 경우  
AWS API 호출 감시 서비스인 CloudTrail을 사용하면 됩니다  

## CodeBuild 개요

CodeBuild란 코드의 소스에, 예를 들어  
CodeCommit, Amazon S3, Bitbucket, GitHub 같은  
이런 소스들에 빌드 명령이 있습니다  
시험에 나오니까 파일 이름은 기억해두세요  
`buildspec.yml 입니다 이 파일은 코드의 루트에 위치`해야 해요  
이 명령을 그냥 콘솔에 입력해도 되지만  
buildspec.yml 파일을 쓰는 게 가장 좋은 연습이 될 겁니다  
애플리케이션이 구축되면 출력 로그가 
`Amazon S3와 CloudWatch 로그에 저장되어 나중에 분석` 할 수 있죠  
`CloudWatch Metrics 는 빌드 통계`를 확인하는 데 쓰이고
`CloudWatch Events 는 실패한 빌드`를 찾아 알려줍니다
`CloudWatch Alarms 는 오류가 너무 많을 때` 쓰이고요 그리고 
프로젝트 빌드 자체는 CodeBuild나 CodePipeline의  
내부에서 정의될 수 있는데 CodePipeline은  
CodeBuild의 기존 프로젝트 빌드도 불러올 수 있어요  
그러면 CodeBuild는 무엇을 테스트할까요?  
Java, Ruby, Python, Go, Node.js, Android, .NET Core, PHP 애플리케이션  
이런 것들엔 사전 빌드된 이미지가 있어서 CodeBuild에 테스트할 수 있습니다  
만약 다른 환경이 필요하다면  
도커 이미지를 확장할 수 있고  
따라서 원하는 언어로 테스트할 수 있습니다  
하지만 지원 여부는 여러분 환경에 따라 다릅니다  
CodeBuild는 어떻게 작동할까요? 여기 CodeCommit의 코드를 좀 봅시다  
소스 코드와 전체 파일들이 있고  
그리고 정말 중요하면서 리포지토리 가장 상단에 위치한  
buildspec.yml이 들어있습니다  
이제 CodeBuild가 이 코드를 가지고 오려면  
CodeBuild에 컨테이너가 있어야 해요  
Java, Go 등의 빌드 환경이 있겠죠  
이 컨테이너가 모든 소스 코드와  
buildspec.yml을 불러오고  
buildspec.yml 파일에 삽입된  
모든 명령을 실행합니다  
컨테이너를 만들 때 CodeBuild가 도커 이미지를 끌어오는데  
앞서 말씀드린 환경들에서  
AWS에 의해 사전에 패키지에 포함된 이미지나 혹은  
자신만의 도커 이미지를 가지고 원하는 코드를 실행할 수 있습니다  
그리고 CodeBuild는 buildspec.yml의 모든 명령을 실행해  
때로는 `과정이 길어지기도 하는데요 그래서 CodeBuild 에는 S3 버킷의 파일 전체를 캐시 저장하는 기능`이 있어요  
이 방법이 최적이지만 만약 몇몇 파일을 빌드에서 빌드로  
재사용하고 싶다면 몇몇 파일을 캐시 저장할 수도 있습니다  
사용자가 선택하기 나름이죠 이제 모든 로그가  
CloudWatch 로그와 Amazon S3으로 이동합니다  
`CodeBuild 가 코드 빌드 혹은 코드 테스트를 완료하면 아티팩트를 생산`할 수 있는데요    
이 아티팩트를 컨테이너에서 추출해 S3 버킷에 넣으면  
거기서 CodeBuild 의 최종 출력 결과물을 볼 수 있습니다  
그래서 buildspec.yml 파일은 정말 중요합니다  
`buildspec.yml 파일은 무조건 코드의 루트에 위치`합니다  
env를 사용하면 buildspec.yml을 실행할  
여러 환경적 역할을 정의할 수 있습니다  
variables는 평문 변수이고  
SSM parameter-store로 변수를 끌어올 수 있습니다  
secrets-manager로 암호를 끌어올 수도 있죠    
그렇게 하면 비밀번호 및 데이터베이스 등을 여기저기서 직접 가져올 수 있는데  
`물론 이런 비밀번호들을 평문으로 buildspec.yml 파일에 저장할 수는 없습니다`  

다음은 `phases` 입니다  
이것은 `CodeBuild의 역할을 정의`합니다  
먼저 install은 예를 들어  
어떤 명령을 사용해서  
사전에 필요한 패키지를 설치할지 등을 결정하죠  
`pre_build 는 빌드 직전 실행되는 명령`입니다    
Build는 실질적인 빌드 명령으로 아주 중요한 부분이고  
`post_build는 마무리 명령`입니다   
예를 들어 빌드가 완성되면 좋은 zip 출력 결과를 생성합니다  
`artifacts는 도커 컨테이너의 어떤 파일을 추출하고 Amazon S3에 보낼지 정합니다`  
기본적으로 암호화되어야 합니다

마지막 `cache 블록은 어떤 파일의 종속성을 Amazon S3에 캐시 저장하면 이후의 빌드 속도를 높일 수 있을지 결정`합니다    
CodeBuild를 개괄적으로 봤는데  
이 부분에서 가장 중요한 점은  
바로 파일의 이름과 위치입니다  
CodeBuild 의 작동 방식을 대략적으로만 알아도  
여러분에게 충분합니다  
CodeBuild는 클라우드에서 실행되고  
`로그를 넘는 심각한 문제 해결이 필요한 경우, 데스크톱에서 CodeBuild를 로컬로 실행`할 수 있는데    
물론 먼저 `도커를 설치해야겠죠 그리고 CodeBuild 에이전트를 사용`합니다    
설명서는 여기 있습니다 CodeBuild 빌드를  
머신에 재현해서 오류가 생겼을 때  
무슨 일인지 제대로 확인할 수 있습니다  
CodeBuild는 VPC 내에서 실행될 수도 있습니다  
기본적으로 컨테이너와 인스턴스는 VPC 밖에서 실행되도록 빌드합니다  
실행에 문제는 없지만 VPC에 있는 몇몇 리소스에는  
액세스할 수가 없습니다  
그래서 `CodeBuild에 VPC 환경을 설정하고 VPC ID, 서브넷 ID 보안 그룹 ID 등을 줍니다`  
그러면 CodeBuild 컨테이너는 VPC의 리소스에
액세스할 수 있게 됩니다 예를 들어 RDS나  
일래스티 캐시, EC2 인스턴스, ALB 등이 있습니다  
예시를 보면 VPC 사설 서브넷에 RDS 데이터베이스가 있고  
CodeBuild 컨테이너를 바로 실행할 수 있습니다  
이제 CodeBuild 컨테이너가  
RDS 데이터베이스 인스턴스에 액세스 가능합니다  
VPC 내부에서 CodeBuild를 사용하는 사례들은  
통합 테스트, 데이터 쿼리 그리고  
내부 로드 밸런서와의 통신 등이 있습니다

## CodeDeploy 개요

AWS CodeDeploy에 대해 알아봅시다  
애플리케이션을 시간이 지남에 따라  
`많은 인스턴스에 자동으로 배포하는 것을 뜻`합니다  
애플리케이션 서버의 버전 1에서 버전 2로 가는 거죠  
이 EC2 인스턴스들은 일래스틱 Beanstalk 에 의해  
관리되는 것이 아니라는 걸 알아두시기 바랍니다  
`각자 실행되는 EC2 인스턴스나 온프레미스 서버들`이에요  
서버들로 애플리케이션을 배포하는 여러 가지 방법이 있는데요  
다음과 같은 오픈 소스 도구들을 사용할 수 있습니다  
Ansible, Terraform Chef, Puppet 등 많습니다  
AWS CodeDeploy 라는 관리 서비스를 사용할 수도 있죠

CodeDeploy 는 어떻게 작동할까요?  
EC2 인스턴스와 온프레미스 서버로 배포하는 첫 사례입니다  
`CodeDeploy Agent 라는 걸 실행`해야 하는데  
아주 중요한 동시에 시험에도 나옵니다  
예시에서 EC2 인스턴스와 온프레미스 서버가  
CodeDeploy Agent 를 실행하는 걸 살펴봅시다  

개발자 입장에선 어떻게 작업할까요?  
Amazon S3 나 GitHub 에 코드를 입력하고요  
여기가 바로 리비전이 있어야 하는 곳이죠  
보통은 코드를 CodeCommit 에 푸시합니다
물론 코드를 CodeCommit 에 푸시해도 되지만  
빌드 아티팩트(Artifact), 배포할 준비가 된 코드 아티팩트는  
Amazon S3나 GitHub 에 저장돼야 합니다  
소스 코드가 있고요 보시다시피    
소스 코드 혹은 빌드 코드라고 하는데요  
appspec.yml 이라고 불리는 또 다른 파일이 있습니다  
이번 강의에서 다룰 `appspec.yml 파일은 CodeDeploy 가 애플리케이션을 배포하는 법을 설명할 때 나옵니다` 
개발자는 코드를 리비전 로케이션에 넣고  
CodeDeploy를 실행한 뒤  
새 배포를 실행하길 원한다고 입력합니다  
그럼 `Agent 는요 계속해서 CodeDeploy 에게 해야 할 작업이 있는지 묻고, 폴링` 하는 겁니다    
배포해야 할 뭔가가 있는지를 계속 묻는 거죠  
CodeDeploy에서 배포를 실행하면  
배포할 것이 생기는 거니까 애플리케이션, 즉  
`빌드 코드와 appspec.yml 파일을 GitHub나 Amazon S3에서 불러오게 되고  
애플리케이션 서버에 다운로드되며 CodeDeploy Agent 는 appspec.yml 파일의 모든 배포 지침을 실행하는 겁니다`  
그러면 배포가 실행되고  
배포에 대한 성공이나 실패 등의  
결과는 다시 Agent에서 CodeDeploy 서비스로 보고됩니다

CodeDeploy 의 작동을 전반적으로 살펴봤습니다  
CodeDeploy 에는 많은 구성 요소가 있는데  
애플리케이션은 독보적 이름으로 컨테이너 기능을 하고요  
애플리케이션은 리비전을 포함할 수도 있고  
배포 구성 등도 포함할 수 있습니다  
컴퓨팅 플랫폼은 EC2나 온프레미스 서버들이 될 수도 있고  
람다 함수나 ECS 컨테이너도 될 수 있습니다  
그리고 배포 구성이란 성공과 실패에 대한 배포 규칙 세트입니다  
EC2나 온프레미스에 배포가 가능하기 때문에  
배포가 가능한 정상 인스턴스의 수를 파악할 수 있기도 하고  
람다나 ECS의 경우 업데이트된 버전에서  
트래픽이 갈 루트를 알아볼 수도 있습니다  

다음은 `배포 그룹인데요 EC2 인스턴스를 그룹`으로  
지정해서 서서히 배포하거나 개발자와 테스트 그룹, 그리고  
프로덕션 그룹을 EC2 대상에 나눌 수도 있습니다  
배포 방식이란 애플리케이션을 배포 그룹에 어떻게  
배포할 것인지를 뜻하는데 EC2와 온프레미스를  
지원하는 `인 플레이스 배포`가 있고요  
`블루/그린 배포`도 있는데 EC2 인스턴스만 지원합니다  
로드 밸런서를 사용하기 때문이죠  
`람다나 ECS에도 블루/그린 배포`를 할 수 있습니다  
`IAM 인스턴스 프로파일`이 있는데 이는 EC2 인스턴스 중 어떤  
`프로파일에게 Amazon S3나 GitHub의 배포 코드로의 접근을 허용할지를 결정`하죠  
애플리케이션 리비전이란 애플리케이션 코드와  
appspec.yml 파일의 조합입니다  
서비스 역할은 CodeDeploy 서비스 자체에 연결해서  
블루/그린 배포를 쓴 경우 EC2 인스턴스나 ASG  
ELB 등에 대한 작업을 수행하게 합니다

마지막으로 대상 리비전은  
특정 배포 그룹에게 배포를 하는 것입니다  
지금은 단어에 익숙해지시면 되고  
실습에서 다시 살펴보면서  
제대로 이해해 볼 겁니다  
실습을 해보시면 꽤 직관적이라는 걸 알 수 있어요  
`appspec.yml 파일은 아주 중요합니다 여기에는 코드를 배포하는 방식에 대한 지침`이 전부 들어있거든요  
이 파일은 코드의 루트에 위치해야 하고요  
첫 블록은 파일 블록인데요 Amazon S3나 GitHub 에서  
파일 시스템으로 기타 파일을 소싱 해줍니다  
그래서 소스와 대상이 있죠  
후크(hooks)에는 애플리케이션을 배포하는 모든 단계가 포함됩니다  
배포 지침들의 집합이라서 ApplicationStop 이나  
DownloadBundle, BeforeInstall Install, AfterInstall  
ApplicationStart, 그리고 중요한 ValidateService가 있습니다  
이것들이 CodeDeploy에서  
특별한 코드나 지침을 실행하기 위해  
추가할 수 있는 단계들입니다  
오른쪽에서는 `BeforeInstall AfterInstall, ApplicationStart, ValidateService`가 특정된 거죠  
이것들 역시 CodeDeploy가 실행 중일 때  
실행할 스크립트 혹은 압축을 해제할 파일일 수도 있습니다  
`ValidateService가 아주 중요한데 이건 가장 마지막에 실행하는 단계`죠
`EC2 인스턴스에 서비스가 올바르게 배포되었는지 확인하는 용도`입니다 그렇지 않으면 실패가 뜨거든요    
ValidateService 는 애플리케이션이 작동 중인지를 확인하고  
CodeDeploy가 CodeDeploy 서비스에게 애플리케이션이  
성공적으로 배포되었다는 보고를 보내는 거죠

ApplicationStop 은 애플리케이션이 멈췄을 때 실행되는데  
배포를 하는 과정에서  
나머지 단계들도 꽤 직관적이어야 합니다  
여기 보이는 게 실행 순서이니  
눈에 익혀두시기 바랍니다 이후 CodeDeploy 서비스 UI에서  
바로 다루게 될 것들인데 그때 가면 더 와닿을 겁니다  
배포 구성은 아주 중요합니다  
서로 다른 옵션이 있는데요  
EC2 인스턴스에는 한 번에 하나씩 배포가 가능합니다
EC2 인스턴스를 하나씩 올리고 내리는 겁니다  
배포가 중간에 실패하면 바로 중지해야 하고요  
반씩 처리하는 방식은 EC2 인스턴스를  
버전 1에서 2로 반만 업그레이드하고 다음 반을  
처리하는 방식이고요 한 번에 다 하는 방식은  
아주 빠른 대신 정상 호스트가 없으며  
다운타임이 발생합니다 개발 환경에선 좋을 것 같네요

마지막으로 커스텀은 사용자 지정 방식입니다    
예를 들면, 적어도 `정상 호스트가 75%는 돼야 한다고 정하는 거죠`  
전체 배포를 실패라고 판단하기까지 몇 번의 실패가 나와야 하는지를  
정하고 이를 초과하면 실패라고 정의됩니다  
만약 첫 EC2 인스턴스 실패가 발생했는데  
실패 상태로 두고 새로운 배포를 진행하면  
그 첫 번째 인스턴스는 이 배포를  
실패 상태로 받아들이는 인스턴스가 되는 거죠  
그리고 롤백을 원할 경우 이전의 배포를 재배포하거나  
실패에 따른 자동 롤백을 허용해야 합니다, 곧 다룰 거예요  
배포 그룹은 이전에도 개념을 배운 적이 있는데요  
태그 된 EC2 인스턴스들의 세트거나  
ASG가 될 수도 있고  
배포 그룹에 배포할 때 세그먼트를 얻기 위해  
태그와 ASG를 섞은 형태일 수도 있습니다  

마지막으로 배포 그룹명 환경 변수를 지정함으로써  
어떤 배포 그룹에 속하는지를 식별하기 위해  
스크립트를 사용자화할 수 있습니다  

`반씩 처리하는 인 플레이스 배포`란 뭘까요?  
V1이 있는데 이 중에서 반을 떼고  
V2로 가서 또 나머지 반을 떼고  
V2로 업그레이드하는 거죠  
이게 인 플레이스 배포 방식입니다  

다른 방식은 `블루/그린 배포`인데요  
예시를 보시면 오토 스케일링 그룹이 있어야 하고  
애플리케이션 로드 밸런서가 모두 V1에 있습니다  
이제 무엇을 하냐면 V2에서  
또 다른 오토 스케일링 그룹에서 애플리케이션이 실행됩니다  
테스트를 완료하고 나면 ALB는 V2에 있는  
새 오토 스케일링 그룹의 대상 그룹으로 리디렉트합니다  
배포와 관련해서는 내용이 방대할 수 있지만  
실습을 해보시면 이해가 더 쉬울 거고

## EC2 및 ASG용 CodeDeploy

CodeDeploy에 대한 개념을 좀 더 알아봅시다  
EC2 인스턴스에 접근할 때  
appspec.yml 파일이 코드의 루트에 있고  
배포 전략이 있습니다  
EC2 인스턴스 플릿을 인 플레이스 업데이트한 후  
후크를 사용할 수도 있습니다 appspec.yml에 심어서  
각 단계의 마지막에 배포를 확인하는 거죠  
반씩 처리하는 방식이라서 반은 우선 떼어 놓고  
버전 2로 업그레이드하고요  
또 반을 떼어두고 버전 2로 업그레이드합니다    
이것이 `인 플레이스 배포`입니다   

`ASG 코드 배포`는 좀 더 복잡한데요  
`인 플레이스와 블루/그린의 두 가지 배포 방식`이 있죠  
인 플레이스라면 방금 본 것과 똑같이 하게 되는 거죠  
기존 EC2 인스턴스를 업데이트하는 겁니다  
ASG에 새로운 EC2 인스턴스를 생성했을 경우에는  
CodeDeploy에서 자동으로 배포를 받아오기 때문에 편리합니다  
ASG의 강점 중 하나죠  
이건 인 플레이스 배포였고요 

블루/그린 배포가 또 있는데  
이 경우엔 `새 오토 스케일링 그룹이 생성`되고  
설정이 복사되죠 그러면 예전 ASG에  
해당하는 EC2 인스턴스를 얼마나 유지할지  
결정해야 하고요 하나의 대상 그룹에서  
다른 대상 그룹으로 리디렉팅 하는 ELB는  
장애 조치됩니다 예시를 한 번 볼까요  

`블루/그린 배포이자 ELB`입니다  
ASG의 시작 템플릿 V1에 EC2 인스턴스들이 있는데요   
CodeDeploy가 V1 애플리케이션을  
이 EC2 인스턴스에 배포할 겁니다  
버전 2로 업그레이드하고 싶은 경우에는  
새로운 EC2 인스턴스가 생성되겠죠  
그러면 시작 패드 V2를 통해  
CodeDeploy가 애플리케이션을 이 EC2 인스턴스에 배포할 겁니다  
그럼 `ELB는 일시적으로 V1과 V2 인스턴스로부터 트래픽을 받게` 되고
`모든 것이 정상이라면 V1은 철거되고 블루/그린 배포가 완료`되는 겁니다

마지막으로, `재배포와 롤백`입니다  
롤백이란 이전에 배포된 애플리케이션의 리비전을  
재배포하는 건데요 이전으로 돌아가서  
배포를 롤백 하는 방법은 두 가지가 있습니다  
먼저 자동으로 하는 방법이 있습니다  
배포에 실패했을 때 혹은 CloudWatch 알람이  
`트리거 돼서 배포에 실패했다고 알려주는 경우`죠  
아니면 수동으로 하는 방법도 있습니다  
롤백을 비활성화하면 배포에 대해 롤백이 실행되지 않죠  
롤백을 하면 CodeDeploy 는 마지막으로 감지한  
성공한 리비전을 새로 배포하는데 이전으로 돌아가진 않습니다  
그냥 새로운 배포를 할 때 가장 나중에 성공한 배포를 사용하는 것뿐이에요  
그러니 복원된 버전이 아니고 새로운 배포에 해당하죠  

## CodeStar 개요

CodeStar 에 관해 살펴보겠습니다  
CodeStar 는 이전에 살펴봤던 모든 서비스를 그룹화하는 통합 솔루션입니다  
모든 서비스를 그룹화하는 통합 솔루션으로  
코드 저장을 위한 CodeCommit 와  
코드 설계와 테스트를 위한 CodeBuild  
코드 배포를 위한 CodeDeploy와  
인프라 프로비저닝을 위한 CloudFormatoion  
전체 파이프라인 조정을 위한 CodePipeline 와   
모니터링을 위한 CloudWatch 같은  
모든 도구를 한 번에 볼 수 있는 것입니다  

CodeStar를 이용해서 클릭 몇 번만 하면  
Python 에서 EC2의 프로젝트를 시작할 수 있고  
백 엔드에서 자동으로 생성됩니다  
따라서 CodeCommit, CodeBuild CodeDeploy 등이 있는데  
개발자에게 매우 편리한 도구로  
제대로 실행되는지 확인만 하면 됩니다  
그리고 CodeStar 지원 언어는  
나중에 더 늘어날 수도 있지만 지금은 C#, Go, HTML5, Java, Node.js, PHP, Python 그리고 Ruby입니다

CodeStar에는 문제 트래킹 도구가 있고    
이 도구를 문제 추적에 사용하면  
JIRA 또는 GitHub의 문제와 통합되어서  
사용하기 정말 편합니다  
또, Cloud9 도구를 사용하면 코딩을 통합할 수 있습니다  
web IDE로 웹 형식으로 클라우드에서 바로 코드를 코딩할 수 있습니다  
사용 불가한 리전도 있지만 실습으로 살펴보겠습니다  
또, 모든 구성 요소를 볼 수 있는 대시보드도 있습니다  
CodeStar는 무료 서비스이고 CodeCommit, CodeBuild 등과  
같은 다른 모든 서비스는 기본 사용량에 대한 비용만 지불하면 됩니다  
그리고 CodeStar는 통합 뷰가 아닙니다  
그래서 각 도구의 사용자 지정이 제한적이지만  
각 도구는 CodeStar의 기본 도구이기 때문에  
자체 콘솔에서 사용자 지정을 할 수 있습니다  

## CodeArtifact 개요

이번엔 CodeArtifact 을 살펴보겠습니다  
소프트웨어를 설계할 때 자체 소프트웨어가 의존하는  
`다른 소프트웨어를 사용하는 것으로 코드 종속성`이라고 합니다  
소프트웨어 설계 때마다 일반적으로 저장소에  
소프트웨어를 푸시한 뒤 다른 소프트웨어를 그 위에 설계합니다  
그래서 완전 종속성을 가지는데 이 완전 종속성 웹을  
Artifact 관리라고 합니다  
일반적으로 Artifact를 사용할 때는  
자체 Artifact 관리 시스템을 설정합니다  
개념이 조금 복잡할 수 있는데  
CodeArtifact 를 사용하면 소프트웨어 개발을 위한    
`보안, 확장성, 비용 효율적인 Artifact 관리 시스템`을  
설정할 수 있습니다  
더 많은 장점은 도표로 설명하겠지만  
`Maven, Gradle, npm, yarn twine, pip, NuGet 과 같은 일반 종속성 관리 도구와 통합`할 수 있습니다  
개발자와 CodeBuild 모두 CodeArtifact를 사용해  
`AWS 클라우드의 Artifact에서 직접 종속성을 검색`할 수 있는 것입니다  
도표로 이해하시면 훨씬 쉽게 이해하실 거예요  
`CodeArtifact 에서 모든 Artifact 는 VPC와 AWS 안에 있습니다`  
때때로 다른 Artifact 관리 시스템을 사용하면  
AWS 외에 타사를 이용하거나  
EC2 인스턴스에 남을 수 있는  
자체 Artifact 측정 시스템을 배포해야 합니다  
예를 들어, 이 경우에는 VPC 내에 있을 것입니다  
CodeArtifact 로 도메인을 정의하는데  
각 도메인은 일련의 저장소일 뿐입니다  
개발자의 입장에서 좋은 점이 있는데요  
그 예를 들어 보면  
JavaScript 개발자가 npm 명령을 실행해  
JavaScript 패키지의 종속성을  
CodeArtifact 로 불러오면 CodeArtifact 는  
공용 Artifact 저장소의 프록시가 됩니다  
그래서 JavaScript 개발자 대신  
공용 Artifact 저장소로 직접 도달하고  
CodeArtifact에 도달하는데  
이는 공용 Artifact 저장소로 연결되어  
요청이 프록시 되는 것입니다  
그 이유는 두 가지가 있는데 첫 번째는 네트워크 보안입니다  
Javascript 개발자는 오직 CodeArtifact 와  
통신하고 CodeArtifact는 공용 저장소 요청에  
프록시를 사용하지만 종속성 또한 불러와서  
CodeArtifact 자체에 캐시되는데  
이는 공용 Artifact 저장소에서  
종속성이 사라진다고 해도  
CodeArtifact 내부에 복사본이 있는 것으로  
향후에 코드가 언제나 설계되도록 하는 것이 좋습니다  
JavaScript뿐만 아니라 pip을 사용하는 Python과  
NuGet을 사용한 .NET과 Java를 사용한 Marven에서도 실행됩니다  
그래서 모두 CodeArtifact에서  
자체 저장소로 프록시 될 수 있습니다  
두 번째는 자체 Artifact를 푸시하는 것입니다  
IT 리더나 개발자는 CodeArtifact 내부의  
다른 저장소로 푸시하는 패키지를 생성하거나  
승인할 수 있는데 이는 모든 Artifact가  
VPC의 한 곳에 배치되고  
모든 것은 CodeArtifact 관리 시스템 내부의  
모든 코드에 따라  
다르다는 것을 의미합니다  
그리고 개발자가 CodeArtifact 외부에서  
Artifact를 얻으면 CodeBuild에서도 가능합니다  
이는 공용 저장소에서 불러오는 대신에  
CodeArtifact에서 직접 모든 정보를 불러올 수 있다는 것입니다  

## CodeGuru 개요

Amazon CodeGuru에 관해 살펴보겠습니다  
머신 러닝 기반의 서비스로 두 가지 기능이 있습니다  
첫 번째는 `자동화된 코드 검토`이며  
두 번째는 `애플리케이션 성능 권장 사항`입니다  
개발자가 코드를 푸시 하면  
대부분 다른 개발자가 코드를 검토합니다  
그리고 코드가 프로덕션에 배포되면  
`코드의 성능을 모니터링해야 하고 성능을 확인해서 버그를 감지할 수도 있는데    
CodeGuru 에서는 자동으로 할 수 있죠`  

CodeGuru Reviewer 에서 정적 코드 분석으로 자동으로 코드를 분석합니다  
예를 들어, CodeCommit 또는 GitHub 에서  
저장소에서 코드를 배포하면  
CodeGuru 에서 모든 줄의 코드를 확인하고
`버그나 메모리 누수 또는 이전에 발생한 것을 감지`해  
실행 가능한 권장 사항을 제공합니다  
머신 러닝 기능이 있기 때문에  
다른 reviewers 가 버그를 감지하기 전에 버그를 감지해 매우 편리하죠  
그리고 CodeGuru Profiler 는  
런타임 또는 프로덕션 중에  
애플리케이션에 관한 가시성 또는 권장 사항을 제공합니다  
그래서 애플리케이션을 설계하고 테스트하면  
CodeGuru Profiler 는  
비용이 높은 사전 프로덕션의 코드 줄을 감지하고 최적화하며  
애플리케이션을 배포할 때  
실시간으로 애플리케이션을 측정하고  
CodeGuru Profiler는 프로덕션에서 성능과  
비용 개선 사항을 식별해  
코드에 직접 권장 사항을 제공합니다  
여기까지 CodeGuru 의 기능입니다  
더 자세히 알아보면  
CodeGuru Reviewer는 커밋(commit)을 보고  
언제든지 코드를 푸시하면  
잘못된 코드줄을 알려줍니다  
정말 편리한 기능입니다 그리고 중요한 문제나  
`보안 취약점과 찾기 어려운 버그를 식별`하죠    
예를 들어, 코딩 모범 사례를 구현해 볼 수 있는데  
`리소스 누수를 찾거나 보안 감지`를 할 수 있고  
이 경우에는 보안 허점이나 입력값 검증을 생성할 수 있습니다  
이런 방식으로 머신 러닝과 자동화된 추론을 사용합니다  
어떻게 사용하냐고요? 수천 개의 오픈 소스 저장소와  
CodeGuru로 분석한 코드 분석이 있고  
Amazon.com 저장소에도 코드 분석이 있어  
머신 러닝을 통해 Code reviewer가 학습합니다  
이는 Java와 Python을 지원하고 GitHub와  
GitHub, Bitbucket, CodeCommit와 통합되어 있습니다  
이것이 전부가 아니고 더 늘어날 수도 있는데  
자세히 알 필요는 없습니다  
CodeGuru와 CodeGuru Reviewer  
CodeGuru Profiler만 알면 됩니다  
Profiler는 애플리케이션이 프로덕션 또는 사전 프로덕션 중일 때  
애플리케이션의 런타임을 이해하도록 하며  
예를 들면, 로깅 루틴에서 CPU 용량을 과도하게 사용하는  
이유를 확인합니다  
따라서 코드 비효율성을 식별 및 삭제하고  
애플리케이션 성능을 향상시키는데 예를 들어, CPU 사용률과  
컴퓨팅 비용을 낮추고 히프(heap) 개요를 제공해서  
어떤 오브젝트가 메모리 공간을 많이 차지하는지 식별합니다  
또한, 애플리케이션에 이상이 있을 때 이상 탐지도 가능합니다  
AWS 클라우드, 온프레미스에서 실행되는 애플리케이션도 지원하고  
CodeGuru Profiler로 모니터링할  
애플리케이션에 최소한의 오버헤드가 발생합니다  
강의는 여기까지입니다 다시 말씀드리면 CodeGuru와  
CodeGuru Reviewer와 Profiler의 개요만 알아도 됩니다  
다음 강의에서 뵙겠습니다

# AWS CloudFormation

코드형 인프라는 무엇일까요?  
지금까지 우리는 수동으로 많은 작업을 해 왔습니다  
`일래스틱 Beanstalk 로 약간 자동화`했고  
`CodeBuild 와 CodePipeline 으로 CICD를 자동화하도록 파이프라인을 설정`했습니다

하지만 `이런 작업은 복제하기가 어렵습니다`   
다른 리전에서 복제하려면 여기저기 계속 클릭하는 지루한 작업을 해야 하죠  
다른 AWS 계정에서 복사하는 것은  
심지어 더 고통스럽고 또는 회사 동료가
모든 삭제해서 내 리전에서 전부  
다시 생성해야 하는 것은 악몽이나 다름없습니다  

그래서 `코드가 되는 인프라`가 필요한데  
이 새로운 개념은  
꽤 새로운 현상이고 IT 계의 새로운 트렌드이며  
코드형 인프라라고 합니다  
이는 `작성할 코드를 배포하고 순서대로 업데이트를 생성해 인프라를 삭제`하는 것입니다  
이때 CloudFormation 를 사용하죠
CloudFormation 은 모든 리소스에 관한  
AWS 인프라 개요를 선언하는 방식으로 대부분 지원됩니다  
가상 CloudFormation 템플릿에  
보안 그룹과 이 보안 그룹을 사용한  
2개의 EC2 머신과 이 머신에 관한  
2개의 탄력적 IP와 S3 버킷을 원하고  
이 머신과 연결된 로드 밸런서가 필요한다고 할 때  
이렇게 선언하는 것입니다  
CloudFormation 이 필요하고  
CloudFormation 이 지정한 올바른 구성을  
모두 순서대로 생성해야 한다고 선언하는 것이죠  
이미 느끼셨겠지만  
CloudFormation 의 장점은  
첫 번째는 `코드형 인프라를 사용해 수동으로 생성되는 리소스가 없어 제어하기 좋다는 것`입니다  
모든 코드는 예를 들어 `Git 으로 버전 관리할 수 있어 CloudFormation 의 버전 관리`를 할 수 있습니다  
그리고 `인프라의 모든 변경 사항은 코드 검토를 통해 검토`합니다  
비용 측면에서 CloudFormation 자체는 무료이지만 생성한 모든 스택에는 식별자가 있어  
손쉽게 스택의 비용을 추적할 수 있으며 CloudFormation 템플릿으로  
리소스 비용을 추산할 수 있습니다  
개발 환경, 저용량의 AWS 계정에서 CloudFormation 을 사용한
비용 절약 전략이 필요하다면 자동으로 오후 5시에  
모든 템플릿을 삭제하고 오전 8시에 재생성 할 수 있습니다    
코드형 인프라이기 때문에  
모두 다시 생성할 수 있고 많은 비용을 절약할 수 있죠  

CloudFormation 의 다른 장점은 `생산성`입니다  
`원하는 만큼 즉흥적으로 인프라를 삭제하고 재생성` 할 수 있습니다    
프레젠테이션을 생성하면 자동으로 도표가 생성되도록 할 수 있습니다  
이것이 선언형 프로그래밍으로 순서와 조정의 측면에서  
순서를 파악할 필요가 없습니다  
CloudFormation 에서 추적합니다

그리고 관심 분리도 있는데  
많은 앱과 층에 원하는 만큼의 스택을 가질 수 있어  
서브넷의 모든 네트워크를 생성하는 VPC CloudFormation 스택이  
가장 일반적입니다  
애플리케이션 스택은 배포할 각 애플리케이션에  
애플리케이션 CloudFormation 스택이 있는 것인데  
일래스틱 Beanstalk에서도 이미 살펴봤습니다  
일래스틱 Beanstalk에서 환경을 생성할 때마다  
이면에서는 CloudFormation 템플릿을 생성한 것입니다    
여기서 활용하려는 개념은  
작업할 것이 많은 만큼 시간을 낭비하지 않고  
웹에서 활용할 수 있는 CloudFormation 템플릿을  
활용하는 것입니다  
방대하지만 활용할 수 있는 문서도 있는데요  
가끔은 찾기 힘들지만  
모든 정보를 얻을 수 있습니다  

CloudFormation의 원리는 무엇일까요? Amazon S3에 템플릿을  
업로드하면 CloudFormation 이 가져오는데  
템플릿을 업로드할 때  
이전 템플릿은 수정할 수 없는 것입니다 다음 강의에서 다루겠지만  
여기서 해야 할 것은  
AWS에 새 버전의 템플릿을 업로드하는 것입니다  
그러면 CloudFormation에서 버전 1과 2의 차이점을 파악하고  
업데이트에 필요한 것을 파악합니다  
스택은 이름으로 식별되는데  
이름이 길 수도 있으며 
`스택을 삭제하면 모든 단일 Artifact와 CloudFormation에서 생성한 모든 스택도 함께 삭제`됩니다    
생성한 모든 리소스를 `클릭 한 번으로 확실히 모두 삭제할 수 있는 장점`이 있습니다  
CloudFormation 템플릿을 배포하려면 수동으로  
템플릿을 수정하거나 CloudFormation designer와  
콘솔에 매개변수를 입력하는 식이 있고  
자동으로 텍스트 에디터를 사용해 YAML 파일에서 템플릿을 수정하고  
`템플릿 배포에 Amazon CLI 즉, 명령줄 인터페이스`를 사용할 수 있습니다  
플로우의 일부 자동화를 원할 때 추천하는 방식이지만  
두 방식 중 하나를 자유롭게 선택하면 됩니다  
이 섹션에서 블록 설계에 관해 많은 것을 학습할 것입니다  
템플릿 구성 요소가 있어 리소스를 얻을 수 있는데  
리소스는 템플릿에서 선언할 AWS 리소스이며  
필수적인 부분입니다  
`리소스를 지정하지 않으면 CloudFormation 템플릿이 실행되지 않죠`    
EC2 머신, 탄력적 IP 보안 그룹, 로드 밸런서 등  
생각나는 것 모두 리소스가 될 수 있습니다  
매개변수는 사용자가 템플릿을 참조하도록  
템플릿에 요청할 수 있는 동적 입력값입니다  
매핑은 템플릿의 정적 변수이며  
출력값은 템플릿에서  
일부를 내보내면  
다른 템플릿에서 참조하는 것입니다  
조건부는 조건의 리스트로  
If문이 생성된 것을 제어하는 것입니다  
그리고 메타데이터가 있습니다 모두 자세히 살펴보니까  
걱정하지 않으셔도 됩니다 때가 되면 다 이해하실 거예요  
`템플릿에는 헬퍼`가 있는데  
템플릿 내에서 참조하거나 연결할 수 있고  
데이터를 변환하는 기능도 사용할 수 있습니다    

## CloudFormation 업데이트 및 스택 직접 삭제

0-just-ec2.yaml

~~~
Resources:
  MyInstance:
    Type: AWS::EC@::Instance
    Properties:
      AvailabilityZone: us-east-1a
      ImageId: ami-a4c7edb2
      InstanceType: t2.micro
~~~

스택을 업데이트

ec2-with-sg-eip.yaml

~~~
Parameters:
  SecurityGroupDescription:
    Description: Security Group Description
    Type: String
    
Resources:
  MyInstance:
    Type: AWS::EC@::Instance
    Properties:
      AvailabilityZone: us-east-1a
      ImageId: ami-a4c7edb2
      InstanceType: t2.micro
      SecurityGroups:
        - !Ref SSHSecurityGroup
        - !Ref ServerSecurityGroup
        
  # an elastic IP for our instance
  MyEIP:
    Type: AWS::EC2::EIP
    Properties:
      InstanceId: !Ref MyInstance
      
  InstanceSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow http to client host
      VpcId: Ref: myVPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
~~~

## YAML 단기집중과정

YAML은 AWS 상에서 다양한 종류에 사용됩니다  
CloudFormation에도 마찬가지입니다  
CloudFormation은 `YAML과 JSON을 지원`합니다  
이들은 스크립트 언어 또는  
데이터 언어로 CloudFormation에서 사용하죠  
솔직히 말씀드리면  
`JSON은 CloudFormation에서 사용하기 그닥 좋진 않습니다`  

## CloudFormation 리소스

리소스를 이야기해 봅시다 CloudFormation 템플릿의 핵심이며 필수 항목입니다  
`CloudFormation 템플릿은 리소스 블록 없이 동작하지 않습니다` 
리소스라는 이름이 암시하는 대로 다른 AWS 구성 요소를 표시합니다  
동의어로 만들어지고 구성됩니다  
`리소스가 선언되면 서로를 참조`할 수 있습니다  
리소스끼리 연결할 수 있죠  
예를 들어 `보안 그룹과 EC2 인스턴스를 연결`할 수 있습니다  
AWS가 리소스의 생성, 업데이트와 삭제를 해 주니 굉장히 좋습니다  
224개가 넘는 리소스가 있습니다  
따라서 전부 이야기해 드릴 수 없는데요  
모든 리소스는 다음의 형식을 따릅니다  
aws 다음에 제품의 이름이, 그리고 데이터 종류의 이름이 나옵니다  
보통, 이 식별자 변수를 읽어 무엇을 만드는지 알 수 있습니다  

리소스 관련 문서를 어디에서 찾을 수 있을까요?  
이 링크에 모든 리소스가 있습니다  
모든 리소스를 제가 알려드리기 어려우니  
이 링크에서 어떻게 리소스를 찾고  
문서를 읽는지 알려드리겠습니다  
같이 문서를 하나 읽어보겠습니다  

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html

예를 들어, EC2 인스턴스 문서를 읽고 이해해 보죠  
제가 드린 첫 번째 웹 페이지는  
`AWS 리소스 유형 참조`입니다    
CloudFormation이 지원하는  
모든 리소스를 포함합니다  
리소스 명명 규칙은 여기 있고 스크롤을 내리면  
더 많은 리소스가 보입니다  
세어보세요, 정말 많습니다  
여기서 알 수 있는 것은 거의 모든 것에 리소스를 만들 수 있다는 거죠  
스크롤을 내려서 알만한 것을 찾겠습니다 오토 스케일링이 있네요  
오토 스케일 그룹을 만드는 법을 알고 있죠  
오토 스케일링 그룹을 만들고  
스케일링 정책과 구성을 실행하는 것을  
이 CloudFormation 리소스를 통해 할 수 있습니다  
스크롤을 내리면 CodeBuild 로  
코드를 커밋, 배포, 파이프라인할 수 있습니다  
이전에 다 본 것들로 우리가 할 수 있죠  
스크롤을 내리면 EC2 인스턴스,  
탄력적 IP, 보안 그룹이 있습니다

## CloudFormation 매개변수

리소스를 살펴보았으니 두 번째로 중요한 매개변수를 봅시다  
매개변수는 AWS CloudFormation 템플릿에 `입력값을 제공하는 방식`입니다  
`템플릿을 다른 회사나 계정, 리전에서 재사용하기 원한다면 알아야 할 중요한 사항`입니다  
어떤 입력값은 미리 결정할 수 없습니다  
예를 들어 인스턴스에 연결되는 키 페어가 있습니다  
매개변수는 강력하고 제어할 수 있으며  
`템플릿에서 발생하는 오류를 유형 덕분에 예방`할 수 있습니다  
실습에서 매개변수를 사용했었는데요  
보안 그룹 설명을 지정했었습니다  
문자열이었고 보안 그룹 설명을 요청하고  
보안 그룹에서 사용했습니다  
매개변수를 사용하기 전에  
스스로에게 `"CloudFormation 리소스 구성이 향후에 바뀔 가능성이 있는가?"`를 물어봐야 합니다    
`만약 그렇다면 매개변수를 사용`해야 합니다  
`매개변수화함으로써 내용을 바꾸기 위해 템플릿을 재업로드할 필요는 없습니다`  
`매개변수를 사용하면 더 안정적이고 더 모듈화`됩니다  
프로그래밍을 한다면 매개변수의 장점을 알고 계실 거예요  
`매개변수는 다른 설정을 가질 수 있고` 
`다른 방식으로 제어`할 수 있습니다  
시험에서 이 모든 것을 알아야 할 필요는 없지만  
관심 있으신 분들을 위해  
이름을 알려드리겠습니다 유형에는 문자열, 숫자,  
`콤마로 구분된 리스트, list<Type>, AWS 매개변수`가 있습니다  
설명과 제약, 제약 설명, 문자열의 최소/최대 길이, 숫자의 최소/최댓값,  
기본값, 값의 숫자를 제약하고 싶을 때  
사용하는 허용 값이 있습니다  
`허용 패턴이란 사용자의 정규 표현식을 확인하고 싶을 때 사용하는 것`입니다  
`NoEcho는 비밀을 전달할 때 사용`합니다  
다양한 최적화 방식과 매개변수가 있습니다  

지금까지 우리가 한 것은 간단한 문자열 매개변수였는데요  
시험을 위해 알아야 할 것은 그것으로 충분합니다  
매개변수는 어떻게 참조할까요?  
`Ref 라는 함수를 사용`해야 합니다  
Ref 와 그 함수를 보는 것은 처음인데요  
기본적으로 템플릿에 있는 흥미로운 함수들은  
강화하고 변수들을 연결할 수 있습니다  
`Ref 함수는 가장 많이 사용되는 것으로 매개변수를 참조할 때 사용`합니다    
이렇게 함으로써 템플릿의 어느 곳에서나 매개변수를 사용할 수 있습니다   
즉, 리소스나 어떤 유형의 입력값, 매개변수, 구성에서 사용할 수 있죠  
YAML 에서는 참조 함수를 줄여서 
`!Ref` 라고 합니다  
이것으로  
구문을 쉽게 알아볼 수 있습니다  
Ref 에서 FN 열을 호출할 수도 있습니다  
여러분 마음이죠  
대부분 !Ref 로 줄여서 사용할 것입니다  
`함수는 템플릿에 있는 다른 요소를 참조할 때도 사용`합니다  

## CloudFormation 매핑

`매핑은 CloudFormation 템플릿에서 고정 변수`입니다  
하드 코딩되어야 합니다 dev, prod와 같은 환경이나  
AWS 리전이나 AMI 유형 등  
`사용자 환경에 따라 일부 값을 하드 코딩해야 할 때 유용`합니다  
모든 값을 명시적으로 템플릿에 쓰여야 합니다  

여기 매핑의 예시가 있습니다  

~~~
Mappings:
  Mapping01:
    Key01:
      Name: Value01
    Key02:
      Name: Value02
    Key03:
      Name: Value03
~~~

이렇게 작성해야 하는데요 매핑 섹션이 있고  
매핑 이름이 있습니다 키가 있고  
그 밑에 키의 코드 이름과 값이 있습니다  
저 수준의 아키텍처입니다  
좀 더 구체화하기 위해 AMI에 리전을 매핑하는 리전 맵이 있죠  
우리는 us-east-1, us-west-1, 또는 eu-west-1에 있고  
32bit 또는  
64bit 아키텍처에 따라  
사용해야 하는 AMI ID가 보입니다  
전반적으로 하드 코딩되어 있고  
템플릿이 실행되는 것에 따라  
사용할 AMI를 보여줍니다  

매핑과 매개변수는 언제 사용할까요?  
`사용할 모든 값을 미리 알고 있을 때 매핑이 유용`합니다    
예를 들어, AMI ID의 경우 리전, AZ, AWS 계정, 환경 등과 같은  
변수에서 추론될 수 있습니다  
여러분이 생각할 수 있는 변수에서 말이죠  
템플릿을 좀 더 안전하게 제어할 수 있게 해줍니다  
만약 사용자별 특정값이 필요하다면  
`사용자가 값을 입력해야 하고 그 값이 무엇일지 사전에 알 수 없습니다`    
이 경우 매개변수를 사용합니다  
`매핑 값에 접근하려면 Fn::FindInMap 을 사용`합니다  
특정 키로부터 값을 반환하는데요  
약자로 된 구문은 이것입니다  
`!FindInMap 로 사용`하고   
MapName, TopLevelKey, SecondLevelKey 가 있습니다  
즉, 3개의 매개변수가 있습니다  
시험을 위해 구문을 알아야 합니다  
이 CloudFormation 템플릿을 살펴보면  
전에 정의한 RegionMap 이 있고  
EC2 인스턴스를 만들어서  
올바른 AMI ID를 참조하려면  
ImageId에 대한 FindInMap 함수를 사용해야 합니다  
첫 번째는 MapName으로  
여기 이름이 RegionMap이니 RegionMap을 사용합니다  
두 번째로 우리가 있는 AWS 리전을 참조하고 싶습니다  
따라서 의사 매개변수를 사용합니다 그리고 Ref 함수가 나오죠  
즉, CloudFormation 템플릿이 실행 중인 AWS 리전을 참조합니다  
예를 들어 us-east-1에서 실행 중이면 이 블록에 있습니다  
SecondLevelKey가 32이면  
32 키를 보고 이 값을 가져옵니다  
ami-6411e20d이 선택될 것입니다  
매핑 관련 알아야 할 것은 이것이 전부입니다  
FindInMap 함수의 구문을 기억하고  
매핑은 템플릿에 명시적으로 쓰여야 한다는 것을 기억해 주세요  

## CloudFormation 출력

출력을 알아보겠습니다  
출력 섹션은 선택 사항이지만 선택적 출력을 선언할 수 있습니다  
만약 이 출력을 내보내면 다른 스택에서 값을 불러올 수 있죠  
스택은 CloudFormation 템플릿입니다  
즉, CloudFormation 템플릿을 연결할 수 있습니다  
`AWS 콘솔에서 출력`을 볼 수도 있고  
`AWS CLI를 이용하여 출력값을 빠르게 검색`할 수 있습니다  
`UI를 사용하여 직접 볼 수 있죠`  
예를 들어 네트워크 CloudFormation 템플릿에서  
`출력을 내보내기 하여`  
예를 들어, `VPC ID와 서브넷 ID를 얻을 수 있습니다`    
`이를 다른 CloudFormation 템플릿에서 재사용`할 수 있죠  
따라서 전문가가 VPC와 서브넷의 자체적인 부분을 처리할 수 있고  
여러분은 개발자로 `이 값을 바로 참조하여 여러 스택에서 협업`할 수 있습니다    
여러분이 알아야 할 것은 CloudFormation 출력을 사용하고  
이들이 다른 CloudFormation 스택에서 참조된다면  
`다른 곳에서 참조 중인 출력이 있는 스택을 삭제할 수 없다는 것`입니다  
알아두면 좋은 내용입니다  

출력의 예시를 살펴보겠습니다  
여기에서는 SSH 보안 그룹을 템플릿의 한 부분으로 만들었습니다

~~~
Outputs:
  StackSSHSecurityGroup:
    Description: The SSH Security Group for our Company
    Value: !Ref MyCompanyWideSSHSecurityGroup
    Export:
      Name: SSHSecurityGroup
~~~

이 값을 출력으로 내보내고  
다른 템플릿에서  
해당 보안 그룹 ID 값을 사용합니다    
구문은 간단한데요 여기 출력 섹션이 있고  
보안 그룹의 이름과 설명이 있습니다  
즉, 우리 회사를 위한 SSH 보안 그룹이죠  
이것이 값입니다 리소스 내에서 생성된  
보안 그룹의 참조를 제공합니다  
그러면 여기 내보내기 블록에서 지정해야 하는데요  
이것은 선택 사항이라 지정하지 않으면  
값이 내보내지지 않고 가져올 수도 없게 됩니다  
따라서 내보내기 값을 지정하면  
이 값이 SSH 보안 그룹 ID이고  
SSH 보안 그룹이란 이름으로 내보내지게 됩니다  

값은 어떻게 가져올까요? 교차 스택 참조를 사용할 것입니다
보안 그룹을 이용하는 두 번째 템플릿을 만들겠습니다

~~~
Resources:
  MyInstance:
    Type: AWS::EC@::Instance
    Properties:
      AvailabilityZone: us-east-1a
      ImageId: ami-a4c7edb2
      InstanceType: t2.micro
      SecurityGroups:
        - !ImportValue SSHSecurityGroup
~~~

여기에서 `Fn::ImportValue 함수`를 사용합니다  
모든 스택이 삭제될 때까지 이전 스택은 삭제할 수 없습니다  
코드 스니펫을 살펴보면  
가장 아래 보안 그룹이 있고  
ImportValue 함수의 약어로 된 구문이 있습니다  
전과 같은 이름인  
SSH 보안 그룹을 참조합니다  
참고로, SSH 보안 그룹의 값을 내보내기 전에  
여기서 SSH 보안 그룹의 값을 가져옵니다  
출력과 내보내기는 시험에서 매우 자주 나오는 문제입니다  
만약 시험에서 어떻게 CloudFormation 템플릿을 연결하는지 묻는다면  
또는 하나에서 다른 하나로 어떻게 값을 검색하는지 묻는다면  
이 내용에 대해 알고 있어야 합니다 구문을 알아야 하고  
ImportValue 함수를 알고 있어야 합니다  

## CloudFormation 조건

조건은 리소스나 어떤 논리 문장에 기반한 출력의  
생성을 제어할 때 사용됩니다  
`조건은 원하는 대로 사용할 수 있습니다`  
일반적으로는 dev 모드, test 모드, prod 모드일 때 어떤 리소스를 만들거나 못 만들게 합니다  
`리전에 따라 사용할 수도 있고 매개변수의 값에 따라 사용할 수도 있죠`   
각 조건은 다른 조건, 매개변수 값,  
매핑을 참조합니다 따라서 여러분이 구성할 수 있습니다  
이를 정의하고 구체화하기 위해  
Conditions 란 블록 아래 조건을 만들어두었습니다  

~~~
Conditions:
  CreateProdResources: !Equals [ !Ref EnvType, prod ]
~~~

CreateProdResources 를 만든다면  
매개변수인 환경 유형,  
즉, EnvType이 여기 있고 참조로  
매개변수의 값이 prod,  
문자열 prod 와 같을 때   
전체가 참이 됩니다  
prod 리소스를 이용하여  
다른 리소스의 조건을 정의합니다  
어떻게 선택할지는 여러분에 달려있습니다  
여기에 사용할 수 있는  
`함수로는 And, Equals, If, Not, Or 함수`입니다  
논리 함수로 원하는 대로 구성할 수 있습니다

조건은 어떻게 사용할까요?  

~~~
Resources:
  MountPoint:
    type: "AWS::EC2::VolumeAttachment"
    Condition: CreateProdResources
~~~

이를 리소스, 출력 등에 적용할 수 있는데
예를 들어, MountPoint라는 리소스를 살펴보면  
AWS EC2 VolumeAttachment라는 유형입니다  
만약 이전에 만든 조건인 CreateProdResource가 참일 때  
이것이 만들어집니다  
조건이 어떻게 사용되는지 알아보았습니다  
유형과 같은 수준에 있어  
여기 리소스 이름 바로 아래 위치합니다

##  CloudFormation 내장 함수

`Ref 함수, GetAtt, FindInMap, ImportValue, Join, Sub, 그리고 조건 함수`입니다  
내용을 상기시켜드리겠습니다  
`Ref 함수는 가장 중요한 것으로 매개변수를 참조할 때 사용`합니다  
매개 변수를 참조하는 경우 매개변수의 값을 반환합니다  
보안 그룹 설명이 있는 실습에서 보았습니다

리소스를 참조할 수도 있는데  
CloudFormation 템플릿에서 참조할 때  
`해당 리소스의 물리적 ID가 반환`됩니다  
예를 들어, EC2 인스턴스를 참조하면 EC2 인스턴스 ID를 얻죠  
`줄여서 !Ref로 사용`합니다  
간단한 예시가 있습니다 서브넷을 만들었고  
속성 VpcId에 이전에 만든 VPC를 참조하고자 합니다  
이러면 VpcID를 얻습니다  
`리소스를 참조하는 경우 물리적 ID를 반환`합니다    
매우 중요하니 알아두세요  

리소스에서 다른 정보는 어떻게 얻을까요?  
`Ref 함수를 이용해서는 다른 리소스의 ID 정보만 얻기 때문`이죠  
무언가는 할 수 없게 됩니다  
이때 `GetAtt 를 사용하여 여러분이 만든 리소스의 속성`을 얻습니다  
모든 리소스와 이 리소스에 있는  
모든 속성의 리스트를 얻습니다  
공식 문서를 살펴봐야 하는데  
같이 살펴보고 이해해 보겠습니다  

https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-ec2-instance.html

EC2 인스턴스에서 Return Values 를 클릭합니다
Ref가 보입니다 Ref는 인스턴스 ID를 반환합니다
GetAtt 함수의 경우 가용 영역을 얻을 수 있고
DNS 이름, 사설 IP 등을 얻을 수 있습니다
여기 다 나와 있습니다 각 리소스에 있는 속성을 알기 원한다면
리소스의 공식 문서를 살펴보세요
예를 들어 EC2 머신의 AZ를 원한다면
어떻게 하는지 알아보았습니다

> ec2 instance
~~~
Resources:
  EC2Instance:
    Type: "AWS::EC2::Instance"
    Properties:
      ImageId: ami-1234566
      InstanceType: t2.micro
~~~

> ec2 volume
~~~
NewVolume:
  Type: "AWS::EC2::Volume"
  Condition: CreateProdResources
  Properties:
    Size: 100
    AvailabilityZone:
      !GetAtt EC2Instance.AvailabilityZone
~~~

Resources 블록으로 가서 ImageId와  
InstanceType이 있는 EC2Instance를 갑니다  
AZ를 얻고자 합니다 예를 들어, EBS 볼륨을 만들 때  
Resources 아래에 NewVolume을 만들고  
유형은 EC2::Volume입니다  
조건은 이전과 같고  
중요한 것은 속성을 살펴보면  
크기가 100이고 AZ는 GetAtt 함수를 사용합니다  
EC2.AvailabilityZone, 즉, EC2 인스턴스는 왼쪽에서  
똑같은 이름을 바로 가져오고 점은  
GetAtt 함수를 사용하여  
가용 영역을 가져옵니다  
시험에 자주 나오는 문제입니다  
`리소스의 속성을 어떻게 가져오는지 묻는다면 GetAtt 함수를 사용`한다고 답변해야 합니다

FindInMap 도 본 적 있는데요 FindInMap 함수를  
다음의 구문으로 줄여서 표현합니다 
`MapName, TopLevelKey, SecondLevelKey 를 지정`해야 합니다  

~~~
Mappings:
  RegionMap:
    us-east-1:
      "32": "ami-12341234"
      "64": "ami-asdasdas"
    us-west-1:
      "32": "ami-12341234"
      "64": "ami-asdasdas"
    ap-southeast-1:
      "32": "ami-12341234"
      "64": "ami-asdasdas"
Resources:
  myEC2Instance:
    Type: "AWS::EC2::Instance"
    Properties:
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", 32]
      InstanceType: t2.small
~~~
  
예시에서는 FindInMap 함수를  
사용하여 ImageId를 찾고 우리가 있는 리전과  
아키텍처의 유형, 즉, 32 또는 64비트 인지에 따라 찾습니다

ImportValue 는 다른 템플릿의 출력으로    
`내보내기 된 값들을 가져올 때 사용`합니다  
이때 ImportValue 함수를 사용합니다  
다시 한번, 값을 가져올 때  
내보내기 된 ImportValue 의 이름을  
주면 됩니다 아주 쉽죠  

이제 `Join` 입니다 아직 본 적 없는데요  
구분자로 값을 결합할 수 있고 이것이 줄여서 표현한 구문입니다  

~~~
!Join [ delimiter, [ comma-delimited list of values ] ]
~~~

Join 을 선언하고 구분자 이름을 입력하고  
쉼표로 구분된 값의 리스트를 입력합니다  
구체적으로 살펴보자면 a:b:c 문자열을 만들기 위해  
":"과 함께 Join 함수를 사용합니다  
오른쪽처럼 a, b, c를 입력하면 됩니다

~~~
!Join [ ":", [ a, b, c ] ]
~~~

프로그래밍을 한다면 일반적인 함수입니다  
그러니 알아두세요  
내장 함수의 출력이 무엇인지를 물어볼 수 있습니다  
만약 Join을 사용하는 경우  
a, b, c 사이에 :을 입력하면 됩니다  

마지막으로 `Sub` 함수입니다  
`Sub 함수는 대체(Substitute)의 약어`입니다  
`문자열에서 값을 바꿀 때 매우 유용`합니다  
참조나 의사 변수와 함께 사용할 수 있고  
`문자열에는 반드시 $ 기호가 있어야 하고`  
변수 이름으로 시작해야 대체합니다  
조금 애매하지만, Sub은 대체할 때 사용한다고 기억하면 됩니다  
보면 바로 이해할 수 있을 거예요

~~~
!Sub
  - String
  - { VarName: VarValue, VarName: VarValue }
~~~

시험에서 본다면 Sub은 값을 대체할 때 사용합니다

마지막으로 조건 함수는  
예를 들어 ProdResources 만을 만들 조건으로  
여러 함수를 여기에서 사용할 수 있습니다  
이것은 내장 함수로  
`And, Equals, If, Not, Or` 과 시간이 지남에 따라  
CloudFormation에 추가되는 함수를 사용할 수 있죠  
사용해야 할 내장 함수는 이것이 전부입니다  
Fn::이 붙는 경우 또는 함수의 이름 전에  
! 기호가 붙는 경우
내장 함수라고 부릅니다
CloudFormation 함수는 여기까지입니다
도움이 되었길 바라며 다음 강의에서 뵙겠습니다

## CloudFormation 롤백

스택 생성에 실패하는 경우에는  
기본적으로 `모든 사항이 롤백됩니다 전부 삭제된다는 뜻`이죠  
`로그`를 통해서 어떤 일이 일어났는지를 알 수 있죠  
스택을 생성할 때 `롤백을 비활성화하는 옵션도 있습니다`  
어떤 일이 발생했는지 트러블 슈팅을 진행하고  
생성된 문제에 대해 좀 더 자세히 파악할 수 있죠  
이미 `생성되어 쓰이고 있는 스택을 업데이트`한다고 했을 때  
업데이트에 `실패하면 스택이 자동으로 롤백`되어서  
이전 작업 상태로 알려진 `그린 상태로 돌아갑니다` 업데이트 대상이었던 상태로 말이죠  
그리고 오류 메시지를 통해 로그에 어떤 일이 생겼는지도 볼 수 있습니다  

## CloudFormation ChangeSet, 중첩 스택 및 StackSet

먼저 ChangeSets 입니다 이미 보셨을 텐데  
스택을 업데이트할 때는 사전에 어떤 변경 사항이  
발생하는지를 알아야 그 신뢰도를 높일 수 있습니다  
따라서 ChangeSet 로  
`업데이트 성공 여부는 알 수 없지만 이전에 본 것과 같이 어떤 일이 생기는지는 알 수 있습니다`

여기 `원본 스택`이 있습니다   
새로운 스택을 업로드해서 ChangeSet 를 생성하는  
과정까지는 이미 실습에서 보신 바 있을 겁니다  
이제 이 ChangeSet을 직접 살펴보면서  
임의로 ChangeSet을 변경할 수 있고  
새로운 스택을 업로드하여 수정하기도 하면서  
이에 만족하는 경우에는 ChangeSet을 실행해서  
현재 CloudFormation 템플릿에 적용합니다  
이 모든 사항은 실습에서  
CloudFormation 스택을 업데이트하면서 보셨을 겁니다  

다음은 `중첩 스택 개념`을 보겠습니다  
중첩 스택은 CloudFormation 기타 스택의 일부입니다   
중첩 스택은 반복되는 패턴 즉 개별 스택의  
공통 구성 요소를 업데이트하고 이들을 다른 스택에서 호출합니다  
예시를 하나 들어 보죠  
`로드 밸런서의 구성이 재사용`될 때나  
`보안 그룹 구성이 재사용`될 때를 들 수 있습니다  
중첩 스택이 최선의 방법으로 간주되죠  
중첩 스택을 업데이트하려면 먼저 `상위 스택을 업데이트`해야 합니다    
이제 교차 스택과 중첩 스택의 차이점이 궁금하실 겁니다  
`교차 스택은 스택의 수명 주기가 서로 다를 때에 유용`합니다  
예를 들어서 VPC 스택과 이를 참조하는 또 다른 스택이 있는데  
이들이 서로 다른 수명 주기를 갖는다고 해 봅시다  
이 경우에는 Outputs Export 와 Fn::ImportValue 를 사용하는데  
흥미로운 함수죠 그리고 이때는  
export 값을 여러 스택으로 전달해야 합니다  
이 예시에서는 VPC 스택이 여러 스택에서  
재사용되므로 이 값을 내보내고  
가져올 필요가 있습니다 아주 타당한 개념이죠

반면에 중첩 스택은 구성 요소가  
`재사용 및 재생성되어야 할 때에 유용`합니다  
예를 들어서 애플리케이션 로드 밸런서를 적절히 구성해야 할 때에는  
중첩 스택을 통해 이를 분리할 수 있습니다  
중첩 스택이 상위 수준의 스택에서만  
영향을 미칠 때에 중요하다고 할 수 있죠  
스택 간에 공유되지 않는 겁니다 애플리케이션 스택을 예로 들 수 있는데  
RDS 중첩 스택, ASG 중첩 스택,  
ELB 중첩 스택이 포함되어 있고 두 번째 애플리케이션 스택으로  
모든 다른 중첩 스택들이 포함되는 경우가 있을 수 있습니다  

끝으로 `StackSets` 가 있습니다 이는 `단일 작업`으로    
`여러 계정과 리전에 걸쳐서 스택을 생성, 업데이트 또는 삭제`하는데  
`StackSet 을 통해서 여러 계정과 여러 리전에 스택을 적용`할 수 있는 거죠  
관리자 계정이 StackSet를 생성한 다음  
신뢰할 수 있는 계정이 StackSet로부터  
스택 인스턴스를 생성, 업데이트 또는 삭제할 수 있죠  
StackSet의 훌륭한 점은  
StackSet을 업데이트하면 연결된 모든 리전과 계정에 대한  
스택 인스턴스 또한 업데이트된다는 겁니다  
따라서 관리자 계정에서  
StackSet을 생성하면  
리전 1의 계정 A, 리전 2의 계정 A 리전 2의 계정 B까지 적용되는 거죠  
StackSet의 장점이었습니다  

## CloudFormation 드리프트

지금까지 인프라 생성에 CloudFormation이 아주 유용하다는 점을 살펴봤는데  
실상 CloudFormation는  
CloudFormation로 생성한 구성을 `수동으로 변경하는 데 대한 보호가 없습니다`  
따라서 여러분 `본인이 아닌 다른 사용자가 콘솔로 접근`하여   
CloudFormation 으로 생성된 `일부 리소스의 구성을 변경할 수가 있다는 겁니다`  
이를 `드리프트(Drift)`라고 합니다 
`드리프트를 감지하는 CloudFormation drift 기능`이 있는데  
모든 리소스가 지원되는 것은 아니지만 이 URL에서 확인해 보실 수 있습니다

> https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-stack-drift-resource-list.html

# AWS의 모니터링 개요

모니터링은 왜 중요한 걸까요? 여러분은 이미 답을 아실 겁니다  
애플리케이션 배포 방법도 알고 안전하게 이를 마쳤으며  
최고의 AWS 구성 요소를 사용해서 코드형 인프라로 자동으로도 수행합니다  
배포 방법에 대해 꿰고 있죠  
애플리케이션이 배포되고 나면  
사용자들은 이 애플리케이션의 구축 방법에는 관심을 두지 않습니다  
일래스틱 Beanstalk 을 사용했는지  
코드형 인프라를 사용했는지 신경 쓰지 않죠  
솜씨는 우리 사이에서나 자랑하는 것이고 사용자들은 크게 개의치 않습니다  
사용자들은 애플리케이션이 작동하는지만 중요하게 보죠  
작동에 있어서는 일례로 지연 시간이 중요합니다  
시간이 지남에 따라 애플리케이션 지연 시간이 증가한다면 왜일까요?  
정지가 발생하여서  
고객 경험을 저하시켜서는 안 되겠죠  
여전히 좋은 상태여야 할 겁니다 가용성 높은 배치를 수행한 까닭이니까요  
사용자가 IT 부서에 불만이라도 남기면 영 좋지 못한 일이라고 할 수 있죠  
사용자가 문제에 대해 우리에게 알리는 것이 아니라  
사전에 문제를 해결할 수 있도록 트러블 슈팅을 수행하는 것이 바람직합니다  
내부적으로는 다음을 생각해야겠죠 문제가 발생하기 전 막을 수 있는가?  
만약 발생해도 사용자가 발견하기 전 먼저 발견할 수 있는가?  
성능과 비용을 모니터링할 수 있는가?  
정지 패턴과 스케일링 방식에 대한 추이를 살펴볼 수 있는가?  
이 모니터링으로 인해 무엇을 배우고 또 개선할 수 있는가?  
`따라서 모니터링은 아주, 아주 중요합니다`  
AWS에는 CloudWatch라는 것이 존재하는데   
CloudWatch로는 지표를 수집할 수 있습니다  
모니터링을 위해 로그를 수집하고 로그 파일을 분석하죠  
AWS 환경에 특정 이벤트가 발생했을 때 알림을 보내기도 합니다  
지표 이벤트 및 이벤트 로그에 실시간으로 반응해서 알람을 보내기도 하죠  
다음으로 X-Ray가 있는데 비교적 새로운 서비스라  
아직 크게 인기가 좋지는 않으나 이들 중 가장 멋지다고 생각합니다  
이를 통해서 애플리케이션 성능과 오류에 트러블 슈팅을 수행하는 데  
지연 시간을 살펴보고 오류를 실시간으로 확인할 수 있습니다  
이를 통해서 마이크로서비스 분산 추적 작업이 가능합니다  
따라서 서로를 호출하거나  
S3, DynamoDB 등의 AWS 구성 요소를 추적하는 등의 작업 시에  
애플리케이션이 어떻게 호출을 수행하고  
이에 소요되는 시간을 알 수 있으며 모든 호출을 추적해 줍니다  
CloudTrail로는 API 호출에 대한  
내부 모니터링을 수행할 수 있고 사용자가  
AWS 리소스를 변경한 내용에 대한 감사를 수행할 수 있습니다  
전반적으로 이 세 가지 기술을 이용하면  
탄탄하게 AWS를 모니터링할 수 있습니다  

## CloudWatch 지표

CloudWatch 는 코스 전반에 살펴봤으나  
짧게 요약해 보겠습니다 먼저 CloudWatch 지표를 보면  
`AWS의 모든 서비스에 대한 지표로 제공`되며  
여러분은 지표의 의미를 파악할 필요가 있습니다  
보통 지표의 이름을 보고 알 수 있죠  
CPUUtilization, NetworkIn 그리고 지표의 동작을 통해서도  
서비스가 어떻게 작동하는지 그 원리를 알 수 있습니다  
트러블 슈팅도 이를 기반으로 수행할 수 있죠  
즉 지표는 이름공간에 속하며 지표의 특성인  
배열을 갖고  
배열의 예로는 인스턴스 ID 환경 등을 들 수 있습니다  
`지표당 최대 10개의 배열`까지 선택할 수 있죠  
지표는 `타임스탬프를 가지며 CloudWatch 지표 대시보드를 생성`할 수 있습니다  
본 코스에서는 EC2 지표와  
EC2 세부 모니터링에 대해 알아본 바 있습니다  
기본적으로 `EC2 인스턴스가 5분마다 지표`를 갖습니다  
추가적으로 `비용이 드는 세부 모니터링을 활성화`한다면  
`1분마다 지표 데이터`를 얻을 수 있습니다  
이를 활성화하면  
EC2 인스턴스의 지표 변화에 보다 빠르게 반응할 수 있고  
`스케일 아웃 또는 인 작업 속도를 높이려는 경우`에도  
ASG 상에서 이점을 얻을 수 있습니다  
이 기능을 통해 10개의 세부 모니터링 지표를 확보할 수 있죠  
참고로 EC2 메모리 사용량은  
`기본적으로 RAM이 푸시되지 않으며 인스턴스`에서  
사용자 지정 지표로서 푸시되어야 합니다  
사용자 지정 지표를 푸시하는 방법에 대해서는 곧 살펴보도록 하죠

## CloudWatch 사용자 지정 지표

본 강의 과정에서 지금까지 살펴본 모든 지표는  
AWS 서비스의 기본값으로 도출해낸 값이었으나  
`CloudWatch 를 위한 사용자 지정 지표를 사용할 수도 있습니다`  
고유의 지표를 정의할 수 있는 거죠  
가령 `RAM 에 메모리 사용량을 푸시`한다거나  
`CloudWatch 나 디스크 공간 애플리케이션에 로그인한 사용자 수` 등이 있죠  
이를 위해서 `PutMetricData 라는 API 호출`을 사용합니다  
세그먼트 지표에 배열이나 특성을 추가할 수 있죠  
`Instance.id, Environment.name 등 원하는 대로 추가`할 수 있습니다  
그리고 StorageResolution API 매개변수를  
이용하여 지표 해상도로 두 가지 값을 지정할 수도 있습니다  
1분 또는 60초에 한 번씩 푸시하는 표준 사용자 지정 지표나  
고해상도 지표가 있죠 이 경우에는  
1, 5, 10, 30초마다 지표를 푸시합니다  
사용자 지정 지표는  
푸시 하는 방향이 과거든 미래든 상관없습니다  
아주 중요한 시험 포인트입니다  
`지표를 2주 전으로 푸시하든 2시간 앞으로 푸시하든 CloudWatch 오류가 발생하지 않습니다`  
`지표를 그대로 수용`하는 거죠  
따라서 `지표를 AWS 의 실제 시간과 동기화하려면 EC2 인스턴스 시간이 현재로 구성되어 있는지를 확인`해야 합니다  
그럼 사용자 지정 지표를 푸시해 보죠  
이를 위해 `CloudWatch 문서의 put-metric-data` 를 보겠습니다  
CLI 문서인데  
CloudWatch 로 지표를 푸시하는 방법이 나와 있습니다  
문서를 읽지는 않겠습니다만  
모든 매개변수는 아래에 상세히 나와 있습니다  
타임스탬프가 지정 가능하다는 점이  
중요한데, `타임스탬프를 2주 전이나 2시간 후로 설정할 수 있습니다`  
상당히 중요한 사실이죠 데이터나  
`값의 이름, 단위, 값 등 배열과 스토리지 해상도 등을 지정`할 수 있습니다    
`고해상도 지표나 표준 해상도를 선택`하고자 하는 경우에 유용하죠  
이제 사용자 지정 지표의 예시를 푸시해 보도록 하죠  

> https://docs.aws.amazon.com/cli/latest/reference/cloudwatch/put-metric-data.html

가령 metric.js 파일을 이와 같은 지표에 푸시한다고 하면
위에 나와 있는 API 호출을 사용하면 됩니다
좀 더 시간을 단축하고 싶으면
API 명령어 하나를 이용해서 지표의 값, 단위 바이트,
인스턴스 ID, 인스턴스 유형 등을 지정하면 됩니다
이 명령어를 가지고
CloudShell 유틸리티를 열어서 지표를 푸시해 보도록 하겠습니다
CloudShell 이 실행되면 명령어를 그대로 넣고 Enter를 눌러 줍니다
이를 통해 CloudWatch에 사용자 지정 지표를 푸시하게 됩니다
예를 들어서 EC2 인스턴스에서 스크립트를
사용해서 이 작업을 수행하면 모든 지표를 주기적으로 푸시할 수 있습니다
지금은 CLI를 사용하여 하나의 데이터 포인트를
CloudWatch에 푸시하죠 이미 아주 유용한 기능이 됐습니다
CloudWatch에 대한 통합 에이전트를 아는 경우
PutMetricData API 호출 기능을 사용해서
CloudWatch에 주기적으로 지표를 푸시할 겁니다
이렇게 MyNameSpace라는 이름의 이름공간을 푸시해 보았는데
다시 CloudWatch 지표 화면으로 돌아가서 새로고침해 보죠

## CloudWatch 로그

CloudWatch Logs를 보죠  
AWS 에서 로그 저장 최적의 장소는 CloudWatch Logs 입니다  
로그를 로그 그룹으로 나누어서  
이름을 지정하면 되는데  
보통은 애플리케이션을 나타냅니다  
`각 로그 그룹 내에는 로그 스트림`이 있습니다  
이들은 애플리케이션 내의 인스턴스 또는 다른 로그 파일 이름  
컨테이너 등을 나타냅니다  
그리고 `로그 만료 정책을 정의`해야 합니다  
예를 들어서 `로그가 만료되지 않도록 설정`하거나    
`30일 이내에 삭제하는 등 지정`할 수 있습니다  
`CloudWatch Logs 스토리지 비용을 고려`하는 거죠  
Amazon S3, Kinesis Data Streams Kinesis Data Firehose  
Lambda, ElasticSearch 등 다양한 위치로 로그를 내보낼 수 있습니다  
CloudWatch Logs에 들어갈 수 있는 로그 유형을 보자면  
`SDK 나 CloudWatch Logs Agent, CloudWatch Unified Agent 를 사용해서 로그를 전송`할 수 있습니다  
CloudWatch Unified Agent 는 CloudWatch 에  
로그를 전송하므로 더 이상은 사용되지 않고 있습니다  
`일래스틱 Beanstalk 은 애플리케이션에서 CloudWatch 로 직접 로그를 수집`하고  
`ECS 는 컨테이너에서 바로 CloudWatch 로 로그를 전송` 합니다  
`AWS Lambda는 함수 자체에서 로그를 전송`하며  
`VPC Flow Logs 는 VPC 메타데이터 네트워크 트래픽과 관련된 로그를 전달`합니다  
`API Gateway 는 들어온 모든 요청을 CloudWatch Logs 에 전달`합니다  
`CloudTrail 에서는 필터를 기반으로 로그를 전송`하고  
`Route53는 해당 서비스에 수행된 모든 DNS 쿼리를 로그`로 남깁니다

지표 필터와 인사이트를 정의하는 것 또한 아주 중요한데  
CloudWatch Logs 에서 `필터 표현식을 사용`하여  
`로그 내 모든 특정 IP를 찾아낼 수 있습니다`   
따라서 `해당 IP가 나타나는 로그 라인을 찾거나 오류 단어가 포함된 모든 로그 라인을 찾아내는 겁니다`  
지표 필터 덕분에 이와 같은 상황의 발생 빈도를 셀 수 있습니다  
이것이 곧 지표가 되는 거죠  
해당 지표는 CloudWatch 경보와 연결됩니다

또 하나 주목할 CloudWatch Logs Insights 기능이 있습니다  
`CloudWatch Logs Insights` 에서
`로그를 쿼리하고 이 쿼리를 CloudWatch 대시보드에 추가`할 수 있습니다  
몇 가지 일반적인 쿼리는 AWS 가 직접 추가해 놓았고  
사용하기 쉬운 언어로 쓰여 있습니다  

먼저 S3 내보내기부터 살펴보도록 하죠  
`CloudWatch 에서 Amazon S3로 전송한다고 치면 내보내기에 최대 12시간까지 소요`될 수 있습니다  
API 호출은 CreateExportTask 로 시간이 지나면 알아서 작업이 끝날 겁니다  
딱히 실시간에 가깝거나 실시간이 아니죠  
대신 `CloudWatch Logs 에서 로그를 스트리밍 하려면 구독`을 사용해야 합니다  
구독이란 `CloudWatch Logs 에 적용하는 필터`로
이제 이를 최종 목적지까지 전달하면 됩니다  
Lambda 함수이거나 사용자 지정 지표 혹은 AWS 지표일 수도 있고  
Amazon Elasticsearch 로 바로 데이터를 전송하거나  
Kinesis data Firehose 에 전송할 수도 있습니다  
`Amazon S3에 실시간에 준하는 속도로 전송`하고자 한다면  
이는 CloudWatch 에서 S3로 내보내기를 사용했던 것에 비해 속도 빠른 대안입니다  
혹은 `Kineses Data Streams 를 이용`해  
Kinesis Data Firehose 나 Kinesis Data Analytics
Amazon EC2, Lambda 등으로도 데이터를 전송할 수 있습니다

끝으로 CloudWatch Logs 를 이용해서
`계정과 리전 간 로그를 수집`할 수도 있습니다
구독 필터가 있는 리전에 계정이 여러 개 존재할 수 있습니다
계정 B와 마찬가지로 공통 계정을 이용해서 Kinesis Data Streams으로 전송되죠
리전 2도 아키텍처는 같습니다
이 모든 로그를 Kinesis Data Streams와
Kinesis Data Firehose로 모아서
Amazon S3까지 가는 겁니다

## CloudWatch 에이전트 및 CloudWatch Logs 에이전트

CloudWatch Agent를 사용하여 EC2 인스턴스로부터  
로그와 지표를 불러들여서 CloudWatch로 전송하는 방법에 대해 알아보겠습니다  
`기본적으로 로그를 EC2 인스턴스에서 CloudWatch로 전송할 수는 없습니다`    
이를 위해서는 EC2 인스턴스에서  
원하는 `로그 파일을 푸시할 작은 프로그램인 에이전트를 생성`해야 하죠  
따라서 EC2 인스턴스에서 CloudWatch Log Agent 를  
실행하여 CloudWatch Logs로 로그를 전송해 줍니다  
이때 `EC2 인스턴스에 IAM 역할`이 있어야 하는데  
이를 통해서 로그를 CloudWatch Logs로 보낼 수 있기 때문입니다  
CloudWatch Log Agent 는  
`온프레미스 서버에도 설치가 가능`합니다   
VM-ware와 같은 가상 서버를 온프레미스에 두고  
작은 Linux 프로그램과 같이 동일한 에이전트를 설치하면  
로그가 CloudWatch Logs에도 표시되죠  
CloudWatch에는 두 가지 에이전트가 있습니다  
`이전 버전인 CloudWatch Logs Agent`와  
`최신 버전인 CloudWatch Unified Agent`죠  
모두 온프레미스 서버의 가상 서버 EC2 인스턴스용입니다

CloudWatch Logs Agent는 이전 버전으로  
`CloudWatch Logs에 로그를 전송하기만` 합니다  

`반면 Unified Agent는 추가 시스템 수준의 지표를 수집`하죠  
`RAM, 프로세스 등`인데 다음 슬라이드에서 보여드리겠습니다  
CloudWatch Logs로 로그를 전송하기도 하죠  
통합된 에이전트이므로 지표와 로그 작업 모두 가능합니다  
Unified Agent 이름에서도 알 수 있죠 `SSM 매개변수 스토어를 사용`하므로  
에이전트 구성도 아주 용이합니다  
이전 버전의 에이전트에는 없었던 기능이죠  
`Unified Agent 일체를 중앙집중식으로 구성`할 수도 있습니다  
CloudWatch Unified Agent 가 CloudWatch Logs 에 로그도 보내지만  
지표를 한번 살펴보도록 하죠 이 에이전트를  
EC2 인스턴스나 Linux 서버에 설치하면  
지표를 수집할 수 있습니다 그렇다면 이때 지표란 무엇일까요?  
CPU 지표를 수집할 수 있는데  
`좀 더 세분화된 수준에서 수집`합니다  
`활성화 상태나, 게스트, 유휴상태, 스틸(steal), 시스템, 사용자` 등을 말이죠   
모두 아실 필요는 없습니다  
지표가 얼마나 세분화되어 있는지를 보여드리고자 하는 거니까요  
`디스크 지표로는 사용 가능 여부나 용량`을 보여 주고  
`디스크 IO 에서는 읽기, 쓰기 바이트, IOPS 수` 등을  
`RAM은 사용 가능 여부 활성화, 용량, 캐시 등`을 알려줍니다  
`TCP 와 UDP 연결 수 넷 패킷, 바이트` 등의  
`Netstats 도 알 수 있죠 프로세스 전반에 대한 정보`도 있는데  
`전체 프로세스 수, 활성 상태` 등에 대해 알 수 있습니다  
`디스크에서 메모리가 유출되는 Swap Space` 도 있죠  
사용 가능 공간과 사용된 공간의 비율을 알 수 있습니다  
이들을 모두 기억하실 필요는 없고  
눈으로 기억한다고 생각하세요  
결론은 CloudWatch Unified Agent를 사용하면  
EC2 인스턴스에 대하여 일반적인 모니터링보다  
더 자세한 지표를 알 수 있다는 겁니다  
EC2의 경우에는 교체나 메모리가 아니라  
디스크, CPU, 네트워크 등에 대한 정보를 알 수 있다는 거죠  
하지만 좀 더 개괄적으로 말입니다  
세부적으로 들어가려면 CloudWatch Unified Agent를 사용하면 됩니다

## CloudWatch 경보

CloudWatch 경보를 살펴보죠 아시는 것처럼  
경보는 모든 지표에서 알림을 트리거 하는데 사용하고  
복잡한 경보도 정의할 수 있습니다  
다양한 옵션을 예로 들 수 있는데요  
샘플링, 백분율, 최댓값과 최솟값 등이죠  
상태는 3가지인데 OK는 트리거 되지 않을 것이며  
INSUFFICIENT_DATA는 경보 상태 결정에  
데이터가 불충분한 것입니다  
그리고 ALARM은 임곗값을 위반한 것이며  
알림을 발송합니다  
기간은 지표로 경보를 평가하는 기간이며  
아주 짧을 수도 있고 아주 길 수도 있으며  
고해상도 사용자 지정 지표에 적용할 수도 있습니다  
10초나 30초 혹은 60초를 여러 번 설정할 수 있죠  
경보에는 3가지의 핵심 타깃이 있습니다  
첫 번째는 EC2 인스턴스에서의 작업입니다  
`중지, 종료, 리부팅 또는 인스턴스를 복원하는 작업`입니다

두 번째는 `오토스케일링 작업을 트리거 하는 것`입니다  
예를 들면, 스케일 아웃이나 스케일 인이죠

마지막은 `SNS 서비스에 알림을 발송하는 것`입니다  
예를 들면, SNS 서비스에서 Lamda 함수에 연결해  
위반하는 경보를 기반으로 원하는 작업을 수행하는 것입니다

EC2 인스턴스 복구를 보죠 이미 살펴봤지만  
EC2 VM을 확인하는 상태 확인과 기본 하드웨어를 확인하는  
시스템 상태 확인이 있고  
이 두 가지를 이용해서 CloudWatch를 정의할 수 있죠  
이렇게 특정 EC2 인스턴스를 모니터링해서  
위반인 경우에는  
확인을 위해 EC2 인스턴스 복구를 시작할 수 있습니다  
예를 들면, EC2 인스턴스를 한 호스트에서 다른 호스트로 이동하는 것입니다  
복원하면 같은 사설, 공용, 탄력적 IP와 메타데이터를 얻고 인스턴스에 관한  
동일한 배치 그룹을 얻습니다  
또한, SNS 주제에 알림을 발송해서  
EC2 인스턴스 복구 알림을 받을 수 있습니다  
CloudWatch 경보의 장점을 살펴보죠  
첫 번째는 이미 살펴본 것으로  
CloudWatch Log 지표 필터에서 경보를 생성하는 것입니다  
기억해야 할 것은 CloudWatch 로그의 지표 필터가  
CloudWatch 경보와 연결된 것입니다  
그리고 특정 단어 예를 들어 error라는  
인스턴스를 너무 많이 받으면  
Amazon SNS로 경보와 메시지를 발송합니다  
그래서 `경보 알림을 테스트`해 보려면  
`set alarm state라는 CLI 호출을 사용`합니다
이는 특정 임곗값에 도달하지 않아도  
경보를 트리거 할 때 유용합니다  
트리거 되는 경보가 인프라에 관한  
올바른 작업을 실행하는지 확인할 수 있기 때문입니다  

> https://docs.aws.amazon.com/cli/latest/reference/cloudwatch/set-alarm-state.html

~~~
aws cloudwatch set-alarm-state --alarm-name "myalarm" --state-value ALARM --state-reason "testing purposes"
~~~

## CloudWatch 이벤트

CloudWatch Events 를 살펴보겠습니다  
`CloudWatch Events 는 EventBridge` 이기도 하고  
CloudWatch에서 사용 가능하며 이제 보여드리겠습니다  
CloudWatch Events로  
`AWS 서비스 내의 이벤트인 모든 소스를 가로챌 수 있습니다`

예를 들어, `EC2 인스턴스를 시작`하거나  
`CodeBuild 장애 Amazon S3 이벤트`  
또는 `Trusted Advisor 이벤트`나  
`CloudTrail 통합으로 모든 API 호출`을 가로챌 수 있죠  
또한, 이벤트를 가로채는 대신 schedule 또는 Cron을  
사용할 수 있는데  
예를 들어, 4시간마다  
이벤트를 생성할 수 있는데  
람다 함수와 연결할 때 매우 유용하며  
이벤트에 관한 JSON 페이로드가 생성되고  
타깃으로 전달되면  
AWS에 너무 많은 타깃을 갖게 됩니다  
Lamda, Batch, ECS 태스크 등의 컴퓨팅 타깃과  
SQS, SNS, Kinesis, Data Streams Kinesis Data Firehose과 같은 통합 타깃  
Step Functions, CodePipeline CodeBuild와 같은 조정 타깃이 있고  
SSM 또는 EC2 Actions의 유지 보수 타깃이 있죠  
그래서 CloudWatch Events 는 매우 강력한 서비스입니다  

## EventBridge 개요

> https://velog.io/@techy-yunong/AWS-EventBridge-concept
> https://www.megazone.com/techblog_20200309_reducing-custom-code-by-using-advanced-rules-in-amazon-eventbridge/
> http://blog.hwahae.co.kr/all/tech/tech-tech/8783/

## X-Ray : 주의

이 서비스가 AWS 서비스 중  
가장 혁신적인 서비스라고 생각하는데  
현재는 활용도가 낮은 것 같습니다  
바로 `AWS X-Ray` 입니다  
시험에서도 X-Ray에 관해 자세하게 출제됩니다    
사용하게 하기 위해서 문제를 출제할 수도 있죠  
저도 X-Ray를 사용해야 한다고 생각합니다  

프로덕션 환경에서 디버깅을 시행할 때  
저도 프로덕션 환경에서 애플리케이션을 디버깅했습니다  
예전에는 좋은 방식이었죠  
로컬에서 테스트하고 어디나 로그 문장을 추가하여 프로덕션 환경에서 다시 배포했습니다  
그리고 로그를 통해 상황과 문제를 파악했습니다  
정말 어렵고 모범 사례도 아닙니다  
더 나은 방법이 있죠  
너무 단순화해서 설명했습니다  
`프로덕션 환경에서의 디버깅은 어렵다`는 것만 알면 됩니다  
그리고 다른 애플리케이션에서 
로깅을 실행하면  
CloudWatch는 다른 모든 형식을 가져  
인사이트를 중앙화하기 어렵고  
CloudWatch 로그 탐색도 어려워져서  
분석하기도 어려워집니다  
그래서 모놀리스(Monolith)를 사용하면 거대한 애플리케이션이 모두 처리해  
쉽게 디버깅할 수 있고 분산된 서비스를 사용하면  
AWS 계정에서 수백 개의 마이크로서비스를 실행하는 악몽을 겪어야 하죠  
모두 서로 통신하기 때문에  
디버깅하기 어렵겠죠?  
그래서 전체 아키텍처나 서비스 맵을  
한 번에 볼 수 없는데 이때 AWS X-Ray를 사용합니다  
`X-Ray 애플리케이션에 관한 시각적 분석을 제공`합니다
클라이언트가 애플리케이션에 요청을 보내면  
`요청이 얼마나 실패하고 실패하지 않는지 확인`합니다  
그리고 애플리케이션에서 어떤 역할을 하는지 확인하죠  
다른 IP와 SNS 그리고 DynamoDB Table을 호출합니다  
보시는 것처럼 EC2 인스턴스와 통신할 때  
발생하는 것을 정확히 시각적으로 추적할 수 있습니다  
이 그래프에서 주황색 또는 노란색 오류는  
어디서 발생한 것일까요?  
이쪽도 아니고 SNS도 아닙니다  
DynamoDB Table이죠 시각적으로 확인할 수 있습니다  
바로 추적의 장점이죠  

더 해 볼 수도 있는데 개념부터 파악하겠습니다  
X-Ray 장점은 아주 많습니다  
`애플리케이션 성능을 트러블 슈팅`하고  
`병목 현상을 식별`할 수 있으며  
마이크로서비스 아키텍처의 종속성을 이해할 수 있는데  
이는 모든 `마이크로서비스가 서로 어떻게 상호 작용하는지 시각적으로 확인`할 수 있기 때문입니다    
그리고 `어떤 서비스가 문제인지 찾아낼 수 있습니다`  
`각 요청의 동작을 이해`할 수 있으며  
요청을 기반으로 오류와 예외를 찾을 수 있습니다  
이제 지연 시간이나 요청 처리 시간 측면에서  
SLA 시간을 충족하는지 대답할 수 있습니다  
`어떤 서비스가 속도를 늦추고 스로틀 하는지 이해할 수 있죠`  
`마지막으로 오류의 영향을 받는 사용자도 파악할 수 있습니다`  
`X-Ray는 호환성이 높습니다`
AWS Lambda, Beanstalk ECS, ELB과 호환하고  
API Gateway와 EC2 인스턴스 또는 모든 애플리케이션 서버와 호환되죠  
심지어 온프레미스에서도 호환됩니다  
이는 X-Ray가 가능한 광범위하고 가능한 모든 애플리케이션에  
적용되도록 시도한다는 것을 의미합니다 

X-Ray의 원리는 무엇일까요? 바로 `추적을 사용`합니다  
추적은 요청을 따르는 방식입니다  
예를 들어, 애플리케이션 서버에 요청을 보내면  
요청을 처리하는 각 구성 요소는  
데이터베이스나 게이트웨이 로드 밸런서  
애플리케이션 서버가 될 수 있고  
또한, 자체 추적을 추가하게 됩니다  
`추적을 세그먼트로 구성`되고  
`세그먼트는 서브세그먼트로 구성`됩니다  
발생한 일에 관한 추가 정보를 제공하기 위해  
추적에 주석을 추가하는 것입니다  
그래서 이 모든 것으로  
모든 요청 및 샘플 요청을 추적할 수 있습니다  
예를 들면  
전체 요청에 관한 백분율만 확인하거나 분당 5개의 요청만 확인할 수 있습니다  
`보안 측면에서는 IAM 인증`을 사용하고  
`미사용 데이터 암호화에는 KMS를 사용`합니다  
그래서 모두 추적하면 X-Ray가 마법을 부려서  
이전에 보여드린 멋진 그래프를 제공합니다  
X-Ray 활성화 방법에는 2가지가 있습니다  

`코드는 Java, Python, Go Node.js와 .NET일 수 있고 반드시 AWS SDK를 가져와야 합니다`  
코드 수정은 거의 하지 않지만  
약간의 수정은 해야 합니다  
그리고 애플리케이션 SDK 즉, X-Ray SDK는 AWS 서비스 호출,  
HTTP와 HTTPS 호출과 MySQL, Postgre, Dynamo DB의 데이터베이스 호출을 캡처합니다  
또한, Queue 호출 등도 포착합니다  
코드 수정 시 두 번째로 할 것은  
X-Ray 데몬(Daemon)을 설치하거나  
X-Ray AWS 통합을 활성화하는 것입니다  
그래서 머신이나 온프레미스 서버 혹은  
`EC2 인스턴스에서 실행하면 데몬을 설치`해야 합니다  
데몬은 저용량 UDP 패킷 인터셉터의 역할을 하는 작은 프로그램이며  
Linux, Windows와 Mac에서 실행되고  
이것을 설치해야 합니다  
AWS Lamda나 이미 X-Ray와 통합된 다른 서비스를 사용하면
데몬이 실행되므로 신경 쓸 필요가 없습니다  
각 애플리케이션은 X-Ray에 데이터 작성을 위해 IAM 권한을 가져야 합니다  
여기서 자주 하는 질문은 컴퓨터에서 X-Ray 애플리케이션이 실행되는데  
테스트하려면 EC2 머신에서 실행되지 않는다는 것입니다  
그 이유는 머신에서  
X-Ray 데몬을 실행하는데 EC2 인스턴스로 배포할 때는  
X-Ray 데몬을 사용하지 않아서  
X-Ray에서 호출을 포착하지 않기 때문입니다  

다시 확실하게 설명하겠습니다 여기 EC2 인스턴스가 있고 애플리케이션 코드가 필요합니다    
코드는 AWS X-Ray SDK를 가져오도록 수정하면  
머신을 실행하는 X-Ray 데몬에 추적을 전송합니다  
또, X-Ray 데몬도 실행해야 하죠  
그러면 X-Ray 데몬이 1초마다  
배치를 AWS X-Ray로 전송하고  
X-Ray가 마법을 부리죠 이제 그래프를 어떻게 업데이트할까요?  
X-Ray는 추적을 전송하는 다른 모든 서비스의 데이터를 수집하고  
서비스 맵은 추적의 모든 세그먼트에서  
산출됩니다  
좋은 기능이며 X-Ray 그래프로 기술이 없는 사람도  
트러블 슈팅을 할 수 있도록 합니다  
트러블 슈팅을 보죠 EC2에서 X-Ray가 실행되지 않으면  
IAM 역할에 적합한 권한이 있는지 확인해야 합니다  
그리고 EC2 인스턴스에서  
X-Ray 데몬이 실행되는지 확인합니다  
Lambda에서 실행하려면 조금 다릅니다  
Lamda가 적합한 정책의  
IAM 실행 역할이 있는지 확인해야 합니다  
Lamda는 살펴보지 않았지만 시험에 나올 수 있습니다  
그래서 Lambda에 적합한 IAM 역할이 있는지 확인해야 하죠  
X-Ray 코드를 가져왔는지도 확인해야 하고  
AWS Lamda에서 X-Ray 통합이 활성화됐는지도 확인해야 합니다  
실습으로 확인해 보겠습니다 X-Ray 개요는 여기까지입니다  
맛보기였고 다음 강의에서는 X-Ray에서 몇 개의 앱을 실행해서  
원리를 이해해 보겠습니다 다음 강의에서 뵙겠습니다

## X-Ray: 계측 및 개념

X-Ray의 고급 개념을 배워보겠습니다  
먼저 코드를 계측하는 방법을 보여드리겠습니다  
이 단어는 아마 새로울 수 있습니다  
`계측이란 뜻은 제품의 성능을 측정하고 오류를 진단하고 추적 정보를 쓰는 것을 의미`합니다  
소프트웨어 엔지니어링의 분야죠  
이제 좀 더 이해될 거예요  
X-Ray로 애플리케이션을 계측하려면  
코드를 수정하여 X-Ray SDK를 이용해야 합니다  
여기 X-Ray SDK와 함께 Node.js 코드를  
계측한 예시가 있습니다  
여기에 코드를 추가하면  
예를 들어, X-Ray SDK를 요구하고 Express 앱에서 사용하면  
코드가 계측될 것입니다  
즉, 코드로부터 X-Ray 서비스에 가는  
추적 정보를 얻습니다  
X-Ray SDK를 사용하는 것은 매우 미미합니다  
때때로 구성의 변경만을 요청합니다  
사용자 정의 추적을 쓰거나 데이터에 주석을 달거나  
X-Ray가 express 서비스에
보내는 방식을 변경하고 싶을 때 애플리케이션 코드도 수정할 수 있습니다
이때는 인터셉터나 필터, 핸들러, 미들웨어를 만들 수 있습니다
꽤 고급 내용으로 코드에서 X-Ray가 동작하는
방식을 사용자가 정의할 수 있습니다
다른 고급 X-Ray 개념으로
세그먼트의 정의는 URL에서 볼 수 있는 것입니다
지금까지 세그먼트를 살펴보았는데요 각 애플리케이션과 서비스가 보냅니다
만약 더 세분화하고 싶다면 서브세그먼트를 정의할 수 있습니다
세그먼트에 세부 사항을 남길 때 사용합니다
추적은 모든 세그먼트를 함께 모았을 때로
API 호출의 종단 간 뷰를 형성합니다
즉, 종단 간 추적이 될 것입니다
샘플링(Sampling)은 곧 살펴볼 것입니다
X-Ray로 보내지는 요청의 양을 줄여
비용을 감소시킬 때 사용합니다
모든 요청이 필요하지 않을 수 있기 때문이죠
이제 매우 중요한 것입니다 주석은 추적을 인덱싱하고
필터와 함께 사용하기 위해 키-값 쌍 데이터를 추가하는 것입니다
주석은 X-Ray에서 굉장히 중요한데
추적을 검색하기 원한다면
인덱스가 있고 메타데이터도 있습니다
메타데이터도 마찬가지로 키-값 쌍이지만
인덱스는 아닙니다
즉, 주석은 인덱싱되어
필터와 함께 검색할 수 있지만
메타데이터는 인덱싱되지 않기 때문에
검색에 사용할 수 없습니다
X-Ray 데몬 또는 에이전트는 여러 계정에
추적을 보내는 구성을 갖고 있습니다
이를 위해 IAM 권한이 올바른지 확인해야 합니다
에이전트는 자동으로 올바른 역할을 가정하여
모든 로깅 및 애플리케이션 추적을 위한
중앙 계정을 만들 수 있습니다
샘플링을 자세히 알아보겠습니다
샘플링 규칙으로 X-Ray 서비스와 레코드에 보내는
데이터의 양을 제어할 수 있습니다
X-Ray에 더 많은 데이터를 보낼수록 더 큰 비용을 지불해야 합니다
코드를 변경하지 않고 샘플링 규칙을 수정할 수 있는데
기본적으로 샘플링 규칙은
X-Ray SDK가 초마다
모든 첫 번째 요청을 기록하고
다음 추가 요청의 5%를 기록합니다
파란색 부분, 즉, 초마다 첫 번째 요청을
리저버(reservoir)라고 하고
이는 서비스가 요청을 처리하는 동안
초당 적어도 하나의 추적이 기록되는 것을 보장합니다
5%는 비율이라고 하는데
리저버의 크기를 초과하는 추가 요청을 샘플링합니다
사용자 정의 샘플링 규칙을 이야기하겠습니다
여러분 자체 규칙을 만들 수 있는데
무엇이 리저버고 무엇이 비율인지 정의할 수 있죠
예시가 있습니다 POST를 위한 더 높은 최소 비율입니다
리저버는 10입니다
초당 10개의 요청이
X-Ray에 보내진다는 뜻이고 다른 10%가 보내진다는 뜻입니다
최소 비율이 더 높기 때문에 X-Ray에 보내는 요청이 더 많습니다
여기에서는 디버깅하려고 하는데요
모든 요청을 원하기 때문에
리저버는 1, 비율도 1입니다
즉, 모든 요청이 X-Ray에 보내집니다
어떤 추적도 잃고 싶지 않죠
각 추적에서 무슨 일이 일어났는지
확인하는 디버깅을 할 때 매우 유용합니다
물론 실제 상황에서 이것은 매우 비쌉니다
X-Ray에 많은 데이터를 보내기 때문이죠
진행 상황을 확인하기 위해 사용자 정의 샘플링 규칙을 변경하는 것은 유용합니다
멋진 점은 X-Ray 콘솔에서 샘플링 규칙을 변경한 경우
애플리케이션을 재시작할 필요가 없다는 점입니다
X-Ray SDK에 아무것도 할 필요 없죠
데몬이 자동으로 샘플링 규칙을 얻어
X-Ray 서비스에 올바른 양의 데이터를 보내줍니다
다음 강의에서는 샘플링 규칙을 정의하는 법을 배우겠습니다

## CloudTrail

CloudTrail은 AWS 계정에 대한  
거버넌스(Governance), 규정 준수 및 감사를 수행합니다  
CloudTrail은 기본적으로 활성화되어 있습니다  
이는 콘솔, SDK, CLI, 다른 AWS 서비스에서 만들어진  
`AWS 계정 내 모든 이벤트의 기록과 API 호출을 얻게 해줍니다`  

모든 로그는 CloudTrail에 나타납니다  
또한 로그를 CloudTrail로부터  
CloudWatch Logs나 Amazon S3로 보냅니다  
모든 리전이나 단일 리전에 적용되는 추적을 만들 수 있습니다  
모든 리전의 기록을  
예를 들어 S3 버킷과 같은  
한 공간에 누적하려는 경우에 말이죠

CloudTrail을 사용할 때  
예를 들어 다른 사람이 먼저 접속해서  
AWS 내 뭔가를 삭제했다고 합시다  
EC2 인스턴스가 종료되었죠  
누가 종료시켰는지 알고 싶다면  
CloudTrail을 살펴보면 됩니다  
CloudTrai에 있는 API 호출을 통해  
누가 무엇을 언제 했는지 파악할 수 있습니다  
요약하자면, CloudTrail은  
SDK, CLI 또는 콘솔의 행동과  
심지어 IAM 사용자와 IAM 역할,  
또는 CloudTrail 콘솔에 있는 다른 서비스 중간에 있습니다  
`이를 통해 무슨 일이 벌어졌는지 조사하고 감사`할 수 있습니다  
90일 이상의 모든 이벤트를 원하는 경우  
이를 CloudWatch Logs에 보내거나  
S3 버킷에 보냅니다  
구체적으로 CloudTrail을 살펴보죠  
CloudTrail에는 3종류의 이벤트가 있습니다  

첫 번째는 `관리 이벤트`라고 합니다  
이것은 AWS 계정에 있는  
리소스에서 수행되는 작업을 의미합니다  
예를 들어 누군가 보안을 구성할 때마다  
IAM AttachRolePolicy라는 API 코드를 사용하고  
이것은 CloudTrail에 나타납니다  
서브넷을 만들면 나타날 것이며  
로깅을 설정하면 기본으로 나타날 것입니다  
`리소스나 AWS 계정을 수정하는 것은 모두 CloudTrail에 나타날 것`입니다  
기본값으로 추적은 어떤 경우에도 관리 이벤트를 기록하도록 구성됩니다  
2종류의 관리 이벤트를 분리할 수 있는데  
리소스를 수정하지 않는 읽기 이벤트,  
예를 들어 IAM에서 모든 사용자를 나열한다던가  
EC2에서 기관의 인스턴스를 나열하는 것과 같은 이벤트입니다  
이를 리소스를 수정하는 쓰기 이벤트에서  
분리할 수 있습니다  
예를 들어 누군가 DynamoDB 테이블을 지우려고 하는 이벤트입니다  
물론 쓰기 이벤트가 좀 더 중요합니다  
AWS 인프라에 손상을 입힐 수 있기 때문입니다  
반면 읽기 이벤트는 여전히 중요하지만, 정보를 얻는 이벤트로  
덜 파괴적입니다  
그리고 데이터 이벤트가 있습니다  
기본적으로 분리되어 있습니다 데이터 이벤트는 로그에 남지 않습니다  
대용량 작업이기 때문이죠 

`데이터 이벤트`가 무엇일까요?  
`GetObject, DeleteObject, PutObject 와 같은 Amazon S3 객체 수준의 활동에서 보이듯이 S3 버킷에서 많이 발생`하는 것들이죠    
기본적으로 로그에 남지 않는 이유기도 합니다    
또한 읽기 이벤트와 쓰기 이벤트를  
분리할 수 있는 옵션이 있습니다 읽기 이벤트로는 GetObject가 있고  
쓰기 이벤트는 DeleteObject 또는 PutObject입니다  
CloudTrail에 있는 다른 이벤트는  
AWS Lambda 기능 수행 활동입니다  
즉, 누군가 API를 호출할 때마다  
`몇 번의 람다 함수가 호출되었는지 파악`할 수 있습니다  
람다 함수를 많이 수행한다면    
이 역시 정말 많은 양이 될 수 있습니다  
CloudTrail의 세 번째 이벤트는 인사이트(Insight) 이벤트입니다  
다음 슬라이드에서 CloudTrail 인사이트를  
자세히 다뤄보겠습니다  
CloudTrail 인사이트를 이야기해 보죠  
모든 유형의 서비스에 걸쳐 많은 관리 이벤트가 발생하는 경우  
많은 API가 계정에서 아주 빠르게 발생합니다  
이때 어떤 것이 이상하고 어떤 것이 특이한지, 특이하지 않은지  
이해하는 것은 어려울 수 있습니다  
CloudTrail 인사이트는 이럴 때 사용합니다    
CloudTrail 인사이트를 활성화하면  
참고로, `유료`입니다 CloudTrail이 이벤트를 분석하고  
`계정 내 비정상적인 활동`을 찾아냅니다  
`예를 들어 부정확한 리소스 프로비저닝, 서비스 제한 초과, AWS IAM 작업 폭주, 주기적인 유지보수 활동의 격차 등`이 있죠    
동작하는 방식은 CloudTrail이 정상 관리 활동을  
분석하여 기준선을 만들고  
이벤트가 올바른 유형인지 계속하여 분석합니다  
무언가 변경될 때 또는 변경을 시도할 때마다  
`비정상적인 패턴을 감지`합니다  
간단하게 관리 이벤트는 CloudTrail 인사이트를 통해  
계속해서 분석됩니다  
무언가가 감지될 때 인사이트 이벤트를 생성하죠  
이런 이상치, 인사이트 이벤트는 CloudTrail 콘솔에 나타납니다  
원한다면 Amazon S3에 보낼 수 있습니다  
또한 `CloudTrail 인사이트 위에서 자동화할 필요가 있는 경우 EventBridge 이벤트 즉, CloudWatch 이벤트도 만들어집니다`  
예를 들어, 이메일을 보내죠  
CloudTrail 인사이트 이면은 이렇습니다  
마지막으로 CloudTrail 이벤트 보관입니다  
CloudTrail에서 이벤트는 기본적으로 90일 동안 보관됩니다  
그 뒤엔 삭제되죠  
때때로 이벤트를 오래 보관하고 싶습니다  
예를 들어, 감사 목적으로 1년 전의 이벤트를 보고 싶을 수 있죠  
따라서 이 `기간을 넘어 이벤트를 보관하려면 S3에 로그를 보내야 합니다`    
Athena를 이용하여 분석할 수 있습니다  
간단하게 모든 관리 이벤트,  
데이터 이벤트, 인사이트 이벤트를  
CloudTrail에서 90일 동안 보관하고  
장기 보관을 위해 S3 버킷에 기록합니다  
분석할 준비가 되면 S3에서 데이터를 쿼리할 때 사용하는  
서버리스 서비스인 Athena 서비스를 이용하여  
관심 있는 이벤트를 찾아  
확인해 볼 수 있습니다

## CloudTrail 대 CloudWatch 대 X-Ray

CloudTrail, CloudWatch X-Ray의 차이는 무엇일까요?  
CloudTrail 은 사용자, 서비스 또는 AWS 콘솔에서 계정에서  
이루어진 API 호출을 감사하는 겁니다  
`승인되지 않은 호출을 감지`하거나  
`API 호출로 인한 변경의 근본적인 원인을 찾을 때 유용`합니다  

CloudWatch는 모니터링을 위해 CloudWatch 지표를 쓰고  
`CloudWatch 로그로 애플리케이션 로그를 저장`하며  
`CloudWatch 경보로 예상치 못한 지표가 나왔거나 했을 때 알림`을 보냅니다  
모두 모니터링과 관련된 거죠  
즉, CloudTrail은 API 호출 CloudWatch는 모니터링이 중점적입니다  

`X-Ray는 자동화된 추적 분석`과  
`중앙 서비스 맵 시각화를 해주기 때문에 분산 서비스에서 큰 숲을 보기에 좋습니다`   
그러면 디버깅과 X-Ray 콘솔 내 지연  
오류 및 오류 분석 같은 항목을 보는 데 정말 유용합니다  
말씀드렸듯 분산 시스템 전체에서 추적 요청을 얻을 수도 있습니다  
여기까지 어떤 서비스가 어디에 쓰이는지 아셨길 바랍니다  
CloudWatch는 전반적인 지표를 위해 존재하고, X-Ray는 훨씬 더  
세분화되고 추적 지향적인 서비스이며  
CloudTrail은 API 호출을 감사하기 위한 겁니다  