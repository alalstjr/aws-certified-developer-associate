- [IAM: Users & Groups](#IAM:-Users-&-Groups)
  - [IAM User 만들기](#IAM-User-만들기)
  - [정책](#정책)
  - [Password Policy](#Password-Policy)
    - [가상 MFA 장치](#가상-MFA-장치)
    - [U2F 보안 키](#U2F-보안-키)
  - [MFA 설정](#MFA-설정)
  - [AWS 액세스 키, CLI 및 SDK](#AWS-액세스-키,-CLI-및-SDK)
    - [CLI 란 무엇일까?](#CLI-란-무엇일까?)
    - [SDK 란 무엇일까?](#SDK-란-무엇일까?)
  - [CLI Install](#CLI-Install)
  - [AWS CLI 연습](#AWS-CLI-연습)
  - [역할](#역할)
    - [IAM 액세스 관리자](#IAM-액세스-관리자)
    - [IAM 모범 사례](#IAM-모범-사례)
- [EC2 기초](#EC2-기초)
  - [인스턴스 유형](#인스턴스-유형)
    - [범용의 인스턴스](#범용의-인스턴스)
    - [컴퓨팅 최적화 인스턴스](#컴퓨팅-최적화-인스턴스)
    - [메모리 최적화의 인스턴스](#메모리-최적화의-인스턴스)
    - [스토리지 최적화 인스턴스](#스토리지-최적화-인스턴스)
  - [보안 그룹](#보안-그룹)
    - [SSH](#SSH)
  - [온-디맨드 인스턴스](#온-디맨드-인스턴스)
  - [예약 인스턴스](#예약-인스턴스)
    - [정기 예약 인스턴스](#정기-예약-인스턴스)
    - [스팟 인스턴스](#스팟-인스턴스)
    - [전용 호스트](#전용-호스트)
    - [전용 인스턴스](#전용-인스턴스)
- [EBS 볼륨](#EBS-볼륨)
  - [스냅샷](#스냅샷)
  - [AMI](#AMI)
  - [인스턴스 스토어](#인스턴스-스토어)
  - [EBS 볼륨](#EBS-볼륨)
    - [IOPS](#IOPS)
    - [스토리지](#스토리지)
    - [st1과 sc1](#st1과-sc1)
    - [EBS 다중 연결](#EBS-다중-연결)
  - [EFS](#EFS)
    - [성능 모드](#성능-모드)
    - [처리량 모드](#처리량-모드)
  - [EBS vs EFS](#EBS-vs-EFS)
  - [EBS](#EBS)
  - [EFS](#EFS)
- [ELB](#ELB)
  - [고가용성과 확장성](#고가용성과-확장성)
    - [확장성](#확장성)
  - [로드 밸런싱](#로드-밸런싱)
  - [Sticky Sessions](#Sticky-Sessions)
    - [애플리케이션 기반 쿠키](#애플리케이션-기반-쿠키)
    - [기간 기반 쿠키](#기간-기반-쿠키)
  - [교차 영역 로드 밸런싱](#교차-영역-로드-밸런싱)
  - [SSL](#SSL)
  - [등록 취소 지연](#등록-취소-지연)
  - [오토스케일링 AGS](#오토스케일링-AGS)
    - [오토 스케일링 그룹의 스케일링 정책](#오토-스케일링-그룹의-스케일링-정책)
- [EBS 볼륨](EBS-볼륨)
  - [스냅샷](#스냅샷)
  - [AMI](#AMI)
  - [인스턴스 스토어](#인스턴스-스토어)
  - [EBS 볼륨](#EBS-볼륨)
    - [IOPS](#IOPS)
    - [스토리지](#스토리지)
    - [st1과 sc1](#st1과-sc1)
    - [EBS 다중 연결](#EBS-다중-연결)
  - [EFS](#EFS)
    - [성능 모드](#성능-모드)
    - [처리량 모드](#처리량-모드)
  - [EBS vs EFS](#EBS vs EFS)
    - [EBS](#EBS)
    - [EFS](#EFS)
- [RDS](#RDS)
  - [백업](#백업)
    - [오토스케일링](#오토스케일링)
  - [RDS 다중 AZ (Multi AZ)](#RDS-다중-AZ-(Multi AZ))
  - [읽기 전용 복제본 (Read Replica)](#읽기-전용-복제본-(Read Replica))
  - [암호화](#암호화)
  - [인증](#인증)
  - [Amazon 오로라(Aurora)](#Amazon-오로라(Aurora))
  - [Amazon 일래스틱 캐시](#Amazon-일래스틱-캐시)
    - [Memcached 를 선택](#Memcached-를-선택)
    - [Redis 를 선택](#Redis-를-선택)
  - [일래스틱캐시 (ElastiCashe) 전략](#일래스틱캐시-(ElastiCashe)-전략)
    - [레이지 로딩(Lazy Loading)](#레이지-로딩(Lazy Loading))
    - [라이트 스루(Write Through)](#라이트-스루(Write Through))
    - [캐시 제거와 타임 투 리브(TTL)](#캐시-제거와-타임-투-리브(TTL))
  - [Redis 클러스터 모드](#Redis-클러스터-모드)
    - [클러스터 모드 비활성화입니다](#클러스터-모드-비활성화입니다)
    - [클러스터 모드 활성화](#클러스터-모드-활성화)
- [DNS](#DNS)
  - [Route 53](#Route 53)
    - [A 레코드](#A-레코드)
    - [AAAA 레코드](#AAAA-레코드) 
    - [CNAME 레코드](#CNAME-레코드) 
    - [NS 레코드](#NS-레코드) 
    - [호스팅 존](#호스팅-존)
  - [레코드 TTL(Time To Live)](#레코드-TTL(Time To Live))
  - [CNAME 과 별칭의 차이](#CNAME-과-별칭의-차이)
  - [라우팅 정책](#라우팅-정책)
    - [단순 라우팅 정책](#단순-라우팅-정책) 
    - [가중치 기반 라우팅 정책](#가중치-기반-라우팅-정책) 
    - [지연 시간 기반 라우팅 정책](#지연-시간-기반-라우팅-정책)
    - [상태 확인 정책](#상태-확인-정책)
    - [장애 조치 정책](#장애-조치-정책)
    - [지리 위치(Geolocation) 라우팅 정책](#지리-위치(Geolocation)-라우팅-정책)
  - [지리 근접 라우팅](#지리-근접-라우팅)
    - [트래픽 플로우](#트래픽-플로우)
  - [다중 응답 라우팅 정책 (Multivalue answer)](#다중-응답-라우팅-정책-(Multivalue answer))
- [VPC](#VPC)
  - [네트워크 ACL의 개념과 보안 그룹](#네트워크-ACL의-개념과-보안-그룹) 
  - [VPC 플로우 로그](#VPC-플로우-로그)
  - [VPC 피어링](#VPC-피어링)
  - [NAT 게이트웨이](#NAT-게이트웨이)

# IAM: Users & Groups

IAM 은 `Identity and Access Management` 의 약자로  
IAM 에서는 사용자를 생성하고  
그룹에 배치하기 때문에 글로벌 서비스에 해당됩니다  

AWS에서는 모든 사용자에게 모든 것을 허용하지 않습니다  
그러면 엉망이 될 겁니다  
새로운 사용자가 너무 많은 서비스를 실행하여 큰 비용이  
발생하거나, 보안 문제를 야기할 수 있기 때문이죠  
따라서 AWS에서는 최소 권한의 원칙을 적용합니다  
즉 사용자가 꼭 필요로 하는 것 이상의 권한을 주지 않는 것입니다.  

## IAM User 만들기

처음으로 할 일은 IAM 사용자를 생성하는 것이죠

https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-1#/users

Users 항목으로 이동해 Add users 를 선택하겠습니다  
보시는 것처럼 상단의 계정 이름을 클릭해 보시면  
현재 루트 계정을 사용 중이죠  
루트 사용자는 계정에 대한 모든 권한을 가지고 있습니다  
그렇기 때문에 위험한 계정이 될 수도 있죠  
따라서 별도의 관리자 계정을 만드는 것이 좋습니다  
루트 계정은 정말로 반드시 꼭 필요할 때만 사용할 겁니다  

그룹 이름은 admin으로 하겠습니다  
admin 그룹에 배치된 사용자는  
이 그룹에 부여된 권한을 승계하게 됩니다  
그리고 권한은 정책을 통해 정의되죠  
admin 그룹에 연결할 정책은 AdministratorAccess 입니다
이 정책은 admin 그룹에 속한 모든 사용자가
계정의 관리자 역할을 하도록 허용할 겁니다  

Next: Tags를 클릭합니다  
AWS에서는 어디에서든 태그를 찾을 수 있는데요  
사용자의 접근을 추적, 조직, 제어할 수 있도록 도와주는 정보입니다    
이 강의에서는 굳이 여기저기에 태그를 만들지 않을 겁니다  
다만 사용자를 위한 태그 생성 방법을 보여드리죠  
그 특정 사용자에 대해 단순히 정보를 추가하는 것입니다  
예를 들어, 이 사용자가 속한 부서는 엔지니어링이라고 표시할 수 있죠

## 정책

~~~
{
    "Version": "2012-10-17",
    "Id": "S3-Account-Permissions"
    "Statement": [
        {
            "Sid": "1",
            "Effect": "Allow",
            "Principal": {
                "AWS": ["arn:aws:iam::123123123:root"]
            },
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
            ],
            "Resource": ["arn:aws:s3:::mybuckey/*"]
        }
    ]
}
~~~

IAM 정책 구조 요소는 버전 숫자를 포함하는데요  
보통은 2012-10-17로 정책 언어 버전입니다  
정책을 식별하는 `ID` 도 있는데 선택 사항이고요  
문장들도 구성 요소입니다  
문장은 하나일 수도 여러 개일 수도 있는데  
문장에는 아주 중요한 부분들이 있죠  
먼저 `Sid` 는 문장 ID로 문장의 식별자이고 역시 선택 사항입니다  
오른쪽에 보시면 1번이라고 나와있죠  
정책에서 `Effect` 는 문장이 특정 API에 접근하는 걸 허용할지 거부할지에 대한 내용입니다  
`Principal` 은 특정 정책이 적용될 사용자, 계정, 혹은 역할로 구성됩니다
이 예시에선 AWS 계정의 루트 계정에 적용이 되죠  
`Action` 은 `Effect` 에 기반해 허용 및 거부되는 API 호출의 목록입니다  
그리고 `Resource` 는 적용될 `Action` 의 리소스의 목록으로  
이 예시에선 버킷이지만 다른 것들도 될 수도 있겠죠

## Password Policy

이 그룹과 사용자들의 정보가 침해당하지 않도록 보호해야겠죠  
다요소 인증, `MFA` 입니다  
`MFA` 는 여러분이 알고 있는 비밀번호와  
여러분이 가지고 있는 보안 장치를 함께 사용하는 것입니다  
`MFA` 의 장점은 사용자가 해킹을 당해 비밀번호가  
누출된 상황이라고 해도 해커에게는 로그인을 위해 휴대전화 등  
사용자 소유의 물리적 장치가 추가로 필요해질 테니  
계정이 침해당하지 않는다는 점입니다  

AWS 에서의 `MFA 장치 옵션` 으로는 어떤 것들이 있을까요?

### 가상 MFA 장치

`Google Authenticator` 를 사용할 수 있는데 하나의 휴대전화에서만 사용이 가능하죠
`Authy` 는 여러 장치에서 사용이 가능합니다  
장치의 개수가 다를 뿐 작동 방식은 동일합니다  
개인적으로 저는 `Authy` 를 사용하는데 컴퓨터와  
휴대전화에서 같이 사용할 수 있기 때문이죠  
`Authy` 는 하나의 장치에서도 토큰을 여러 개 지원합니다  
즉, 가상 `MFA` 장치를 사용하면  
루트 계정, IAM 사용자 또 다른 계정, 그리고  
또 다른 IAM 사용자가 지원되는 식으로 가상 MFA 장치에  
원하는 수만큼의 계정 및 사용자 등록이 가능합니다  

### U2F 보안 키

이는 물리적 장치로 예를 들어  
Yubico 사의 YubiKey 가 있죠 Yubico 는 AWS 의 제3자 회사로  
AWS 제공 장치가 아니라 제3자 회사의 장치입니다  
이렇게 `물리적 장치를 사용하면 전자 열쇠`에 달고 다닐 수 있으니  
사용이 상당히 편리할 수 있겠죠  
YubiKey 는 하나의 보안 키에서 여러 루트 계정과 IAM 사용자를  
지원하기 때문에 하나의 키로도 충분합니다

### 하드웨어 키 팝 MFA 장치

역시 AWS 의 제3자 회사인 Gemalto 의 제품입니다  
만약 미국 정부의 클라우드인 AWS GovCloud 를  
사용하시는 경우라면, MFA 숫자를 실시간으로 보여주는 특수한 키 팝(작은 물건)이 필요한데요  
역시 SurePassID 라는 제3자 회사가 제공하고 있죠  

## MFA 설정

왼쪽의 `Account settings (계정 설정)` 에 들어가서  
`Change password policy (암호 정책 변경)` 를 누르면  
여기서 비밀번호 정책 적용이 가능하죠    
비밀번호 최소 길이 지정이 가능하고  
적어도 하나의 대문자 및 소문자 숫자를 포함하도록 합니다  

오른쪽에 있는 계정 이름을 클릭하고  
`My Security Credential(보안 자격 증명)` 로 들어갑니다  
https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials

`Multi-factor authentication (MFA) - 멀티 팩터 인증` 를 클릭하고  
휴대전화를 사용할 거니까 Virtual MFA device 를 선택하겠습니다

## AWS 액세스 키, CLI 및 SDK

Create access key 버튼으로 액세스 키를 생성하면  
곧 다운로드 권한이 주어질 겁니다  
직장에서 보안 문제를 피하기 위해서는  
절대 액세스 키를 공유하지 마세요 여러분만 알고 계셔야 합니다  

### CLI 란 무엇일까?

`CLI` 는 명령줄 인터페이스를 의미하며  
`AWS CLI` 는 명령줄 셸에서 명령어를 사용하여  
AWS 서비스들과 상호작용할 수 있도록 해 주는 도구입니다

`CLI` 를 사용하면 `AWS 서비스의 공용 API 로 직접 액세스가 가능`합니다
그리고 `CLI` 를 통해 리소스를 관리하는 스크립트를 개발해  
일부 작업을 자동화할 수 있죠  
`CLI` 는 오픈 소스로, GitHub 에서 모든 소스 코드를 찾으실 수 있으며  
AWS 관리 콘솔 대신 사용되기도 합니다  

### SDK 란 무엇일까?

`SDK 는 소프트웨어 개발 키트입니다`  
특정 언어로 된 라이브러리의 집합인데요  
따라서 프로그래밍 언어에 따라 개별 `SDK` 가 존재합니다  
이 방식을 사용해서도 역시 AWS 서비스나 API 에  
프로그래밍을 위한 액세스가 가능하도록 해줍니다  
하지만 `SDK 는 터미널 내에서는 사용하는 것이 아니라  
코딩을 통해 애플리케이션 내에 심어 두어야 하는 겁니다`  
애플리케이션 내에 자체적으로 AWS SDK 가 있는 거죠  
다양한 프로그래밍 언어를 지원하죠  
JavaScript Python, PHP, .NET  
Ruby, Java, Go Node.js, C++ 등을 지원합니다

## CLI Install

https://docs.aws.amazon.com/cli/latest/userguide/getting-started-version.html

## AWS CLI 연습

사용자 -> 생성된 IAM 유저 계정 클릭   
IAM 사용자인 상태이며 이제 Security credentials (보안 자격 증명) 로 이동합니다
액세스 키는 CLI, 즉 명령줄 인터페이스를 사용할 때 굉장히 유용합니다  
혹은 AWS 에 프로그래밍 언어의 구현을 위해 SDK 를 사용할 때도 유용하죠  
Create access key 를 클릭합시다 액세스 키는 기밀입니다  
오직 생성 시에만 표시 및 다운로드가 가능하죠  

먼저 AWS CLI 부터 구성해야 하는데요  
aws configure 라고 입력하겠습니다  
그러면 액세스 키 ID를 입력하라고 나오네요  
생성된 액세스 키를 붙여 넣어 입력한 후 Enter 를 누르고요  
이번엔 암호 액세스 키를 입력하라는 안내가 나옵니다  
역시 이렇게 입력해 주겠습니다  
기본 리전 이름은 가까운 리전을 말하는 겁니다  
강의 전체가 eu-west-1에서 진행될 테니 eu-west-1로 지정해 주겠습니다  
여러분들은 각자의 리전을 선택해 입력하시면 됩니다  

그럼 어떻게 작동하는지도 한 번 봐야겠죠
aws iam list-users 를 입력 후 Enter 를 누르면
제 계정의 모든 사용자를 목록으로 보여 줄 겁니다

## AWS 클라우드쉘

`CloudShell` 은 화면 우측 상단의 이 아이콘입니다  
사용 할 수 있는 리전에 있는지 확인하세요 모든 리전에서 가능한 건 아니거든요  
AWS CloudShell FAQs에 가시면 사용이 불가능한 리전이 나와 있습니다

## 역할

EC2 인스턴스는 AWS에서 어떤 작업을 수행하려고 할 수 있습니다  
그러기 위해서는 EC2 인스턴스에 권한을 부여해야 합니다  
이를 위해 IAM 역할을 만들어 이들을 하나의 개체로 만듭니다  
EC2 인스턴스가 AWS에 있는 어떤 정보에 접근하려고 할 때  
IAM 역할을 사용하게 될 것입니다  
만약 IAM 역할의 권한을 올바르게 부여한 경우  
하려고 하는 호출에 접근하게 될 것입니다  

역할은 여러분이 신뢰하는 개체에 권한을 부여하기 위해 사용됩니다

### IAM 액세스 관리자

이것은 사용자 수준에서 가능합니다 액세스 관리자는  
사용자에게 부여된 서비스의 권한과  
해당 서비스에 마지막으로 액세스한 시간이 보입니다  
최소권한의 원칙에 따랐을 때 매우 도움 되는 정보입니다  
해당 도구를 사용하여 어떤 권한이 사용되지 않는지 볼 수 있고  
따라서 사용자의 권한을 줄여 최소권한의 원칙을 지킬 수 있습니다

왼쪽 하단에 Credential report 가 있고 Download Report 를 클릭하여  
보고서를 다운로드합니다 CSV 파일이 다운로드될 거예요  
사용자가 언제 생성되었는지, 비밀번호가 활성화되었는지,  
비밀번호를 마지막으로 언제 사용했는지, 마지막으로 언제 변경되었는지,  
비밀번호 변경 주기를 활성화한 경우 다음 주기는 언제인지  
MFA 가 활성화되었는지 출력됩니다.

다음으로는 IAM 액세스 관리자를 이야기하겠습니다  
Users를 클릭합니다  
오른쪽에 Access Advisor 가 있습니다  
마지막에 사용된 서비스를 보여줄 것입니다  
보통 최근 4시간 동안의 활동 내역이 보입니다  
만약 보이지 않는다면 4시간이 지났기 때문이죠

### IAM 모범 사례

루트 계정은 AWS 계정을 설정할 때를 제외하고 사용하지 마세요  
사용자를 그룹에 넣어 해당 그룹에 권한을 부여할 수 있어요  
따라서 그룹 수준에서 보안을 관리할 수 있습니다  
또한 비밀번호 정책을 강력하게 만들어야 합니다  
다요소 인증(MFA)을 사용한다.  
AWS 서비스에 권한을 부여할 때마다 역할을 만들고 사용해야 합니다  
가상 서버인 EC2 인스턴스를 포함해서요  
AWS를 프로그래밍할 경우, 즉, CLI나 SDK를 사용할 경우  
반드시 액세스 키를 만들어야 합니다 액세스 키는 비밀번호와 같습니다

# EC2 기초

이것은 일래스틱 컴퓨트 클라우드의 약자로 AWS에서 제공하는 서비스형 인프라스트럭처입니다  
즉, EC2는 하나의 서비스가 아닙니다  
높은 수준에서 보면 많은 것을 포함하고 있습니다  
가상 머신을 EC2에서 임대할 수 있는데 이를 EC2 인스턴스라고 합니다  

데이터를 가상 드라이브 또는 EBS 볼륨에 저장할 수 있고  
일래스틱 로드 밸런서로 로드는 분산시킬 수 있습니다  
또 오토 스케일링 그룹(ASG)을 통해 서비스를 확장할 수 있습니다  

즉, EC2 사용자 데이터 스크립트를 사용하여 인스턴스를 부트스트래핑할 수 있습니다  
부트스트래핑이 무슨 뜻일까요?  
이는 머신이 작동될 때 명령을 시작하는 것을 말합니다  
스크립트는 처음 시작할 때 한 번만 실행되고 다시 실행되지 않습니다

## 인스턴스 유형

m5.2xlarge 라는 유형의 인스턴스를 예로 들어 보겠습니다  
`m 을 인스턴스 클래스`로 부르겠습니다  
그리고 이 인스턴스 클래스는 범용의 인스턴스입니다  
`5는 인스턴스의 세대`를 뜻합니다  
즉, AWS 가 하드웨어를 계속 개선해서 새로운 세대의 하드웨어를 출시하고  
m5 이후에 m 유형의 인스턴스 클래스를 개선하면  
m6가 되는 것입니다 2xlarge 는 인스턴스 클래스 내에서 크기를 나타냅니다  
small 로 시작해 large, 2xlarge 4xlarge 등의 크기가 있죠  
인스턴스의 크기를 나타내며 크기가 클수록 인스턴스에  
더 많은 메모리와 CPU 를 가지게 됩니다

### 범용의 인스턴스

먼저, 범용의 인스턴스는 웹 서버나 코드 저장소와 같은 다양한 작업에 적합합니다  
컴퓨팅, 메모리, 네트워킹 간의 균형도 잘 맞습니다

### 컴퓨팅 최적화 인스턴스

이제 컴퓨팅 최적화 인스턴스는 컴퓨터 집약적인 작업에 최적화된 인스턴스입니다  
그러면 고성능 프로세서는 어디에 사용할까요?  
일부 데이터의 일괄 처리에 사용하거나  
미디어 트랜스코딩 작업 시 혹은 고성능 웹 서버가 필요하거나  
고성능 컴퓨팅이라는 HPC 작업을 할 때 그리고 머신 러닝이나  
전용 게임 서버가 있을 때 사용합니다  
모두 훌륭한 CPU와 컴퓨팅을 요구하는 작업이며  
EC2 인스턴스는 이런 특성을 가지고 있습니다  
그리고 컴퓨터 최적화의 모든 인스턴스는  
C로 시작하는 이름을 가지고 있습니다  
C5, C6 등이죠  

### 메모리 최적화의 인스턴스

다음으로 메모리 최적화의 인스턴스를 살펴보겠습니다  
이 유형의 인스턴스는 메모리에서 대규모 데이터셋을  
처리하는 유형의 작업에 빠른 성능을 제공합니다  
메모리는 RAM을 뜻하고 사용 사례를 살펴보면  
대부분 인 메모리 데이터베이스가 되는  
고성능의 관계형 또는 비관계형의 데이터베이스에 사용하고  
일래스틱 캐시를 예로 들 수 있는  
분산 웹스케일 캐시 저장소에도 사용합니다  
즉, BI에 최적화된 인 메모리 데이터베이스와  
대규모 비정형 데이터의 실시간 처리를 실행하는  
애플리케이션에도 사용합니다

### 스토리지 최적화 인스턴스

로컬 스토리지에서 대규모의 데이터셋에  
액세스할 때 적합한 인스턴스입니다  
스토리지 최적화 인스턴스의 사용 사례로는  
고주파 온라인 트랜잭션 처리인 OLTP 시스템에 사용되며
관계형과 비관계형인 NoSQL 데이터베이스에 사용합니다  
데이터베이스 섹션에서 더 자세히 살펴보겠습니다  
예를 들어, 레디스(Redis) 같은  
메모리 데이터베이스의 캐시나 데이터 웨어하우징 애플리케이션과 분산 파일 시스템에 사용됩니다

## 보안 그룹

`EC2 인스턴스에 들어오고 나가는 트래픽을 제어`합니다
보안 그룹은 간단한데요 허용 규칙만 포함합니다  
출입이 허용된 것이 무엇인지 확인할 수 있고  
IP 주소를 참조해 규칙을 만들 수 있습니다  

### SSH

시큐어 셸이라는 의미로 다음 강의에서 살펴봅니다  
포트는 22번 포트로 Linux에서 EC2 인스턴스로 로그인하도록 합니다  
파일 전송 프로토콜인 FTP의 포트는 21번 포트이며 파일 공유 시스템에 파일을 업로드하는데 사용됩니다

SFTP도 22번 포트를 사용하는 이유는 무엇일까요? SSH를 사용해서 업로드하기 때문이고 
보안 파일 전송 프로토콜이 되기 때문입니다

원격 데스크톱 프로토콜인 RDP의 3389번 포트이며
윈도우 인스턴스에 로그인할 때 사용됩니다

### SSH 연결하기

SSH는 명령줄 인터페이스 도구로  
Mac과 Linux에서 사용할 수 있고  
Windows10 이상의 버전에서 사용할 수 있습니다  
Windows10 이하의 버전이라면  
퍼티(PuTTY)를 사용하면 됩니다  
퍼티는 SSH와 동일한 것입니다  
SSH를 사용해야 할 때 Windows에서는 퍼티를 사용합니다  
퍼티는 모든 버전의 Windows에서 사용 가능합니다  

이제 머신에 접속하기 위해  
ssh ec2-user@와  
35.180.100.144를 입력하고 키를 참조하도록 하기 위해  
머신에 접속할 수 있는 키를 이 중간에 입력합니다  
키를 사용하려면 -i를 입력하고 EC2Tutorial.pem을 입력합니다  
그러면 ssh -i EC2Tutorial.pem가 되고  
그다음은 인스턴스 사용자 이름과 인스턴스 IP가 오게 됩니다  
Enter를 클릭하면 다른 경고문이 나타납니다  
비보호의 개인 키 파일이라는 경고가 나타났습니다    
이 부분이 시험에 정말 잘 나옵니다  
파일을 처음 다운로드하면  
`0644 라는 권한이 생기는데 권한이 너무 열려 있어서 개인 키가 유출될 수 있습니다`
다른 사람이 개인 키에 접근할 수 있어 bad permissions가 나타나고  
SSH를 머신에 연결할 수 없도록 합니다  
해결하는 방법이 자주 출제되며 `해결하려면 chmod 0400` 를 입력하고  
이렇게 키 이름을 참조합니다

## 온-디맨드 인스턴스

`사용한 만큼 지불하는 옵션`이죠  
비용이 초당 청구됩니다 EC2 인스턴스가 실행된  
초반 1분 이후부터 1초당 비용이 청구되죠  
온-디맨드는 클라우드에 가장 적합한 방식으로  
`가격은 높지만, 선결제나 장기 약정이 필요 없습니다`  
사용 해지, 중지, 시작이 언제든 가능하죠  
온-디맨드 방식은  
`애플리케이션 작동 방식을 예측할 수 없는`  
연속적인 단기 워크로드에 적합합니다  

간단 예시  
첫 번째로 온-디맨드는 원할 때면 언제든
리조트에 묵을 수 있는 겁니다
전액을 지불해야 하지만 원하면 언제나 방을 얻을 수 있죠

## 예약 인스턴스

온-디맨드와 비교하면 약 75%의 비용을 절약할 수 있고
`1년 혹은 3년 중에서 선택할 수 있죠`  
3년의 기간을 선택하면 해당 인스턴스를 더 오랜 기간동안  
사용할 의향이 있다고 AWS에 알리는 것과 같습니다  

종종 오랜 시간 동안 사용해야 하는 서버가 있는 경우에는
이를 AWS에 알림으로써 비용을 절감할 수 있는데요
이럴 때 사용 가능한 첫 번째 옵션이 바로 예약 인스턴스입니다
예약 인스턴스는 최소 1년 이상 사용해야 합니다
약속된 기간이죠
예약 인스턴스에는 세 가지 종류가 있는데
첫 번째로는 단순한 예약 인스턴스로
데이터베이스 같은 장기 워크로드에 사용됩니다
그리고 전환형 예약 인스턴스가 있는데
시간이 지난 후 다른 종류의
인스턴스로 바꿀 수 있는 유연형 인스턴스죠

예약 인스턴스가 적합한 곳으로는  
애플리케이션이 안정된 상태로 사용되는, 즉 데이터베이스 등이 해당되죠  
3년간 데이터베이스를 사용해야 하는 상황이라면  
이런 인스턴스를 예약함으로써 비용을 크게 절감할 수 있을 겁니다  

간단 예시  
예약 인스턴스는 오랜 기간 호텔에 머무는 것으로  
미리 계획을 세웁니다  
할인도 괜찮게 받습니다  
한 달 정도 길게 머무는 손님이니까요  

### 정기 예약 인스턴스

그리고 정기 예약 인스턴스가 있습니다
예를 들어 일 년 내내는 아니지만 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)
일 년 동안 매주 목요일 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)
오후 3시부터 6시까지 서버가 필요한 경우죠 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)

### 스팟 인스턴스

온-디맨드 인스턴스에 비교하면 최대 90%까지 할인이 되죠  
여러분이 지불하고자 하는 가격이  
현재 스팟 인스턴스의 가격보다 낮다면  
`인스턴스가 언제든 중단될 수 있다는 겁니다`

저렴한 단기 워크로드 용 인스턴스지만  
손실 가능성이 있으며 신뢰성이 낮습니다  

그럼 어떤 유형의 워크로드가 적합할까요?  
단발성 데이터 분석인 배치 로드  
그리고 이미지 프로세싱 이미지 변환이 중단되어  
한 이미지 변환에 실패해도 나중에 다시 시작하면 되니까요  
그리고 분산된 워크로드가 있는경우

간단 예시  
아시다시피 일부 호텔은 밤에 객실이 빌 때  
아주 공격적인 할인을 선보입니다  
객실을 비워 두면 손해를 볼 것이고 사업이 망할 수도 있죠  
하지만 이 호텔은 조금 이상합니다  
만약 호텔이 여러분보다 객실비를  
더 많이 지불할 수 있는 손님을 찾게 되면  
여러분을 쫓아낼 수 있거든요  
이러면 이상한 호텔이긴 하겠지만 스팟 인스턴스가  
이런 경우와 비슷하답니다

### 전용 호스트

Amazon 전용 호스트는 EC2 인스턴스를 갖춘 유저 중심의 물리적 서버입니다  
즉, AWS 데이터 센터 내 하나의 서버 전체를 임대하는 거죠  
`전용 호스트를 사용하면 준수 요건의 처리가 쉽고`   
기존의 `서버 결합 소프트웨어 라이센스`의 사용이 가능하기 때문에  
비용을 절감할 수 있습니다  

전체 서버를 독자적으로 이용하게 되니 비용은 더 올라갑니다  
만약 복잡한 라이센스 모델의 소프트웨어를 사용하거나  
자가 라이센스를 가진 경우, 혹은 강력한 규제나 규정 준수 요건이  
있을 때도 상당히 도움을 주는 옵션이죠  

간단 예시  
이 경우 리조트 전체를 혼자서 예약합니다  
규정 준수 관련 이유로 이웃이 없어야 하거나  
서버 결합 라이센스를 가지고 있는 등의 이유 때문이죠  

### 전용 인스턴스

여러분의 전용 하드웨어에서 실행되는 EC2 인스턴스를 의미합니다  
같은 계정의 다른 인스턴스와 하드웨어를 공유하며  
인스턴스가 어떻게 배치될지에 대해서는 여러분이 간섭할 수 없습니다  
다시 말해, 전용 하드웨어가 있어도  
해당 하드웨어의 근본에는 접근할 수가 없습니다  
전용 호스트의 약한 버전이라고 할까요

# EBS 볼륨

EBS 볼륨은 일래스틱 블록 스토어의 줄임말입니다  
네트워크 USB 스틱이라고 생각하시면 됩니다  
USB 스틱처럼 한 컴퓨터에서 꺼내, 다른 컴퓨터에 꽂는  
그런 장치는 맞지만 실제 물리적 연결은 없으며  
네트워크를 통해 연결되는 거죠  

EBS 볼륨은 특정한 가용 영역에 고정되어 있으므로  
us-east-1a에 생성된 볼륨은  
us-east-1b로 연결이 불가능합니다

## 스냅샷

언제든 원하는 시점에 EBS 볼륨을 가지고 와서  
`백업이라고 불리기도 하는 스냅샷(Snapshot)`을 생성할 수 있습니다

스냅샷을 생성하는 이유는 무엇일까요? 복원 목적도 있으나  
가용 영역(AZ) 또는 리전(Region)에 걸친 스냅샷을 복사할 수 있기 때문입니다

더불어서 AWS의 다른 리전에 데이터를 전송하여 글로벌 인프라를 활용하는 것이죠  
또 다른 가용 영역에 새로운 EBS 볼륨을 복원할 수 있습니다

## AMI

AMI는 Amazon Machine Image의 약자로 사용자 지정 EC2 인스턴스를 나타냅니다  
각자의 소프트웨어 구성에 대해 운영 체제를 정의 및 설정하며 모니터링 도구를 설정할 수도 있는데  
이때 자체적으로 AMI를 생성하면 부팅과 구성에 시간이 단축됩니다

다른 사용자가 만들어서 판매하는 AMI로 자주 찾아볼 수 있습니다 AWS의 공급 업체가  
자체적으로 AMI나 구성이 훌륭한 소프트웨어를 생성하고  
여러분은 시간 절약을 위해 `마켓 플레이스 AMI에서 이들을 구매`할 수 있습니다

`AMI는 특정 AWS 지역용으로 구축되며 각 AWS 지역마다 고유`합니다.   
다른 AWS 지역의 AMI를 사용하여 EC2 인스턴스를 시작할 수는 없지만   
AMI를 대상 AWS 지역에 복사한 다음 이를 사용하여 EC2 인스턴스를 생성할 수 있습니다.

## 인스턴스 스토어

EC2 인스턴스는 가상 머신이지만 `실제로는 하드웨어 서버에 연결`되어 있습니다  
EC2 인스턴스 스토어는 I/O 성능 향상을 위해 활용할 수 있습니다  
이들이 훌륭한 처리량을 갖추고 있어서 매우 향상된 디스크 성능을  
요할 때에 활용할 수 있도록 확보할 필요가 있습니다

이때 주의할 점은 여러분이  
EC2 인스턴스, 즉 인스턴스 스토어를 중지 또는 종료하면  
해당 스토리지 또한 손실된다는 것입니다  
이 같은 이유로 이를 임시 스토리지라고 부르며  
EC2 인스턴스 스토어가  
`장기적으로 데이터를 보관할 만한 장소가 될 수 없음을 보여 줍니다`

그러면 언제 사용하는 것이 좋을까요?  
버퍼나 캐시 스크래치 데이터 또는 임시 콘텐츠를 사용하려는 경우  
이들을 보관할 좋은 장소가 되지만 장기적인 스토리지는 될 수 없습니다  
장기 스토리지의 경우에는 EBS 가 적합합니다

마지막으로 EC2 인스턴스의 기본 서버에 장애가 발생할 시에는  
해당 EC2 인스턴스가 연결된 하드웨어에도  
장애가 발생하므로 데이터 손실에 대한 위험이 존재합니다  
따라서 EC2 인스턴스 스토어를 사용할 때에는  
여러분의 필요에 따라 데이터를 백업해 두거나  
복제해 둬야 합니다

## EBS 볼륨

총 여섯 개의 유형이 있고
이들을 여러 범주로 나눌 수 있습니다

`gp2/gp3`가 있는데 이는 범용 SSD 볼륨으로
`다양한 워크로드에 대해 가격과 성능의 절충안이 되어 줍니다`

`io1과 io2`가 있습니다  
최고 성능을 자랑하는 SSD 볼륨으로  
`미션 크리티컬이자 지연 시간이 낮고 대용량의 워크로드`에 쓰입니다

`st1` 볼륨이 있는데 이는 저비용의 HDD 볼륨으로  
`잦은 접근과 처리량이 많은 워크로드`에 쓰이죠

`sc1` 볼륨은 가장 비용이 적게 드는 HDD 볼륨으로  
`접근 빈도가 낮은 워크로드`를 위해 설계되었습니다

EBS 볼륨은 어떻게 정의하는 걸까요?  
가령 크기, 처리량과 IOPS가 있죠  
`IOPS는 초당 I/O 작업 수`를 뜻합니다

EC2 인스턴스에는  
`gp2/gp3와 io1/io2만이 부팅 볼륨`으로 사용될 수 있습니다  

gp2 는 짧은 지연 시간을 자랑하며 효율적인 비용의 스토리지입니다  
시스템 부팅 볼륨에서 가상 데스크톱, 개발, 테스트 환경에서 사용할 수 있죠   
gp2는 좀 더 오래된 버전으로 볼륨이 더 작습니다 최대 3,000 IOPS에  
볼륨과 IOPS가 연결되어 있어서 IOPS가 증가할 때면  
즉 볼륨의 GB 수를 늘릴 때에 세 배 더 증가한 16,000 IOPS가 된다는 의미입니다

gp2와 gp3에는 차이가 있는데 gp3는 최신 세대의 볼륨으로  
기본 성능으로 3,000 IOPS와 초당 125MB의 처리량을 제공합니다  
각각 IOPS는 최대 16,000 처리량은 1,000MB/s까지 증가시킬 수 있습니다

gp2/gp3가 비용 효과적인 스토리지이며  
`gp3에서는 IOPS와 처리량을 독자적으로 설정`할 수 있는 반면  
`gp2에서는 그 둘이 연결되어 있다는 점`입니다

### IOPS

이는 IOPS 성능을 유지할 필요가 있는 주요 비즈니스 애플리케이션이나  
16,000 IOPS 이상을 요하는 애플리케이션에 적합합니다  
일반적으로 `데이터베이스 워크로드`에 알맞죠

### 스토리지

io1/io2에 중에서는 최신 세대를 고르는 것이 좋습니다 4에서 16TB에 달하며  
Nitro EC2 인스턴스에서는 최대 64,000 IOPS까지 가능합니다  
Nitro EC2 인스턴스의 경우 이를 통해 더 높은 IOPS까지 이용할 수 있습니다  
Nitro EC2 인스턴스가 아닌 경우에는  
최대 32,000 IOPS까지 지원됩니다  
또한 io1/io2를 이용하면 gp3 볼륨처럼 프로비저닝된 IOPS를  
스토리지 크기와 독자적으로 증가시킬 수 있습니다  
io2 이용 장점은 무엇일까요?
`io1과 동일한 비용으로 내구성과 기가 당 IOPS의 수가 더 높습니다`  
현재까지는 io2를 사용하는 것이 더 합리적인 거죠

### st1과 sc1

부팅 볼륨일 수 없습니다   
최대 16TB까지 확장

두 가지 종류의 볼륨을 제공합니다  
하나는 st1인 처리량 최적화 HDD로  
빅 데이터나 데이터 웨어하우징 로그 처리에 적합합니다

최대 처리량은 초당 500MB 그리고 최대 IOPS는 500에 달합니다  
다음으로는 sc1인 콜드 HDD가 있는데 이는 아카이브 데이터용으로  
접근 빈도가 낮은 데이터에 적합합니다  
최저 비용으로 데이터를 저장할 때에 사용하죠  
최대 처리량은 초당 250MB  
그리고 최대 IOPS도 250입니다

### EBS 다중 연결

앞서 EBS 볼륨은 단일한 EC2 인스턴스에만 연결할 수 있다고 했습니다  
EBS 다중 연결을 제외한 경우에 말이죠   
동일한 가용 영역 내의 여러 EC2 인스턴스에 연결하여 사용할 수 있습니다  
EBS는 `io1이나 io2 제품군일 때만 여러 EC2 인스턴스에 연결이 가능`합니다

## EFS 

Elastic File System 의 약자로  
다양한 가용 영역에 걸쳐 다수의 EC2 인스턴스에  
마운트 할 수 있는 관리형 NFS 혹은 네트워크 파일 시스템입니다  
즉 `다중 AZ에서 동작`하며   
이 점이 EFS와 EBS의 가장 큰 차이를 보여 줍니다  

EBS는 단일 가용 영역에 묶여 있는 반면  
`EFS는 다중 가용 영역에 걸쳐서 마운트가 가능`합니다

따라서 가용성이 매우 높죠   
확장성도 높으며 비용도 많이 듭니다

EBS는 한 번에 하나의 EC2 인스턴스에만 연결되어 있어서  
데이터가 다중의 EC2 인스턴스 간 공유되지 않지만

EFS 에서는 네트워크 파일 시스템으로  
`EFS 드라이브의 모든 EC2 인스턴스가 동일한 파일에 대한 접근 권한`을 갖습니다

EFS는 콘텐츠 관리, 웹 서비스  
데이터 공유 또는 WordPress 웹사이트에서 쓰입니다  
`표준 NFSv4.1 프로토콜`이 사용되며  
이는 네트워크 드라이브 마운트 시 기본적인 방법입니다  

EFS는 Windows가 아닌 `Linux 기반 AMI에서만 작동`합니다

EFS 옵션에 대해서는 어떤 사항을 알고 있어야 할까요? 먼저 그 규모를 알아야 합니다
EFS는 수천 명의 동시 클라이언트와  
초당 최대 10GB의 처리량을 자랑합니다   
성능이 아주 우수한 거죠  
또한 파일 시스템 자체가 페타바이트(PB) 정도까지  
확장될 수 있으므로 용량을 따로 관리할 필요가 없습니다  
자동으로 수행되죠

### 성능 모드

웹 서버 운영이나 지연 시간에 민감한 파일이 있는 경우  
범용 성능 모드를 사용합니다

EFS에서 대규모 데이터 워크로드를 처리하는 경우  
Max I/O 성능 모드가 적합합니다    
지연 시간은 더 길겠지만 처리량은 더 향상됩니다

### 처리량 모드
 
기본적으로는 버스팅(Bursting) 처리량 모드로 설정되어 있습니다
1TB의 스토리지에 대해  
초당 50MB를 저장할 수 있으며  
여기에 초당 100MB까지 확장이 가능하다는 겁니다  
일반적으로는 파일 시스템의 크기에 따라  
처리량이 증가하므로 EFS 파일 시스템의  
크지는 줄이면서 처리량을 높이기 위해서는  
프로비저닝 된 처리량 모드로 설정을 바꿀 수 있습니다  
이 모드에서는 스토리지 크기와 상관없이 처리량을 설정할 수 있죠  
1TB의 스토리지에 불과하더라도  
초당 1GB의 처리량을 요청할 수 있습니다

접근 빈도가 높은 파일에 대해 표준으로 설정되어 있으며  
EFS-IA라고 부르며 저비용의 빈도가 낮은 접근에 대한 티어가 있습니다  
이와 같은 파일을 저장할 저비용의 장소인 거죠

## EBS vs EFS

### EBS

EBS 볼륨은 한 번에 하나의 인스턴스에만 연결이 가능하고  
특정 가용 영역에 한정됩니다  

gp2에서는 디스크 크기가 늘어나면 IO도 함께 증가하죠  

io 1은 IO를 볼륨 크기와 관계 없이 독립적으로 증가시킬 수 있죠  
중요한 데이터베이스를 실행할 때 좋은 방법입니다

EBS를 다른 가용 영역으로 옮기고자 할 때는  
가장 먼저 스냅샷을 찍어야 합니다  
스냅샷을 찍었다면  
다른 AZ에서 그 스냅샷을 복원시키죠

EBS의 스냅샷이나 백업을 만들 때에는  
EBS 볼륨 내의 IO를 전부 사용하게 되니  
`인스턴스가 EBS를 사용 중이 아닐 때에만 실행`하셔야 합니다

EBS의 경우에는 실제 사용한 양이 아니라  
EBS 드라이브의 크기에 따라  
실제 사용량이 아니라 정해진 사용량을 지불하는 식이었죠

반면 EBS는 네트워크 볼륨을 한 번에 하나의 인스턴스에  
연결할 수 있고 특정 AZ 내로 한정이 되죠  
인스턴스 스토어는 EC2 인스턴스에 IO를 최대로 사용하게끔 해주지만,
`인스턴스가 망가지면 함께 망가지는`  
임시 드라이브인 거죠

### EFS

EFS는 여러 개의 가용 영역에 걸쳐  
`무수히 많은 인스턴스들에 연결`될 수 있습니다

이는 Linux 인스턴스에서만, 가능한데 POSIX 파일 시스템이라  
Windows에서 구동되지 않기 때문입니다

`EFS 는 EBS 보다 훨씬 비쌉니다`  
거의 세 배 정도 더 비싸죠

# ELB

## 고가용성과 확장성

### 확장성

확장성은 애플리케이션 시스템이  
`조정을 통해 더 많은 양을 처리`할 수 있다는 의미입니다  

우선 `수직 확장성`이 있고  
탄력성이라고 불리기도 하는 `수평 확장성`이 있습니다  

확장성과 고가용성은 서로 다른 개념입니다

먼저 수직 확장성입니다  
수직 확장성은 인스턴스의 크기(T2.small -> T2.lage) 처럼 `사양을 확장하는 것을 의미`합니다
그러면 이런 수직 확장성을 언제 사용하게 되는 걸까요?  
데이터베이스와 같이 분산되지 않은 시스템에서 흔히 사용됩니다   
하지만 일반적으로 확장할 수 있는 정도에는 한계가 있는데요  
하드웨어 제한이 걸려 있죠  

수평 확장성이란  
애플리케이션에서 `인스턴스나 시스템의 수`를 늘리는 방법입니다  
T2.small T2.small T2.small ...

`수평 확장은 인스턴스의 수를 늘린다는 뜻`인데  
AWS 용어로는 스케일 아웃과 스케일 인이라고 합니다  
인스턴스의 수가 `늘어나면 스케일 아웃`이고요  
`수를 줄이면 스케일 인`이죠  
다른 스케일링 그룹이나 로드 밸런서에도 사용합니다

고가용성은 `동일 애플리케이션의 동일 인스턴스를 다수의 AZ에 걸쳐 실행하는 경우`를 의미하죠   
다중 AZ가 활성화된 자동 스케일러 그룹이나 로드 밸런서에서도 사용됩니다  

## 로드 밸런싱

부하를 다수의 다운스트림 인스턴스로 분산하기 위해서죠  
다운스트림 인스턴스의 장애를 원활히 처리할 수 있죠  
로드 밸런서가 상태 확인 메커니즘으로  
어떤 인스턴스로 트래픽을 보낼 수 없는지 확인해 주거든요  

해당 인스턴스로는 트래픽을 보낼 수 없기 때문에  
로드 밸런서에겐 인스턴스의 상태가  
아주 중요하죠 그리고 상태 확인은  
포트와 라우트에서 이뤄집니다  

### Classic Load Balancers

이 로드 밸런서는 TCP나 트래픽 아니면 HTTP와 HTTPS를 지원합니다  
TCP는 4계층으로 HTTP/HTTPS는 7계층인데요

상태 확인은 TCP 또는 HTTP 기반으로 이루어집니다

### 애플리케이션 로드 밸런서

7계층, 즉 `HTTP 전용 로드 밸런서`로  
머신 간 다수 HTTP 애플리케이션의 라우팅에 사용이 되죠  
이러한 머신들은 대상 그룹이라는 그룹으로 묶이게 되는데요
동일 EC2 인스턴스 상의 여러 애플리케이션에 부하를 분산합니다  

컨테이너와 ECS를 사용하게 되죠  
HTTP/2와 WebSocket을 지원하며 리다이렉트도 지원하므로  
HTTP에서 HTTPS로 트래픽을 자동 리다이렉트하려는 경우  
로드 밸런서 레벨에서 가능하다는 의미가 되겠죠  

EC2 인스턴스가 대상 그룹이 될 수 있습니다

Application Load Balancer를 사용하여 EC2 인스턴스로 트래픽을   
분산할 때 요청을 수신하는 IP 주소는 ALB의 프라이빗 IP 주소가 됩니다.   
클라이언트의 IP 주소를 가져오기 위해 ALB는 클라이언트의 IP 주소를 포함하는  
X-Forwarded-For라는 추가 헤더를 추가합니다.

ALB는 URL 경로, 호스트 이름, HTTP 헤더 및 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다.

### 네트워크 로드 밸런서

layer 4(L4) 밸런서로  
TCP나 UDP 기반의 트래픽을  
인스턴스로 전달하는 것입니다  
낮은 계층의 밸런서죠  
초당 수백만 건의 요청을 처리할 수 있어 매우 고성능입니다  
ALB보다 지연 시간이 훨씬 짧습니다

밸런서 `애플리케이션의 평균 지연 시간은 400ms` 이고
반면에 `NLB의 지연 시간은 약 100ms` 입니다

NLB의 사용 사례를 살펴보면 고성능이나 TCP 또는 UDP 수준의  
트래픽을 원할 때 사용합니다

그렇다면 NLB는 무엇을 트래픽에 보낼까요?

여러 대상 그룹인데  
첫 번째는 EC2 인스턴스로  
대상 그룹에 EC2 인스턴스를 등록하면  
NLB에서 트래픽 전송 방법을 파악합니다  

두 번째는 IP 주소입니다  
고정 IP와 개인 IP를 지정해서  
NLB에서 직접 트래픽을 보내도록 합니다  
이유가 무엇일까요?  
약간 과하지만 EC2 인스턴스의 경우  
자체 데이터 센터에 서버가 있는 경우에는  
가급적이면 그대로 개인 IP가 있는 서버의 로드 밸런서를 사용합니다

세 번째 옵션은 ALB입니다  
`NLB와 ALB를 결합`하는 것이 가능하죠  
왜 결합할까요?  
NLB의 기능을 활용해서 고정 IP를 가질 수 있기 때문입니다  
따라서 NLB 수준의 고정 IP를 가지면서  
규칙과 같은 HTTP 관련 기능에  
ALB를 활용할 수 있는 것이죠  

Network Load Balancer에는 AZ당 하나의 static IP 주소가 있으며 
Elastic IP 주소를 연결할 수 있습니다. 
Application Load Balancer 및 Classic Load Balancer는 
static DNS 이름입니다.

### 게이트웨이 로드 밸런서

GWLB는 네트워크의 모든 트래픽이  
방화벽을 통과하게 하거나  
침입 탐지 및 방지 시스템에 사용합니다  
그래서 IDPS나 심층 패킷 분석 시스템 또는  
일부 페이로드를 수정할 수 있지만  
네트워크 수준에서 가능합니다

모든 로드 밸런서보다 낮은 수준에서 실행됩니다  
IP 패킷의 네트워크 계층인 L3입니다  
이제 GWLB는 2가지 기능을 갖게 됩니다

첫 번째는 투명 네트워크 게이트웨이입니다  
VCP의 모든 트래픽이 GWLB가 되는  
단일 엔트리와 출구를 통과하기 때문입니다  
그리고 대상 그룹의 가상 어플라이언스 집합에  
전반적으로 그 트래픽을 분산해 로드 밸런서가 됩니다  
이 부분이 GWLB에 관해 꼭 알아야 할 부분입니다  
마지막으로 시험 볼 때  
6081번 포트의 GENEVE 프로토콜을 사용하세요  
바로 GWLB가 됩니다

## Sticky Sessions

중요한 정보를 취하는  
세션 데이터를 잃지 않기 위해  
사용자가 동일한 백엔드 인스턴스에 연결됩니다  
고정성을 활성화하면  
백엔드 EC2 인스턴스 부하에 불균형을 초래할 수 있습니다  
일부 인스턴스는 고정 사용자를 갖게 됩니다  

### 애플리케이션 기반 쿠키

대상으로 생성된 사용자 정의 쿠키로  
애플리케이션에서 생성됩니다  
그리고 애플리케이션에 필요한 모든 사용자 정의 속성을 포함할 수 있죠  
쿠키 이름은 각 대상 그룹별로 개별적으로 지정해야 하는데  
이런 이름은 사용하면 안 됩니다  
AWSALB, AWSALBAPP 혹은 AWSALBTG 같은 이름이죠  
ELB에서 사용하기 때문입니다

애플리케이션 쿠키가 될 수도 있는데  
지금은 로드 밸런서 자체에서 생성됩니다  
그리고 ALB의 쿠키 이름은 AWSALBAPP입니다 

### 기간 기반 쿠키

로드 밸런서에서 생성되는 쿠키로  
ALB에서는 이름이 AWSALB이며 CLB에서는 AWSELB입니다  
특정 기간을 기반으로 만료되며 그 기간이 로드 밸런서 자체에서  
생성되는 것입니다  
애플리케이션 기반의 쿠키는  
애플리케이션에서 기간을 지정할 수 있습니다

## 교차 영역 로드 밸런싱

교차 영역 로드 밸런싱은 ALB에서 늘 활성화되어 있고
비활성화할 수 없습니다  
보통 데이터가 한 가용 영역에서 다른 가용 영역으로 이동하면  
비용을 지불해야 합니다  
하지만 활성화되어 비활성화할 수 없으니  
AZ 간 데이터 전송에 관한 비용이 없습니다  

네트워크 로드 밸런서에는 기본으로 비활성화되어 있어서  
교차 영역 로드 밸런싱 활성화에 비용을 지불해야 합니다  
가용 영역 간 데이터 전송에 비용을 지불해야 하는 것이죠

마지막으로 클래식 로드 밸런서에는  
교차 영역 로드 밸런싱이 기본으로 비활성화되어 있습니다  
활성화하면 가용 영역 간 데이터 전송에 비용이 발생하지 않습니다  
모든 로드 밸런서에서 사용할 수 있는 것이죠

`ALB에는 기본적으로 활성화`되어 있고  
`NLB에서 활성화하려면 비용`을 내야 합니다  
그리고 `CLB 에는 비용 없이 활성화`할 수 있습니다

## SSL

SSL 인증서를 사용하면 클라이언트와 로드 밸런서  
사이에서 전송 중에 있는 트래픽을 암호화할 수 있습니다  
인-플라이트 암호화라고 불리는 과정으로  
`즉 데이터가 네트워크를 통과하는 중에 암호화되고  
발신자와 수신자만이 이를 해독할 수 있는 거죠`  
SSL은 보안 소켓 계층을 뜻하며 연결을 암호화하는 데에 사용됩니다  
그리고 TLS는 SSL의 최신 버전으로써 전송 계층 보안을 의미하죠  
요즘에 주로 사용되는 건 TLC 인증서지만  
저를 포함한 많은 사람들은 이를 여전히 SSL이라고 부르고 있습니다  

공용 SSL 인증서는 Comodo, Symantec GoDaddy, GlobalSign  
Letsencrypt 등의 인증 기관에서 발급됩니다  
로드 밸런서와 연결된 공용 SSL 인증서를 사용하면  
클라이언트와 로드 밸런서 사이의 연결을 암호화할 수 있습니다

유저가 HTTPS를 통해 연결됩니다  
이때 S는 SSL 인증서를 사용하고 있다는 의미이며  
암호화되어 안전한 상태죠  
그리고 공용 인터넷을 통해 로드 밸런서와 연결되죠  
그리고 이때 로드 밸런서는 내부적으로  
SSL 인증서 종료라는 작업을 수행합니다  
그리고 백엔드에서는 EC2 인스턴스와 통신할 수 있는데, HTTP를 사용하기  
때문에 암호화는 되어 있지 않죠 하지만 트래픽은 어느 정도의 안전성을  
보장하는 사설 네트워크인 VPC를 통해 전송됩니다  
그럼 로드 밸런서가 X.509 인증서를 불러옵니다  
SSL 혹은 TLS 서버 인증서라고 불리는 인증서죠  
그리고 AWS에서 ACM을 사용해 SSL 인증서를 관리할 수 있습니다  
ACM은 AWS 인증서 관리자의 약자죠

SNI, 즉 서버 이름 표시  
CLB는 구형 버전으로 SNI를 지원하지 않는다는 점  
반면 ALB와 NLB는, SNI 및 다중 SSL 인증서를 지원하죠

## 등록 취소 지연

클래식 로드 밸런서를 사용할 경우에는 연결 드레이닝이라 부르고  
애플리케이션 밸런서나 네트워크 로드 밸런서를 사용하는 경우에는 등록 취소 지연 이라 부른다.

인스턴스가 등록 취소, 혹은 비정상인 상태에 있을 때  
인스턴스에 어느 정도의 시간을 주어  
인-플라이트 요청, 즉 활성 요청을 완료할 수 있도록 하는 기능이죠  
연결이 드레이닝되면 즉 인스턴스가 드레이닝되면  
ELB는 등록 취소 중인 EC2 인스턴스로  
새로운 요청을 보내지 않는 거죠

연결 드레이닝 파라미터는 매개변수로 표시할 수 있습니다  
1부터 3,600초 사이의 값으로 설정할 수 있는데  
`기본적으로는 300초, 즉 5분`입니다

## 오토스케일링 AGS

스케일 아웃이 있습니다  
부하가 증가하면 거기 맞춰서 EC2 인스턴스를 추가하는 거죠  
반면 스케일 인은 줄어든 부하에 맞춰 EC2 인스턴스를 제거하는 작업입니다  
그리고 오토 스케일링 그룹은 EC2 인스턴스가 일정량만큼만  
증가하거나 줄어들도록 만들 수도 있는데요  
그렇게 되면 ASG에서 실행되는  
머신의 최소 및 최대 숫자를 설정할 수 있습니다
마지막으로 ASG에는 굉장히 좋은 기능이 있는데요  
`로드 밸런서에 자동으로 새 인스턴스를 등록해 주는 기능입니다`

### 오토 스케일링 그룹의 스케일링 정책

먼저 동적 스케일링 정책부터 보겠습니다  
동적 스케일링 정책은 세 가지 유형이 있습니다  

첫 번째는 대상 추적 스케일링으로 가장 단순하고 설정하기도 쉽죠  
예를 들면 모든 EC2 인스턴스에서  
오토 스케일링 그룹의 평균 CPU 사용률을 추적하여  
이 수치가 40%대에 머무를 수 있도록 할 때에 사용합니다  
이처럼 기본 기준선을 세우고  
상시 가용이 가능하도록 하는 거죠  

단순과 단계 스케일링은 좀 더 복잡합니다  
CloudWatch 경보를 설정하고  
가령 다음과 같이  
전체 ASG에 대한 CPU 사용률이 70%를 초과하는 경우  
용량을 두 유닛 추가하도록 설정할 수 있죠  
그리고 전체 ASG 내의  
CPU 사용률이 30% 이하로 떨어지면 유닛 하나를 제거한다는  
설정도 추가할 수 있습니다

예약된 작업이 있습니다  
나와 있는 사용 패턴을 바탕으로 스케일링을 예상하는 거죠  
예를 들어서  
금요일 오후 5시에 큰 이벤트가 예정되어 있으니  
여러 사람들이 애플리케이션을 사용하는 데에 대비해  
여러분의 ASG 최소 용량을  
매주 금요일 오후 5시마다 자동으로 10까지 늘리도록 하는 겁니다  

제 생각에는 머신 러닝을 기반으로 하며  
손쉬운 ASG 오토 스케일링 중 하나인 예측 스케일링이 향후 더욱 대두될 겁니다
따라서 스케일링 기반이 될 훌륭한 지표가 있어야겠죠  
여러분의 애플리케이션의 목적과 작동 방식에 따라 달라지긴 하지만  
대표적인 것들을 살펴보겠습니다  
첫째로는 CPU 사용률을 들 수 있습니다  
일반적으로 인스턴스에 요청이 갈 때마다  
일종의 연산이 수행되어야 하므로  
이 과정에서 일부 CPU가 사용됩니다  
모든 인스턴스의 평균 CPU 사용률을 봤을 때  
이 수치가 올라가면  
인스턴스가 잘 사용되고 있다는 의미이니  
스케일링에 있어서 좋은 지표가 될 겁니다  
또 다른 지표를 보겠습니다  
애플리케이션에 따라 다를 수 있습니다만  
테스트를 기반으로 하는 대상별 요청의 수를 들 수 있습니다  
EC2 인스턴스는 한 번에 대상별로  
1,000개의 요청까지만 최적으로 작동하므로  
바로 이 대상을 스케일링에 활용할 수 있겠습니다  
예를 들어서 업로드와 다운로드가 많아  
EC2 인스턴스에 대해 해당 네트워크에서 병목 현상이 발생할 것으로 판단된다면  
평균 네트워크 입출력량을 기반으로 스케일링을 수행해서  
특정 임계값에 도달할 때  
스케일링을 수행하도록 설정할 수 있습니다  
또는 여러분이 직접 CloudWatch에서  
애플리케이션 별로 지표를 설정하고  
이를 기반으로 스케일링 정책을 바꿀 수 있습니다

스케일링 휴지(Scaling Cooldown)
인스턴스의 추가 또는 삭제를 막론하고  
기본적으로 5분 혹은 300초의 휴지 기간을 갖는 것입니다  
휴지 기간에는 ASG가 추가 인스턴스를 실행 또는 종료할 수 없습니다 

EC2 Health Checks(기본값) 대신 Application Load Balancer Health Checks을 기반으로 EC2 인스턴스의 상태를 확인하도록 ASG을 구성할 수 있습니다. EC2 인스턴스가 ALB Health Checks에 실패하면 비정상으로 표시되고 ASG가 새 EC2 인스턴스를 시작하는 동안 종료됩니다.

# RDS

`RDS는 관계형 데이터베이스 서비스`를 나타내며  
이는 SQL을 쿼리 언어로 사용하는  
데이터베이스를 위한 관리형 데이터베이스를 뜻합니다

EC2 인스턴스 상에 자체 데이터베이스 서비스를 배포하지 않고    
RDS를 사용하는 이유는 무엇일까요?
RDS는 관리형 서비스로  
AWS가 데이터베이스뿐만 아니라  
여러 기타 서비스 또한 제공하고 있습니다  
가령 해당 데이터베이스의 프로비저닝은 완전히 자동화되어 있고  
기본 운영 체제 패치 또한 자동으로 이루어집니다  
또한 지속적인 백업이 수행되며  
특정 타임스탬프도 복구할 수 있습니다  
이를 지정 시간 복구 PITR이라고 합니다

다중 AZ를 설정할 수 있고  
재해 복구 시 유용하게 이용하는  
다중 AZ에 대한 강의 섹션 또한 찾아보실 수 있습니다  
업그레이드를 위한 유지 보수도 존재하고  
인스턴스 유형을 늘려서  
읽기 전용 복제본을 추가함으로써 인스턴스 유형의  
수직 및 수평 확장성을 증가시킬 수도 있습니다  
끝으로 스토리지가 EBS를 기반으로 하는데  
gp2 볼륨 또는 io1을 뜻한다는 것은 전에 다룬 바 있어서 다들 알고 계시겠죠

단 RDS 인스턴스에는  
SSH를 따로 가질 수 없습니다
이는 `관리형 서비스로 AWS에서 제공되므로 기본 EC2 인스턴스에 대해서는  
사용자가 따로 접근 권한을 갖지 않기 때문`이죠

## 백업

백업은 RDS에서 자동으로 활성화되며 자동으로 생성됩니다  
정의해 놓은 유지 관리 기간 동안  
매일 수행되는 데이터베이스 전체에 대한 백업과  
트랜잭션 로그, 즉 일일 트랜잭션 로그가  
매 `5분 마다 RDS에 백업`되죠

자동 백업은 기본적으로는 7일간 보관되지만  
`최대 35일까지로 보관 기간을 설정`할 수 있습니다  
또한 데이터베이스 스냅샷이 있는데  
스냅샷은 백업과 약간 다릅니다  
스냅샷은 사용자가 수동으로 발동시키는 백업으로  
백업 보관 기간을  
사용자 임의로 설정할 수 있습니다

### 오토스케일링

RDS 데이터베이스를 생성할 때는 원하는 스토리지 용량을 지정해야 합니다  
스토리지를 20GB로 지정하는 것과 같이 말이죠  
단 데이터베이스 사용이 많고  
사용 가능한 공간이 부족해지는 경우  
바로 이 기능
`RDS 스토리지 오토 스케일링`이 활성화되어 있으면  
RDS가 자동으로 스토리지에 대한 스케일링을 수행하죠  
따라서 스토리지 확장을 위해  
데이터베이스를 중단하는 등의 작업을 따로 수행할 필요가 없습니다  
즉 애플리케이션이  
RDS 데이터에 다량의 읽기 및 쓰기 작업을 수행할 때에  
자동으로 특정한 임계값을 확인해서  
스토리지에 대한 오토 스케일링 작업이 수행되는 RDS 기능입니다

## RDS 다중 AZ (Multi AZ)

다중 AZ는 `주로 재해 복구에 사용`됩니다    
만약 RDS DB를 만들고, DB에 특정 레코드를 인서트 할 시, 다른 AZ(Availability Zone)에 똑같은 복제본이 만들어집니다.  
Multi AZ는 AWS 에 의해서 자동으로 관리가 이뤄집니다.  
직접 번거로운 과정을 거치지 않아도 되고, 유사시 우리가 현재 사용하고 있는 메인 DB에 문제가 생길 경우  
RDS 는 이를 즉시 발견하고 다른 AZ에 만들어진 복제본을 그대로 사용합니다.  
이를 Disaster Recovery 라고 부릅니다. Multi AZ는 복제본을 만든다고 해서 성능이 더 좋아지는 건 아니지만, 만약 성능개선이 주목적이라면,  
Read Replicas 를 사용해야 합니다.

만약 Amazon RDS Active에 어떤 문제가 생긴다면,  
RDS는 자동으로 Amazon RDS back-up으로 fail over를 합니다.   
뭔가 새로 만들거나, 헤비 워크가 필요 없기 때문에 재해가 생길 시, 재해복구 시간이 현저히 감소됩니다.

재해 복구를 대비해서 `읽기 전용 복제본을 다중 AZ로 설정할 수 있다.`    
원하는 경우에는 읽기 전용 복제본을 다중 AZ로도 설정할 수 있습니다

단일 AZ에서 다중 AZ로 RDS 데이터베이스 전환이 가능할지 물을 수 있습니다  
이 작업에는 다운타임이 전혀 없는 점을 염두에 둬야 합니다  
즉 단일 AZ에서 다중 AZ로  
전환할 때에 데이터베이스를 중지할 필요가 없는 겁니다

## 읽기 전용 복제본 (Read Replica)

읽기 전용 복제본은 이름에서 알 수 있듯 `읽기를 스케일`링합니다

- 생성과정
  1. 원본 스냅샷 생성
  2. 스냅샷을 통해 복제본 인스턴스 생성
  3. 변경사항 발생 시 비동기식 복제

Replication 이란 `백업과 성능 향상을 위해서 데이터베이스를 여러 대의 서버에 복제`하는 행위를 뜻합니다.   
원본 데이터가 위치하는 서버를 마스터라고 하고, 그 원본을 복제한 서버를 슬레이브라고 합니다.  
마스터와 슬레이브를 `구분할 때는 읽기와 쓰기`를 이용합니다.  
데이터베이스의 작업은 읽기와 쓰기로 구분할 수 있습니다.  
SQL 로 말하면 읽기는 SELECT 구문이고, 쓰기는 INSERT, UPDATE, DELETE입니다.   
그런데 쓰기 작업은 저장된 데이터가 변경되기 때문에 복제된 서버들 간에 동일한 형태를 유지하는 것이 어렵습니다.  
그래서 보통 한대의 서버에만 쓰기 작업을 하고, `그 서버의 데이터를 복제해서 여러 대의 슬레이브 서버를 만든 후에 슬레이브에서는 읽기 작업만을 수행`합니다.   
read replica란 바로 이런 작업을 RDS에서 할 수 있도록 해주는 서비스입니다.

즉, Read Replica 는 RDS DB 인스턴스의 읽기 전용 인스턴스입니다.   
`서비스에서 읽기 위주의 작업이 많은 경우 Read Replica 를 여러 개 만들어서 부하를 분산`할 수 있습니다.   
즉, 쓰기 작업은 마스터 DB 인스턴스에 하고 읽기 작업은 Read Replica 에 할당하면 마스터 DB 인스턴스의 부하를 줄일 수 있습니다.   
만약 마스터 DB 인스턴스에 쓰기를 하면 자동으로 Read Replica DB 인스턴스로 데이터가 복제됩니다.   
단, 즉시 복제되는 것은 아니며 약간의 시간차가 있습니다.

Read Replica 는 성능 극대화를 위해 존재하기에, `Read heavy work 가 많을 시 Read Replica 를 사용`해야 합니다.   
만약 트래픽이 많아진다면, 서버 다운이 일어날 수 있는데, 이를 방지하기 위해 Read Replicas를 사용한다고 이해하면 좋습니다.   
앞서 배운 Multi AZ 와는 달리 이 기능은 Disaster Recovery 용도가 아닙니다.  
Read Replica 는 하나의 RDS DB에 대해 최대 5개까지 생성 가능합니다.  
또한 Read Replica 의 Read Replica 를 생성할 수 있습니다.  
하지만 생성 혹은 사용 시 약간의 latency 가 존재할 수 있습니다.  
그리고 마지막으로 Read Replica 는 고유의 앤드포인트가 존재합니다.   
RDS DB는 앤드포인트로 정체를 가려낼 수 있습니다.

RDS 읽기 전용 복제본과 관련된 네트워킹 비용을 한번 살펴보겠습니다  
AWS에서는 하나의 가용 영역에서 다른 가용 영역으로  
데이터가 이동할 때에 비용이 발생합니다  
하지만 예외가 존재하며 이 예외는 보통 관리형 서비스에서 나타납니다  
RDS 읽기 전용 복제본은 관리형 서비스입니다  
읽기 전용 복제본이 다른 AZ 상이지만  
`동일한 리전 내에 있을 때는 비용이 발생하지 않습니다`

하지만 서로 다른 리전에 복제본이 존재하는 경우  
즉 us-east-1에 대해서  
복제본이 eu-west-1에 존재하는 경우에는  
RDS DB 인스턴스와 읽기 전용 복제본이  
`여러 리전을 넘나들어야 하기 때문에 네트워크에 대한 복제 비용이 발생합니다`

## 암호화

먼저, 사용하지 않는 데이터인 미사용 데이터 암호화는  
AES 256비트 암호화를 사용하는  
AWS의 키 매니지먼트 서비스인 AWS KMS로  
마스터 데이터베이스와 읽기 전용 복제본을 암호화할 수 있습니다  
따라서 암호화 실행 시 실행 시간을 정의해야 하며  
마스터 데이터베이스를 암호화하지 않으면  
복제본도 암호화할 수 없습니다

또, 늘 SSL 인증서가 필요한 전송 중 암호화도 있고  
이는 데이터 전송 중에 RDS로 암호화를 사용하는데  
클라이언트에서 데이터베이스로 전송 중인 것을 말합니다

모든 클라이언트가 SSL을 사용하도록 하려면

PostgreSQL 에서는  
rds.force_ssl=I인 콘솔 매개변수 그룹을 설정해야 하며 꽤 명시적입니다

MySQL 사용 시  
GRANT USAGE ON *.* TO 'mysqluser'@%'REQUIRE SSL이라는  
명령문을 데이터베이스 내부에서 실행해야 합니다  
이 또한 꽤 명시적이죠

RDS 백업을 암호화하는 방법입니다  
여기서 알아야 할 것은  
암호화 되지 않은 RDS 데이터베이스에서 스냅샷을 생성하면  
`스냅샷 자체는 암호화되지 않는 것`입니다  
마찬가지로 암호화된 RDS 데이터베이스에서 스냅샷을 생성하면  
모든 스냅샷이 기본으로 암호화되는데 이는 항상 기본 값은 아닙니다  
그래서 암호화되지 않은 스냅샷을  
암호화된 스냅샷으로 복제해야 합니다  
암호화되지 않은 RDS 데이터베이스의 스냅샷을 생성해 복제한 뒤  
이 스냅샷의 암호화된 버전을 쉽게 만들 수 있는 것이죠

다음은 암호화되지 않은 RDS 데이터베이스의 암호화 방법입니다  
지금까지 배운 것으로  
암호화 되지 않은 RDS 데이터베이스의  
스냅샷을 생성해야 하고 이는 암호화되지 않습니다
그리고 스냅샷을 복제하고  
`복제한 스냅샷의 암호화를 활성화`합니다  
이제 복제된 암호화 스냅샷이 생겼습니다  
이 암호화된 스냅샷으로  
암호화된 스냅샷에서 데이터베이스를 복원할 수 있으며  
이는 암호화된 RDS 데이터베이스를 제공합니다  
이제 모든 애플리케이션을 이전의 암호화되지 않은  
RDS 데이터베이스에서 새 암호화된 RDS 데이터베이스로 옮기고  
이전 데이터 베이스를 삭제합니다

정리하자면  
미사용 데이터 암호화는  
데이터베이스 인스턴스를 처음 생성할 때만 실행되며  
암호화되지 않았으면 스냅샷을 생성해야 합니다  
그리고 스냅샷을 복제해 암호화 한 다음에  
암호화된 스냅샷에서 새 데이터베이스를 생성하면  
데이터베이스를 암호화하죠

## 인증

이제 IAM 인증을 사용한 RDS 연결법을 살펴보겠습니다  
말씀드린 대로 `MySQL과 PostgreSQL에서만 실행`되며  
암호는 필요하지 않고  
`인증 토큰`이라는 것이 필요한데   
RDS API 호출을 사용해서 IAM으로 직접 얻을 수 있습니다

## Amazon 오로라(Aurora)

오로라는 AWS의 사유 기술입니다  
오픈 소스가 아니죠  
하지만 Postgres와 MySQL과 호환됩니다

오로라에서는 장애 조치도 즉각적입니다  
MySQL RDS의 다중 AZ에서 장애 조치보다 속도가 훨씬 빠르죠  
기본적으로 클라우드 네이티브라서 가용성이 높기 때문입니다  
RDS보다 비용이 20% 정도 비싸지만  
규모 면에서 더 효율적이어서  
비용을 많이 절약할 수 있습니다

오로라가 특별한 이유는 3개 AZ에 걸쳐 기록하는 것은 무엇이든  
6개의 데이터 복제본을 저장하기 때문입니다  
6개의 복제본을 저장할 수 있는데  
쓰기에는 6개 중 4개만 필요합니다  
이는 한 개의 AZ가 다운돼도 괜찮다는 것을 말하며  
읽기에는 6개 중 3개만 필요하다는 의미입니다  
읽기에 아주 적합한 것이죠  
또한, 정말 훌륭한 자가 복구 과정이 있는데  
일부 데이터가 손상되거나 잘못된 경우  
백엔드에서 P2P 복제로  
자가 복구를 하는 것입니다  
하나가 아니라 수백 개의 볼륨에  
의지할 수 있는 것입니다

또, 읽기 전용 복제본에 오토 스케일링을 적용할 수 있습니다  
그래서 `최대 15개의 읽기 전용 복제본에 일정 수의 읽기 전용 복제본을 `
오토 스케일링을 통해 설정할 수 있습니다  
오토 스케일링으로 애플리케이션이 읽기 전용 복제본과 URL을  
추적하는 것이 어려워지고 연결하기도 어려워집니다  
이를 해결하는 방법이 시험에 자주 출제됩니다

`리더 엔드 포인트(Reader Endpoint)`라는 것은  
라이터 엔드 포인트와 동일한 기능이 있는데  
로드 밸런싱의 연결을 돕고  
`모든 읽기 전용 복제본에 자동으로 연결`합니다  
클라이언트가 리더 엔드 포인트에 연결할 때마다  
읽기 전용 복제본 중 하나가 연결돼  
이런 식으로 로드 밸런싱 됩니다  
한 가지 알아야 할 것은 로드 밸런싱은  
명령문 수준이 아니라 연결의 수준에서 발생합니다

## Amazon 일래스틱 캐시

캐시란 무엇일까요? 캐시는 높은 성능과  
`낮은 지연 시간을 가진 인 메모리 데이터베이스`입니다  
그리고 일래스틱 캐시를 사용하면  
읽기 집약적인 워크로드의 부하를 줄이는데 도움이 됩니다

일반적인 데이터베이스(RDBMS)는 디스크(HDD,SSD)에 데이터를 영구적으로 저장해 놓고, 필요한 데이터만 메모리에 읽어서 사용합니다.  
인 메모리 캐시는 `디스크에 접근하지 않고 메모리로만 모든 처리를 하기 떄문에 데이터 저장 및 검색 속도가 매우 빠릅니다.`   
단 데이터는 딱 메모리 크기까지만 저장할 수 있습니다.  
또한, 메모리에만 저장되어 있기 때문에 `서버의 전원 공급이 중단되면 데이터는 소멸`됩니다.

일래스틱 캐시와 RDS 데이터베이스 그리고 애플리케이션이 있고  
애플리케이션은 일래스틱 캐시를 쿼리합니다  
쿼리가 이미 생성됐는지  
이미 생성되어 일래스틱 캐시에 저장됐는지 확인하는 것은  
`캐시 히트(cache hit)`고  
이는 일래스틱 캐시에서 바로 응답을 얻어서  
쿼리하기 위해 데이터베이스로 이동하는 동선을 줄여줍니다

`캐시 미스(cache miss)`의 경우에는 데이터베이스에서 데이터를 가져와서  
데이터베이스에서 읽습니다  
동일한 쿼리가 발생하는 다른 애플리케이션이나 인스턴스에서는  
데이터를 캐시에 다시 기록하여  
다음에는 `같은 쿼리로 캐시 히트를 얻도록 합니다`  
이는 RDS 데이터베이스에서 부하를 줄이는데 도움을 주는데  
데이터를 캐시에 저장하기 때문에  
캐시 무효화 전략이 있어야 하며  
가장 최근 데이터만 사용하는지 확인해야 합니다  
이것이 캐싱 기술 사용과 연관된 어려움이라고 할 수 있죠

`레디스(Redis)`는 자동 장애 조치로 다중 AZ를 수행하는 기술이며  
읽기 전용 복제본은 읽기 스케일링에 사용되며 가용성이 높습니다  
약간 RDS와 비슷합니다  
그리고 지속성으로 인해 데이터 내구성도 있으며  
백업과 기능 복원 기능도 있습니다  
RDS와 많이 유사합니다

`멤캐시트(Memcached)`는 `데이터 분할에 다중 노드를 사용하고 이를 샤딩(sharding)` 이라고 합니다    
가용성이 높지 않고 복제도 발생하지 않습니다   
`지속적인 캐시가 아닙니다`  
백업과 복원 기능도 없죠  
그리고 다중 스레드 아키텍처로  
몇몇 샤딩과 함께 캐시에서 함께 실행되는  
여러 인스턴스가 있습니다  
여기서 기억해야 할 것은
`레디스는 고가용성과 백업읽기 전용 복제본 등이 있고`

`멤캐시트는 데이터를 손실할 수 없는 단순한 분산 캐시`입니다  
`가용성이 높지 않고 백업과 복원 기능도 없습니다`  
바로 이것이 두 기술의 가장 큰 차이점입니다

### Memcached 를 선택

`상대적으로 작고 정적인 데이터를 캐싱`하는 경우  
여러 코어 또는 스레드가 있는 멀티 스레드의 경우  
메모리 관리가 redis 만큼 정교하지는 않지만, `메타 데이터에 대한 메모리 리소스를 비교적 적게 소비하여 간단한 사용에 적합`하다.  
쉽게 확장할 수 있지만 해싱 사용 여부에 따라 캐시된 데이터의 일부 또는 전부를 잃는다.

### Redis 를 선택

문자열, 해시, 목록, 세트, 정렬된 세트 및 비트맵과 같은 `복잡한 데이터 유형이 필요한 경우`  
인 메모리 데이터 세트를 정렬하거나 순위를 지정해야 하는 경우  
키 저장소의 속성을 원할 경우  
읽기 집약적 애플리케이션을 위해 기본 항목에서 하나 이상의 읽기 전용 복제본으로 데이터를 복제해야 하는 경우  
`기본 노드가 실패할 때 자동 장애 조치가 필요한 경우`  
서버에 대한 `이벤트를 클라이언트에 알리기 위해 게시 및 구독(게시/구독) 기능이 필요한 경우`   
`백업 및 복원 기능이 필요한 경우`  
`여러 데이터베이스를 지원`해야 하는 경우

## 일래스틱캐시 (ElastiCashe) 전략

어떤 캐싱 설계 패턴이 가장 적합한가? 입니다

### 레이지 로딩(Lazy Loading)

시험에서는 캐시 어사이드(Cache-Aside)나  
레이지 포퓰레이션(Lazy Population) 라고도 합니다  
모두 같은 것을 의미합니다

### 라이트 스루(Write Through)

라이트 스루는 `데이터베이스가 업데이트될 때 캐시를 추가하거나 업데이트하는 것을 의미`합니다    
살펴보죠 아까와 같이 애플리케이션, 일래스틱 캐시, RDS가 있습니다  
애플리케이션이 일래스틱 캐시와 통신할 때  
캐시 히트가 발생하면 좋죠  
그리고 RDS에서 쓰기를 할 때  
즉, 애플리케이션이 아마존 RDS 데이터베이스를 수정할 때  
먼저 캐시에 쓸 것입니다  
라이트 스루라고 부르는 이유는  
일래스틱 캐시를 통해 RDS에 쓰기 때문입니다  
이 구조에서 무엇을 얻을 수 있을까요?  
캐시 데이터는 절대 오래될 수 없습니다  
아마존 RDS가 바뀔 때마다  
캐시도 자동으로 바뀌게 됩니다

### 캐시 제거와 타임 투 리브(TTL)

즉, 캐시에 제한된 크기가 있습니다  
따라서 캐시 데이터를 제거하기 위해 Cache Eviction이란 방법을 사용합니다  
`예를 들어 항목을 캐시에서 명시적으로 삭제`하거나  
캐시 메모리가 꽉 찼을 때 사용합니다  
그러면 가장 최근에 사용되지 않은 항목이 제거됩니다  
이를 LRU 또는 최근 최소사용이라고 하거나  
항목을 타임 투 리브(TTL)로 설정할 수 있습니다  
예를 들어 이 항목은 5분 동안만 사용 가능하니  
5분이 되면 캐시에서 삭제될 것이라는 뜻입니다  
TTL은 리더보드, 코멘트, 활동 스트림 등등  
어떤 종류의 데이터에도 유용합니다

## Redis 클러스터 모드

레디스에서 할 수 있는 일래스틱 캐시 복제 방식은 2개이며 둘 다 알아야 합니다

### 클러스터 모드 비활성화입니다

샤드란  
샤드(shard)란 샤딩을 통해 나누어진 블록들의 구간(혹은 Epoch)을 말한다.   
샤드는 지분증명과 관련이 있는 것이 아니라 확장성 개선과 관련된 개념이다.   
샤딩(sharding)의 아이디어는 가능한 계정(계약도 계정)의 공간을 숫자 주소의 첫 번째 숫자를 기준으로 하위 공간으로 분할하는 것이다.   
샤드에 포함된 정보는 여전히 다른 노드와 공유할 수 있으며,   
모든 사람이 여전히 모든 원장 항목을 볼 수 있기 때문에 원장을 분산하고 안전하게 유지할 수 있다.   
그들은 단지 모든 정보를 처리하고 저장하지 않는다.

이 경우, 기본 노드는 1개이며  
`5개까지 노드를 복제`할 수 있습니다
레디스에는 샤드가 1개 있으며  
`모든 데이터가 이 샤드`에 있습니다  
기본 캐시 노드는 1개입니다  
선택적으로 `5개까지 캐시를 복제`할 수 있습니다  
즉, `노드의 복제본은 0개에서 5개`까지 가질 수 있습니다  
기본 노드와 복제본이 있을 때  
기본 노드에 실패가 발생하면  
복제본이 대신합니다  
`복제본은 캐시 간에 비동기적`이며  
기본 노드는 읽기와 쓰기에 사용됩니다  
다른 노드는 읽기 전용이죠  
장애 복구 외에도  
읽기 복제본을 활성화함으로써  
레디스용 일래스틱 캐시에서 읽기 성능을 올릴 수 있습니다  
즉, 샤드 1개가 있고  
모든 노드가 레디스 클러스에 있는 데이터를 갖게 될 것입니다  
이를 통해 노드 실패가 발생할 때 데이터의 손실을 대비합니다  
다중 AZ를 활성화할 수도 있습니다 다중 AZ 장애 조치를 위해  
기본값으로 활성화되어 있습니다  
다시 한번, 이것은 다중 AZ에 유용합니다  
또한 일래스틱 캐시 클러스터의  
읽기 성능을 올릴 때도 사용합니다

### 클러스터 모드 활성화

이 모드에서는 `데이터가 여러 샤드로 분할`되며  
`쓰기를 확장할 때 유용`합니다  
예시로 살펴보겠습니다 여기 샤드 1  
샤드 2, 샤드 3, 샤드 N이 있습니다  
기본 아이디어는 데이터의 일부분이  
샤드 1에,  
일부분은 샤드 2에, 이런 식으로 샤드 N까지 분할됩니다  
즉, 데이터는 모든 샤드에 걸쳐 분할됩니다  
각 샤드는 이전에 본 클러스터 모드 비활성화처럼  
똑같이 동작합니다  
즉, 기본 노드 1개가 있고  
노드의 복제본은 5개까지 있습니다  
데이터가 복제되고 모든 샤드에서  
복제본 수를 동일하게 설정합니다  
다중 AZ도 가능합니다 기본값으로 활성화되어 있습니다  
기본 노드와 복제본 사이에서  
장애가 발생했을 때 장애 조치가 가능합니다  
클러스터 당 최대 500개의 노드를 가질 수 있습니다  
즉 복제본을 만들지 않는다면  
단일 마스터에 500개의 샤드를 갖는다는 뜻입니다  
복제본을 설정하면  
예를 들어, 마스터 1개와 복제본 1개를 원한다면  
250개의 샤드를 갖습니다  
마스터 1개에 5개의 복제본을 원하면  
최대 83개의 샤드를 가질 수 있습니다  
클러스터 모드를 활성화하는 경우  
데이터 샤딩에 정말로 관심 있는 것입니다  
`즉, 쓰기를 확장하기 원하고 데이터는 분할될 것입니다`    
데이터가 여러 샤드에 걸쳐 분할되겠죠  
이것이 일래스틱 캐시에서 클러스터 모드 활성화와  
클러스터 모드 비활성화의 차이점입니다

# DNS

DNS은 `Domain Name System` 으로  
`사람에게 친숙한 호스트 이름을 대상 서버 IP 주소로 번역해` 줍니다  
예를 들어, 웹 브라우저에  
www.google.com을 입력하면  
IP 주소를 주고 웹 브라우저가 이면에서 여기에 접근하여  
구글로부터 데이터를 얻습니다

http://api.www.example.com.이 있습니다  
마지막 .을 루트라고 합니다  
전체 도메인 이름의 루트죠  
그리고 있는 .com 은 TLD 입니다  
바로 최상위 도메인입니다  
example.com 이 2단계 도메인이고  
www.example.com 이 서브 도메인입니다  
api.www.example.com 이 도메인 이름입니다
HTTP 부분은 사용하기를 원하는 프로토콜입니다  
전체를 `FQDN` 이라고 하는데  
전체 주소 도메인 이름의 약자입니다

## Route 53

고가용성, 확장성을 갖춘, 완전히 관리되며 권한있는 DNS입니다  
마지막으로 왜 Route 53이라고 할까요?    
53은 DNS 서비스, 즉, 이름에서 사용되는 `전통적인 DNS 포트`입니다

타임 투 리브(TTL) 은 DNS 리졸버(resolver)에서 레코드가 캐싱 되는 시간입니다  
Route 53 에서 지원하는 DNS 레코드 종류는 많은데 반드시 알아야 하는 것은 A, AAAA, CNAME, 그리고 NS

### A 레코드

호스트 이름과 `IPv4 IP를 매핑`하죠
예를 들어 example.com은 1.2.3.4로 바로 연결됩니다

### AAAA 레코드

AAAA은 A와 비슷한 아이디어입니다  
이번에는 호스트 이름을 `IPv6 주소에 매핑`합니다  

### CNAME 레코드

CNAME은 호스트 이름을 `다른 호스트 이름과 매핑`합니다  
물론 대상 호스트 이름은 A나 AAAA 레코드가 될 수 있죠  
Route 53에서 DNS 이름 공간 또는 Zone Apex의  
상위 노드에 대한 CNAMES를 생성할 수 없습니다  
예를 들어 example.com 에 CNAME 을 만들 수는 없지만  
www.example.com에 대한 CNAME 레코드는 만들 수 있습니다

### NS 레코드

NS 레코드는 네임 서버 레코드로 도메인에 대한 네임서버의 권한을 가지고 있는지 알려주는 레코드이다.  
쉽게 말해, 내가 example.kr 이라는 도메인을 aws 업체에서 구입해서 사용하고 있다고 하면,  
example.kr 도메인을 관리하는 네임 서버는 당연히 aws 의 ns2.aws.co.kr 가 되게 된다.  
즉 NS 레코드는 어떤 도메인에 대한 처리를 다른 도메인 네임 서버에게 위임하는 기능을 가진 레코드이다.  

### 호스팅 존

도메인과 서브도메인으로 가는 트래픽의 라우팅 방식을 정의합니다  
호스팅 존에 두 종류가 있는데  
퍼블릭 호스팅 존과 프라이빗 호스팅 존이 있습니다  

- Public Hosted Zones 
  - 특정 도메인(예: example.com)과 그 하위 도메인(acme.example.com, zenith.example.com)의 트래픽을 인터넷에서 라우팅하는 방식에 대한 정보를 담고 있는 컨테이너이다.
  - Route 53에 도메인을 등록하면 호스팅 영역이 자동으로 생성된다.
  - 기존 도메인에 대한 DNS 서비스를 Route 53로 전송하는 경우 도메인에 대한 호스팅 영역 생성부터 시작한다.
- Private Hosted Zones
  - Amazon VPC 서비스로 생성한 하나 이상의 VPC 내에 있는 도메인과 그 하위 도메인에 대하여 Amazon Route 53의 DNS 쿼리 응답 정보가 담긴 컨테이너이다.
  - 회사 내부에서만 접근할 수 있는 비공개 URL 이 필요로 할 때 사용한다.
  - 비공개 URL 이기 때문에 private DNS 레코드가 존재한다.

## 레코드 TTL(Time To Live)

예시에서 클라이언트가 DNS route 53와 웹 서버에 접속한다고 해봅시다  
myapp.example.com 에서 DNS 요청을 보내면  
DNS로부터 회신을 받는데요  
회신 내용으로는 A 레코드와 IP 주소  
그리고 TTL이 있으며 TTL은 300초 정도 된다고 합시다  
TTL은 클라이언트에게 이 결과를 캐시하도록 요청합니다  
300초의 TTL 동안 말이죠    
300초 동안 클라이언트는 결과를 캐시합니다  
이 말인즉슨, 
`클라이언트가 재요청을 보내거나 같은 호스트 이름으로 접속할 경우  
클라이언트는 DNS 시스템에게 쿼리를 보내지 않아도 된다는 의미죠`  
이미 답변을 캐시에 저장했기 때문에 답을 알고 있으니까요  
하지만 캐시에도 시간이 소요되니 캐시 TTL이 발생합니다  
DNS 요청 쿼리를 계속해서 자주 보내는 상황을 원치 않는 겁니다  
레코드는 그렇게 자주 바뀌지 않거든요  
이미 저장된 답변을 이용함으로써  
웹 서버에 접속이 가능하며 HTTP 요청 및 회신을 보낼 수 있겠죠  
두 가지의 극단적인 경우를 봅시다  
예를 들어 TTL을 24시간으로 높게 설정한다면  
Route 53의 트래픽은 현저히 적겠죠  
결과가 24시간 동안 캐시될 테니  
클라이언트는 요청을 적게 보낼 겁니다  
하지만 클라이언트가 오래된 레코드를 받을 가능성도 있죠  
따라서 만약 레코드를 바꾸고자 한다면  
모든 클라이언트들이 새 레코드를 캐시에 저장할 때까지  
24시간을 기다려야 한다는 뜻입니다  
반대로 TTL을 60초 정도로 짧게 설정한다면  
DNS에는 트래픽의 양이 많아져서  
비용이 많이 들게 됩니다  
Route 53에 들어오는 요청의 양에 따라 요금이 책정되거든요
하지만 오래된 레코드의 보관 시간은 짧아지겠죠  
따라서 레코드 변경이 빨라집니다  
레코드 변경 전반이 더욱 편리하죠  
어떤 TTL 설정이 더 적합할지는 상황에 따라 달라집니다  
레코드를 변경하려는 경우
예를 들어 TTL을 24시간으로 늦춘 다음  
모든 클라이언트가 느린 새 TTL을 가지고 있다는 점을   
확인한 후, 레코드 값을 바꿔서 모두에게 업데이트가 되면 TTL을 올리는 식이죠  
그런 전략을 사용합니다  
TTL은 모든 레코드에 있어 필수적인데요  
다음 강의에서 다룰 별칭 레코드는 제외됩니다

## CNAME 과 별칭의 차이

CNAME 은 `호스트 이름이 다른 호스트 이름으로 향하도록` 할 수 있습니다  
예를 들어 app.mydomain.com이   
blabla.anything.com으로 향하는 식이죠  
`이건 루트 도메인 이름이 아닌 경우에만 가능`해서  
mydomain.com 앞에 뭔가 붙어야 하죠

반면 별칭 레코드도 있습니다  
이건 Route 53에 한정되지만  
`호스트 이름이 특정 AWS 리소스로 향하도록` 할 수 있습니다
가령 app.mydomain.com이  
blabla.amazonaws.com를 향할 수 있는 거죠  
`별칭 레코드는 루트 및 비루트 도메인 모두에 작동`합니다  
mydomain.com을 별칭으로 사용해  
AWS 리소스로 향하도록 할 수 있기 때문에, 아주 유용하죠  
그 외에도 `별칭의 장점으로는 무료`이고    
자체적으로 상태 확인이 가능하다는 점이 있습니다

AWS 리소스를 위한 `별칭 레코드의 타입은 항상 A 또는 AAAA` 인데  
리소스는 IPv4나 IPv6 중 하나죠  
`별칭 레코드를 사용하면 TTL을 설정할 수 없습니다`  
Route 53에 의해 `자동으로 설정`이 되죠

일라스틱 로드 밸런서(Elastic Load Balancer)가 될 수도 있고  
CloudFront 배포도 가능해요  
ELB 와 CloudFront 배포 API Gateway  
일래스틱 빈스톡 환경, S3 웹사이트도 가능하고요  
`S3 버킷은 안 되고` 
버킷들이 웹사이트로 활성화될 시 S3 웹사이트는 가능하죠  
VPC 인터페이스 엔드포인트 Global Accelerator 가속기  
동일 호스트 존의 Route 53이 대상으로 가능합니다  

`EC2의 DNS 이름에 대해서는 별칭 레코드를 설정할 수 없습니다`

## 라우팅 정책

라우팅 정책은 Route 53가 DNS 쿼리에 응답하는 것을 돕습니다  
여기서 라우팅이라는 단어를 혼동하셔서는 안 됩니다  
로드 밸런서가 트래픽을  
백엔드 EC2 인스턴스로 라우팅하는 것과는 다른 상황이죠  
여기서의 라우팅은 DNS 관점입니다  
`DNS는 트래픽을 라우팅하지 않죠` 
트래픽은 DNS를 통과하지 않아요  
DNS는 DNS 쿼리에만 응답하게 되고  
클라이언트들은 이를 통해 HTTP 쿼리 등을  
어떻게 처리해야 하는지를 알 수 있게 되는 거죠  
`DNS는 호스트 이름들을 클라이언트가 실제 사용 가능한 엔드 포인트로 변환하는 것을 돕죠`

### 단순 라우팅 정책

`일반적으로 트래픽을 단일 리소스로 보내는 방식`입니다  
예를 들어 클라이언트가  
foo.example.com 으로 가고자 한다고 하면  
Route 53이 IP 주소를 알려주는 거죠  
이는 A 레코드 주소입니다  
동일한 레코드에 여러 개의 값을 지정하는 것도 가능한데요  
이렇게 `DNS에 의해 다중 값의 받은 경우에는 클라이언트 쪽에서 그 중 하나를 무작위`로 고르게 됩니다  
이 예시의 경우에는 클라이언트가 foo.example.com로   
가기를 요청하고, Route 53은 세 개의 IP 주소로 답합니다  
A 레코드에 임베딩된 주소들이죠

### 가중치 기반 라우팅 정책

EC2 인스턴스가 세 개 있는데  
70, 20, 그리고 10의 각각 다른 가중치를 할당받아  
이 예시에서는 가중치의 합이 100이 되는데  
실제로는 이럴 필요는 없습니다  
Amazon Route 53에서 오는 DNS 응답의 70%가  
첫 번째 EC2 인스턴스로 리다이렉팅된다는 의미죠  
20퍼센트는 두 번째로 10퍼센트는 세 번째 인스턴스로 갑니다  

가중치 기반 정책이 사용되는 경우는 제법 명확한데요  
`서로 다른 지역들에 걸쳐 로드 밸런싱을 할 때나 적은 양의 트래픽을 보내 새 애플리케이션을 테스트하는 경우`에도 사용합니다

### 지연 시간 기반 라우팅 정책

지연 시간이 가장 짧은, 즉  
`가장 가까운 리소스로 리다이렉팅을 하는 정책`입니다  
지연 시간에 민감한 웹사이트나 애플리케이션이  
있는 경우에 아주 유용한 정책이죠

### 상태 확인 정책

만약 한 지역이 사용 불가능 상태가 되면  
당연히 그곳으로는 유저를 보내고 싶지 않겠죠  
그러기 위해선 Route 53에서 상태 확인을 생성해야 합니다
이 상태 확인들은 각자의 메트릭을 사용하는데  
CloudWatch의 지표에서도 확인이 가능합니다  

간격도 설정 가능한데 두 개의 선택지가 있죠  
`30초마다 정기적으로 확인할 수도 있고  
비용이 더 들지만 10초마다 할 수도 있죠`  
빠른 상태 확인이라고 불립니다  
HTTP, HTTPS와 TCP 등 많은 프로토콜을 지원합니다  

위치도 선택할 수 있습니다  
상태 확인은 로드 밸런서로부터  
`2xx나 3xx의 코드를 받아야만 통과`가 됩니다  
텍스트 기반 응답일 경우  
상태 확인은 응답의 처음 5,120바이트를 확인합니다  
`응답 자체에 해당 텍스트가 있는지 보기` 위해서죠  

`여러 개의 상태 확인 결과를 하나로 합쳐주는 기능`입니다  
Route 53을 보면 EC2 인스턴스가 세 개 있고  
상태 확인을 세 개 생성할 수 있죠  
이들은 EC2 인스턴스를  
하나씩 확인해 주는 하위 상태 확인이 될 겁니다  
이제 이 하위 상태 확인을 바탕으로  
상위 상태 확인을 정의할 수 있습니다  
이 상태 확인들을 모두 합치기 위한 조건은   
OR와 AND 또는 NOT입니다  
하위 상태 확인을 256개까지 모니터링할 수 있고  
상위 상태 확인이 통과하기 위해 몇 개의  
상태 확인을 통과해야 하는지도 지정할 수 있죠  

### 장애 조치 정책

장애 조치 라우팅 정책은 첫 번째, 두 번째 리소스를 정해두고 첫 번째 리소스가 비정상일 경우 두 번째 리소스로 라우팅합니다.   
로드밸런싱 용도로 사용하기에는 어려움이 있습니다.   
첫 번째 리소스가 비정상인 경우에만 두 번째 리소스로 라우팅을 하기 때문입니다.   
레코드를 정의할 때 특이한 점은,   
Failover record type을 'Primary'로 지정할 때 Health check 부분은 정상여부를 확인하기 위해 필수로 기입해야 한다는 점입니다.

하나는 기본 EC2 인스턴스이고  
두 번째는 보조 EC2 인스턴스 혹은 재해 복구 EC2 인스턴스입니다

상태 확인이 비정상이면  
자동으로 Route 53은 2번째의 EC2 인스턴스로 장애 조치하며 결과를 보내기 시작합니다

클라이언트의 DNS 요청은  
정상으로 생각되는 리소스를 자동으로 얻습니다  
기본 인스턴스가 정상이면 Route 53도 기본 레코드로 응답합니다  
하지만 상태 확인이 비정상이면 장애 조치에 도움이 되는  
두 번째 레코드의 응답을 자동으로 얻게 됩니다

### 지리 위치(Geolocation) 라우팅 정책

지연 시간 기반의 정책과는 매우 다르게
사용자의 `실제 위치를 기반`으로 합니다  
예를 들어 사용자가  
특정 대륙이나 국가 혹은 더 정확하게  
미국의 경우에는 어떤 주에 있는지 지정하는 것이며  
`가장 정확한 위치가 선택`되어  
그 IP로 라우팅 되는 것입니다  
일치하는 위치가 없는 경우는  
기본 레코드를 생성해야 합니다  
사용 사례로는 콘텐츠 분산을 제한하고  
로드 밸런싱 등을 실행하는 웹사이트 현지화가 있습니다  
이런 레코드는 상태 확인과 연결할 수 있습니다  

## 지리 근접 라우팅

이는 사용자와 `리소스의 지리적 위치를 기반`으로  
트래픽을 리소스로 라우팅하도록 합니다  
이 정책으로 편향값을 사용해 특정 위치를 기반으로  
리소스를 더 많은 트래픽을 이동하는 것입니다  

리소스는 AWS의 리소스로  
속한 특정 리전을 지정하면  
목록에서 자동으로 올바른 라우팅을 계산하거나  
AWS 리소스가 아닌 온프레미스 데이터 센터인 경우  
위도와 경도를 지정해서  
AWS가 위치를 파악하도록 해야 합니다

### 트래픽 플로우

트래픽 플로우라는 기능으로  
복잡한 지리 근접 레코드를 설계하는 방법에 관해  
살펴보겠습니다  
이는 지리 근접성뿐만 아니라 모든 것에 적용됩니다  
UI라는 비주얼 에디터로  
복잡한 라우팅 의사 결정 트리를 관리하는 것입니다  
이것이 바로 UI이고 다른 규칙을 지정해 여러 가지를  
시도가능하다.

## 다중 응답 라우팅 정책 (Multivalue answer)

다중 응답 라우팅 정책은 요청에 대해 여러 리소스 값을 반환할 수 있습니다. 
로드밸런서 역할을 할 수 있지만 몇 가지 제약사항이 있습니다.(해당 정책으로만 로드밸런싱을 구현하는건 추천드리지 않는 방법입니다.)
Record type을 지정할 때 CNAME, NS 를 지원하지 않으며 리소스 값으로 alb 등의 값을 줄 수 없고 오로지 'IP address or another value' 로만 지정이 가능합니다.

# VPC

Virtual Private Cloud(VPC) 사설 네트워크를 의미합니다.

논리적인 구조인 VPC 내부에는  
서브넷이 있고 이것이 VPC 안에 있는 네트워크를 분할하게 해줍니다  
서브넷은 가용 영역 수준에서 정의됩니다  
즉 1개의 AZ가 있습니다 예시에 AZ A가 있죠  
서브넷은 여러 개가 될 수 있는데  
첫 번째 서브넷은 공용 서브넷입니다  
보이는 것처럼 공용 서브넷은  
인터넷으로부터 접근됩니다  
즉, 서브넷은 월드 와이드 웹(www)에 접근할 수 있고  
월드 와이드 웹으로부터 접근될 수 있죠  
또 다른 서브넷은  
사설 서브넷이라고 합니다 사설 서브넷은  
인터넷에서 접근할 수 없습니다  

인터넷으로의 접근과 서브넷 사이의 접근을 정의하기 위해  
라우팅 테이블을 사용할 것입니다  
VPC 내에서 여러 라우팅 테이블을 정의하여  
다른 서브넷 사이에서 네트워크가  
어떻게 흐를지 정의합니다

큰 범위의 VPC 다이어그램을 살펴보면  
클라우드 인프라가 있고  
리전이 하나 있습니다 리전 안에 VPC가 있죠  
VPC는 IP 범위를 갖고 있습니다  
이를 CIDR 범위라고 합니다 VPC에서 허용하는 IP 범위입니다

공용 서브넷에 EC2 인스턴스가 있다고 했는데요  
무엇이 서브넷을 공개적으로 만드는 걸까요?  
어떻게 인터넷에 접근할까요?  
이를 위해 `인터넷 게이트웨이`를 사용합니다  
인터넷 게이트웨이가 서브넷에 있는 VPC 인스턴스가  
인터넷에 연결되도록 지원합니다  
여기 인터넷 게이트웨이가 있고 VPC에 있습니다  
공용 서브넷은 인터넷 게이트웨이로 라우팅 되고  
예를 들어 공용 서브넷에 있는 EC2 인스턴스는  
인터넷 게이트웨이로 라우팅 됩니다  
인터넷 게이트웨이가 인터넷과 통신하는 법을 알고 있어서  
공용 서브넷을 공개적으로 만들어줍니다  
즉, 공용 서브넷은 인터넷 게이트웨이로 직접 라우팅 됩니다  
다른 예시를 살펴보겠습니다  
사설 서브넷에 EC2 인스턴스가 있고  
이것도 인터넷에 접근하게 만들고 싶습니다

## 네트워크 ACL의 개념과 보안 그룹

NACL 또는 네트워크 ACL을 만들 수 있는데  
이것은 서브넷에서 들어오고  
나가는 트래픽을 제어하는 방화벽입니다  
어떤 규칙을 허용하거나 거부할 수 있죠  
즉, 트래픽을 허용하거나 거부할 수 있습니다  
NACL을 서브넷 수준에서 만들고  
규칙은 오직 IP 주소를 포함합니다  
즉, 이 IP 주소에서 오는 모든 트래픽을 허용하거나  
이 IP 주소에서 오는 모든 트래픽을  
거부하는 등이 될 수 있습니다

다른 강의에서 보안 그룹을 자세히 다뤄봤지만  
NACL을 다루지는 않았습니다 왜일까요?  
기본 VPC에서  
기본 NACL은 들어오고 나가는  
모든 것을 허용하기 때문입니다  

## VPC 플로우 로그

서브넷 플로우 로그, ENI 플로우 로그,  
일래스틱 네트워크 인터페이스, 플로우 로그가 있습니다  
즉, 네트워크가 VPC를 통과할 때마다  
플로우 로그에 기록될 것입니다  
연결 문제를 모니터링하고 해결할 때 도움 됩니다  
예를 들어 여러분의 서브넷이  
왜 인터넷에 접근할 수 없는지 또는 왜 서브넷이 다른 서브넷과  
또는 인터넷에서 서브넷에  
왜 통신하거나 통신하지 못하는지 등을 알 수 있습니다  
네트워크에 문제가 있을 때  
이를 해결하기 위해  
VPC 플로우 로그를 살펴봐야 합니다  
여기에 허용되고 거부된 트래픽 관련  
모든 정보가 있기 때문입니다  
네트워크 정보가 캡처될 뿐만 아니라  
AWS에 의해 관리되는 모든 것이 있습니다  
즉, 일래스틱 로드 밸런서, 일래스틱 캐시, RDS, 오로라가  
VPC 플로우 로그에 나타날 것입니다 따라서 연결 문제가 있을 때  
여기를 바로 살펴보면 됩니다  
VPC 플로우 로그 데이터는 S3나  
CloudWatch 로그에 보내서 저장할 수 있죠  
이렇게 AWS 환경에 저장할 수 있습니다

## VPC 피어링

2개의 가상 사설 클라우드가 있고  
이들은 2개의 다른 계정이나 2개의 다른 지역에 있습니다  
이들을 `같은 네트워크에 있는 것처럼 만들기 위해 연결`하고자 합니다  
즉, AWS의 V 네트워크를 이용하여  
VPC를 비공개로 연결하고자 합니다  
이것은 그들이 같은 네트워크에 있는 것처럼 행동하게 만들어 줍니다  
VPC A와 VPC B가 있고  
이 둘이 서로 통신하게 하기 위해  
`A로부터 B로의 VPC 피어링 연결을 설정`해야 합니다  
VPC 연결을 확실하게 하기 위해  
각 VPC에 정의된 IP 범위가  
겹치지 않는지 확인해야 합니다  
다른 VPC에 네트워크를 지정하려면  
IP 주소를 사용하여 통신해야 하는데  
만약 네트워크 범위가 겹치면  
네트워크는 어디로 가야 할지 모릅니다  
따라서 VPC를 연결하기 위해 VPC가 작동하는  
IP 주소 범위가 다르고 겹치지 않는지 확인해야 합니다  
VPC 피어링은 전이되지 않기 때문에  
서로 통신해야 하는 VPC마다 설정해야 합니다  
즉, VPC C를  
VPC 피어링을 통해 A와 C를 연결하려면  
B와 C는 서로 통신할 수 없습니다  
VPC 피어링이 전이되지 않기 때문이죠  
즉, VPC B와 VPC C 사이에서  
통신하기 원한다면  
B와 C 사이에 VPC 피어링 연결을 해야 합니다  
이 말은 VPC 피어링이 많아질수록, 즉, 더 많은 VPC를 추가할수록  
더 많은 피어링 연결 추가가 필요하다는 것입니다  

엔드 포인트는 사설 네트워크를 이용하여 AWS 서비스를 연결하게 해줍니다  
공용 인터넷 네트워크를 이용하는 대신에 말이죠  
여러분이 모를 수 있는 것은  
모든 AWS 서비스는 공개라는 점입니다  
즉, EC2 인스턴스가  
AWS 서비스를 사용할 때마다 공개적으로 AWS와 소통합니다  
때때로 EC2 인스턴스는 공용 서브넷에 연결되지 않을 수 있는데  
이때는 AWS 서비스에 비공개로 접근하기 원합니다  
이때 VPC 엔드 포인트를 사용합니다  
이를 통해 AWS 서비스에 접근할 때  
보안 수준을 향상하고 지연 시간을 단축합니다  
예시를 살펴보면, 사설 서브넷과 그 안에 EC2 인스턴스가 있습니다  
이제 Amazon S3와 DynamoDB에 접근하고자 합니다  
VPC를 벗어나 공용 영역으로 들어가고자 하는 것입니다  
이때 VPC 엔드 포인트 게이트웨이를 생성합니다  
이것은 오직 S3와 DynamoDB를 위한 것입니다

`EC2 인스턴스가 VPC 엔드 포인트에 통신`하고  
`S3와 DynamoDB에 비공개로 접근`합니다  
보이는 것처럼 트래픽은 인터넷을 통하지 않습니다    
VPC 엔드 포인트 인터페이스는  
서비스의 나머지 부분으로 여러분의 VPC에서만 사용됩니다

온프레미스 데이터 센터 사이의 연결을 어떻게 설정할까요?  
사무실 건물일 수도 있고 클라우드 VPC일 수도 있습니다  
첫 번째 방법은 `Site-to-Site VPN` 으로  
`온프레미스 VPN 장치를 AWS 에 연결`합니다  
연결은 `자동으로 암호화되어 인터넷에 공개 연결`됩니다  
예시에서는 온프레미스 데이터 센터와  
VPC 사이의  
`가상 사설 네트워크 (VPN)로 인터넷`에 공개됩니다  
`설정하기 쉽고 빠릅니다 몇 분 안에 설정할 수 있죠`  
`비공개 연결이 아니죠, 암호화하여 공개 인터넷을 통해 VPC에 연결`됩니다

같은 목적으로 사용 가능한 것으로 `Direct Connect(DX)`가 있습니다  
온프레미스 데이터 센터와 VPC를 연결하기 위해 사용되는데    
이 경우에는 `물리적으로 연결`됩니다  
즉, `비공개 연결`이기 때문에  
`공개된 인터넷을 통하지 않을 것이며 안전하고 빠릅니다`  
`사설 네트워크`를 통하죠  
그리고 `VPC 와의 비공개 회선이기 때문에 설정하는 데 적어도 한 달이 걸리죠`  
AWS와 비공개 연결을 위해서  
할 일이 있기 때문입니다  
이름이 Direct Connect 인 이유는 비공개 라우팅이기 때문입니다  
VPN과 Direct Connect는  
같은 목적을 달성하지만, 방법이 다르고 타임라인이 다릅니다  

만약 Site-to-Site VPN을 사용하거나  
Direct Connect를 사용한다면  
이전에 이야기한 VPC 엔드 포인트에 접근할 수 없다는 것을 알아두세요   
VPC 엔드 포인트는 VPC에 있는 AWS 서비스로  
비공개로 접근하게 하지 온프레미스 데이터 센터로  
접근하게 하는 것이 아닙니다

## NAT 게이트웨이

IPv4를 사용하여 프라이빗 서브넷의 EC2 인스턴스에 대한 인터넷 액세스를 제공하는 동시에 이 솔루션에 최소한의 관리가 필요하고 원활하게 확장되도록 하고 싶습니다.

# S3

`S3은 객체를 저장하게 해주는 시스템이자 서비스`입니다  
즉, 파일이 버킷 또는 디렉터리에 있고  
각 버킷은 전역적으로 고유한 이름을 갖습니다  

S3은 전역 서비스이지만  
`버킷은 리전 리소스`입니다  
명명 규칙으로는 `대문자나 소문자를 포함하지 말 것`,  
`밑줄을 사용하지 말 것 길이는 3에서 63자일 것`,  
`IP 주소가 아닐 것 소문자 또는 숫자`로 시작할 것이 있습니다  

`버킷 내에는 디렉터리 개념 없이 키 이름만 아주 깁니다`  
UI는 여러분이 디렉터리를 생각하도록 만들 것이지만요  
왜냐하면 S3 내에서  
디렉터리를 생성할 수 있기 때문입니다  
S3에서 가질 수 있는 것은  
'/'를 가진 매우 긴 이름의 키뿐입니다  

Amazon S3에서 `객체의 최대 크기는 5TB, 5,000GB` 로 매우 큽니다

그러나 한 번에 5GB 이상 업로드할 수 없습니다  
즉, 5TB의 큰 객체를 업로드하기 원한다면  
객체를 5GB 미만으로 나누어서  
각각 업로드해야 합니다  
이것을 멀티파트 업로드라고 합니다  

## 버전 관리

즉, 같은 키로 파일 버전을 다시 업로드하는 경우에  
기존 파일을 덮어쓰게 되는데 사실은 덮어쓰는 게 아니라  
해당 파일의 새로운 버전을 생성하는 겁니다  
`따라서 기존의 파일을 덮어쓰는 것이 아니라 새로운 파일 버전을 생성하는 거죠`   
여기서는 간단하게 표현해서  
버전 1, 2, 3 등이 되겠습니다  
Amazon S3에서 버킷을 버저닝하여  
모든 파일 버전을 어느 정도 유지하는 것이  
가장 좋은 방법이라고 할 수 있는데요  
원치 않은 삭제로부터 보호받을 수 있기 때문입니다  
이전 버전을 복원할 수 있거든요  
또한 필요한 이전 버전으로 손쉽게 되돌릴 수도 있습니다

## 객체 암호화

Amazon S3에 객체를 업로드할 경우  
이들은 AWS 내의 서버가 되므로  
`객체로 접근이 불가능하게끔` 
보호하려 할 겁니다  
예를 들어 누군가가 Amazon 서버에 들어올 때  
혹은 회사에서 설정한 보안 기준을  
확실히 준수하려는 경우 등이 있겠죠  

### SSE-S3

`AWS 가 처리 및 관리하는 키`를 사용해 S3 객체를 암호화하는 방법이죠

객체는 `서버 측에서 암호화`됩니다  
SSE가 서버 측 암호화를 뜻하죠  
그리고 암호화 유형은 `AES-256 알고리즘`입니다  
따라서 이렇게 객체를 업로드하고  
SSE S3 암호화를 설정하려면  
`"x-amz-server-side-encryption":"AE256"`로  
헤더를 설정합니다 x-amz는 x Amazon이며  
x Amazon 서버 측 암호화 AES-256, 이런 식으로  
헤더 이름을 기억할 수 있겠죠

Amazon S3로 해당 객체를 업로드해서  
SSE-S3 암호화를 하려 합니다  
그러면 우선 Amazon S3에 객체를 업로드합니다  
HTTP 혹은 HTTPS 프로토콜을 사용할 수 있습니다  
그리고 방금 언급했던 헤더를 추가합니다  
"x-amz-server-side- encryption":"AES256"  
그러면 Amazon S3는 이 헤더를 통해 고유의 S3 관리 데이터 키를  
사용해야 한다는 사실을 인식하고 S3 관리 데이터 키와 객체를 사용해서  
암호화가 이루어집니다 그 후 객체는 암호화되어  
Amazon S3 버킷에 저장이 되죠  
아주 간단합니다 하지만 이 인스턴스에서는  
`Amazon S3에서 데이터 키를 전부 소유 및 관리`하고 있는 거죠 

### SSE-KMS

`AWS 키 관리 서비스를 사용`해서 암호화 키를 관리하는 방법입니다

`누가 어떤 키에 접근할 수 있을지 제어 가능`하고 또한 `감사 추적`을 할 수 있기 때문입니다  
이를 위해서는 헤더를 설정할 때  
`x Amazon 서버 측 암호화 값을 "aws:kms"로 지정`해야 합니다  
역시 서버 측 암호화이므로 원리는 이전과 동일합니다

객체가 있고, HTTPS와 헤더를 사용해 업로드가 되어 있죠  
그리고 이 헤더를 통해서  
Amazon S3은 미리 정의해 둔  
KMS 고객 마스터 키를 사용하게 됩니다  
고객 마스터 키를 사용하면  
즉 지정된 키와 객체를 사용하면  
암호화가 이루어지고 파일은 SSE-KMS 암호화 방식 하에  
S3 버킷에 저장됩니다

### SSE-C

`사용자가 만든 암호화 키`를 관리할 때 쓰이는 방식이죠

서버 측 암호화 방식을 뜻하며  
AWS 가 `외부에서 고객이 관리하는 키를 사용`하죠  
이런 경우에 Amazon S3은  
`고객이 제공한 암호화 키를 저장하지 않습니다`  
암호화를 위해서는 당연히 키를 사용하겠지만  
그 후에는 키를 폐기합니다  
그리고 데이터를 AWS로 전송할 때에는  
`HTTPS를 사용`해야 합니다 AWS로 암호를 전달할 테니  
전송되는 동안 암호화가 반드시 필요하겠죠  
암호화 키가 HTTP의 헤더에 제공되어야 하는데, 모든 HTTP  
요청마다 매번 제공되어야 합니다 항상 사용 후 폐기되기 때문이죠

만약 SSE-C를 통해 Amazon S3으로부터 파일을  
다시 받으려면 사용된 것과 동일한  
클라이언트 측 데이터 키를 제공해야만 합니다  
그러니 `클라이언트 측에서 관리할 것이 더 많겠죠`  
클라이언트가 데이터 키를 관리하는데 Amazon 측인 AWS는  
사용자가 어떤 데이터 키를 사용했는지를 알 수 없기 때문입니다  
우리가 해야 할 일이 좀 더 많죠

### 클라이언트 측 암호화

이 방법은 Amazon S3에 객체를 업로드하기 전  
클라이언트, 즉 `여러분이 객체를 암호화`하는 겁니다  
클라이언트 라이브러리를 사용할 수 있는데  
`Amazon S3 Encryption Client`  
등으로 클라이언트 측 암호화를 수행할 수 있습니다  
클라이언트는 데이터를 `S3로 보내기 전에 암호화`해야 합니다  
만약 전달받은 데이터가  
클라이언트 측 암호화, 즉 CSE를 사용해 암호화되었다면  
데이터를 해독할 책임도  
전적으로 사용자에 달려있습니다  
따라서 올바른 키가 준비되어 있어야겠죠  
즉 클라이언트 측 암호화에서는  
키와 암호화 주기 전체를  
클라이언트가 전부 관리하게 됩니다

## 보안

### 사용자 기반 보안

IAM 사용자는 IAM 정책을 가지고 있는데  
이들의 `정책은 어떤 API 호출이 허용될지를 결정`합니다  
만약 유저가 IAM 정책을 통해 Amazon S3 버킷으로의  
액세스 방법을 승인받게 되면 실행이 가능해집니다  

### 리소스 기반 보안

S3 콘솔에서 설정 가능한 버킷 전반의 규칙이며  
S3 버킷에서 보안 주체가 무엇을 할 수 있는지  
혹은 할 수 없는지를 결정하는 정책이죠  
그리고 이를 통해 S3 버킷으로의 교차 계정 액세스가 활성화됩니다  

사용자가 IAM을 통해 S3 버킷에 액세스할 수 있다 해도  
`버킷 정책이 사용자 액세스를 명시적으로 거부한다면 액세스가 불가능합니다`

### S3 버킷 정책

이는 JSON 기반 정책인데요  
JSON 버킷 정책이 있습니다 이 버킷 정책을 사용하면  
S3 버킷 상에서 퍼블릭 읽기가 허가됩니다  

~~~
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicRead",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": ["arn:aws:s3:::mybuckey/*"]
        }
    ]
}
~~~

"Effect"는 "Allow" "Principal"의 "*"은 누구나  
"Action"은 "s3:GetObject"  
"Resource"는 examplebucket/*  
즉 S3 버킷의 어떤 객체도 가능하다는 의미죠  
좋습니다, 이를 통해 S3 버킷에 퍼블릭 액세스가 가능해지죠  
이러한 버킷 정책은 사용자의 버킷이나 객체  
둘 다에 적용할 수 있습니다  
Action은 API가 허가 및 거부를 하도록 설정하고  
Effect는 허용이나 거부 Principal은 해당 S3 버킷의  
정책을 적용할 계정 혹은 유저입니다  
흔히 S3 버킷 정책을 사용하는 경우의 예로는  
버킷에 퍼블릭 액세스 권한을 승인하거나  
업로드 시점에 객체를 암호화시킬 경우, 혹은  
교차 계정 S3 버킷 정책을 사용해서  
다른 계정에 액세스 권한을 주는 경우 등이 있습니다  

그리고 블록 퍼블릭 액세스 버킷 설정이 있죠  
`객체가 퍼블릭화 되는 것을 차단하는 새로운 설정`이었죠
계정에 제한이 있을 경우에 사용됩니다

네트워킹에서는 VPC 엔드 포인트로 S3에 비공개 액세스가 가능합니다  
즉 VPC에 EC2 인스턴스가 있고 인터넷 액세스는 없는 경우  
VPC 엔드 포인트를 통해 비공개로 S3에 액세스할 수 있는 거죠  
로깅 및 감사에서는 S3 액세스 로그를 사용하면  
다른 S3 버킷에 해당 로그가 저장됩니다  
API 호출은 CloudTrail, 계정에  
API 호출을 로깅할 수 있는 서비스에도 로깅이 가능합니다

사용자 보안에는 MFA 삭제라는 것이 있는데  
멀티 팩터 인증을 뜻하죠  
`특정 버전 객체를 버킷에서 삭제하고 싶은 경우에 MFA 삭제를 활성화`하면 됩니다  
그러면 `MFA로 인증이 되어야만 객체를 삭제`할 수 있습니다

### 사전 서명된 URL

AWS의 자격 증명으로 서명된 URL입니다  
`한정된 시간 동안만 유효`하고요  
사용 예시를 보면, 유저가 로그인한 서비스로부터  
프리미엄 영상을 구매하여 다운로드하는 경우 등입니다  
그러므로 만약 시험에서 제한된 시간 내에  
특정 사용자가 특정 파일에 액세스하는 경우에 관련된 문제가 나오면  
사전 서명된 URL을 생각하시면 됩니다  

버킷 정책 생성 참고 사이트

~~~
{
    "Version": "2012-10-17",
    "Id": "bukit",
    "Statement": [
        {
            "Sid": "Statement1",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::버킷이름/*",
            "Condition": {
                "Null": {
                    "s3:x-amz-server-side-encryption": "true"
                }
            }
        },
        {
            "Sid": "Statement2",
            "Effect": "Deny",
            "Principal": "*",
            "Action": "s3:PutObject",
            "Resource": "arn:aws:s3:::버킷이름/*",
            "Condition": {
                "StringNotEquals": {
                    "s3:x-amz-server-side-encryption": "AES256"
                }
            }
        }
    ]
}
~~~

https://aws.amazon.com/ko/blogs/security/how-to-prevent-uploads-of-unencrypted-objects-to-amazon-s3/

## 정적 웹사이트

`www 에서 접근이 가능하도록 허용`하며 웹사이트 URL도 아주 간단합니다  
HTTP 엔드 포인트로 이와 같은 모습이거나  
여러분이 속한 리전에 따라 다음과 같은 모습일 수 있습니다  
버킷 이름으로 먼저 시작해서  
.s3-website.AWS-리전  
.amazonaws.com으로 끝납니다  

## CORS 교차 오리진 리소스 공유

오리진(Origin)이란 뭘까요? 오리진은 체계, 즉 프로토콜이자  
호스트, 도메인, 그리고 포트입니다  
쉽게 설명하면  
가령 https://www.example.com는  
체계가 HTTP  
호스트가 www.example.com, 포트가 443인 오리진입니다  
포트는 어떻게 알까요? HTTP를 사용하는 경우 기본 포트가 443입니다  
CORS는 교차 오리진 리소스 공유라고 했습니다  
즉 리소스를 다른 오리진에서 얻을 수가 있다는 말이죠  
웹 브라우저에는 기본적인 보안으로  
CORS를 갖추고 있는데 이는 여러분이 웹사이트를  
방문했을 때 다른 오리진이  
허락할 때에만 요청을 보낼 수 있도록 허락하는 설정입니다  
브라우저 기반 보안인 거죠  
그럼 같은 오리진과 다른 오리진이란 무엇일까요?  
같은 오리진은 다음과 같습니다  
example.com/app1 또는 example.com/app2일 때  
같은 오리진이라고 할 수 있죠 이때는 첫 번째 URL에서  
두 번째 URL로 웹 브라우저 간 요청이 가능합니다  
오리진이 같기 때문이죠  
하지만 www.example.com를 방문한 다음 웹 브라우저에  
other.example.com에 대한 요청을 할 경우  
이를 교차 오리진 요청이라고 하며  
이때 올바른 CORS 헤더가 없으면 웹 브라우저가 해당 요청을 차단합니다  
CORS 헤더는 화면에서 보이는 것과 같이  
Access-Control-Allow-Origin 라고 합니다













