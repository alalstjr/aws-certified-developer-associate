- [IAM: Users & Groups](#IAM:-Users-&-Groups)
  - [IAM User 만들기](#IAM-User-만들기)
  - [정책](#정책)
  - [Password Policy](#Password-Policy)
    - [가상 MFA 장치](#가상-MFA-장치)
    - [U2F 보안 키](#U2F-보안-키)
  - [MFA 설정](#MFA-설정)
  - [AWS 액세스 키, CLI 및 SDK](#AWS-액세스-키,-CLI-및-SDK)
    - [CLI 란 무엇일까?](#CLI-란-무엇일까?)
    - [SDK 란 무엇일까?](#SDK-란-무엇일까?)
  - [CLI Install](#CLI-Install)
  - [AWS CLI 연습](#AWS-CLI-연습)
  - [역할](#역할)
    - [IAM 액세스 관리자](#IAM-액세스-관리자)
    - [IAM 모범 사례](#IAM-모범-사례)
- [EC2 기초](#EC2-기초)
  - [인스턴스 유형](#인스턴스-유형)
    - [범용의 인스턴스](#범용의-인스턴스)
    - [컴퓨팅 최적화 인스턴스](#컴퓨팅-최적화-인스턴스)
    - [메모리 최적화의 인스턴스](#메모리-최적화의-인스턴스)
    - [스토리지 최적화 인스턴스](#스토리지-최적화-인스턴스)
  - [보안 그룹](#보안-그룹)
    - [SSH](#SSH)
  - [온-디맨드 인스턴스](#온-디맨드-인스턴스)
  - [예약 인스턴스](#예약-인스턴스)
    - [정기 예약 인스턴스](#정기-예약-인스턴스)
    - [스팟 인스턴스](#스팟-인스턴스)
    - [전용 호스트](#전용-호스트)
    - [전용 인스턴스](#전용-인스턴스)
- [EBS 볼륨](#EBS-볼륨)
  - [스냅샷](#스냅샷)
  - [AMI](#AMI)
  - [인스턴스 스토어](#인스턴스-스토어)
  - [EBS 볼륨](#EBS-볼륨)
    - [IOPS](#IOPS)
    - [스토리지](#스토리지)
    - [st1과 sc1](#st1과-sc1)
    - [EBS 다중 연결](#EBS-다중-연결)
  - [EFS](#EFS)
    - [성능 모드](#성능-모드)
    - [처리량 모드](#처리량-모드)
  - [EBS vs EFS](#EBS-vs-EFS)
  - [EBS](#EBS)
  - [EFS](#EFS)
- [ELB](#ELB)
  - [고가용성과 확장성](#고가용성과-확장성)
    - [확장성](#확장성)
  - [로드 밸런싱](#로드-밸런싱)
  - [Sticky Sessions](#Sticky-Sessions)
    - [애플리케이션 기반 쿠키](#애플리케이션-기반-쿠키)
    - [기간 기반 쿠키](#기간-기반-쿠키)
  - [교차 영역 로드 밸런싱](#교차-영역-로드-밸런싱)
  - [SSL](#SSL)
  - [등록 취소 지연](#등록-취소-지연)
  - [오토스케일링 AGS](#오토스케일링-AGS)
    - [오토 스케일링 그룹의 스케일링 정책](#오토-스케일링-그룹의-스케일링-정책)
- [EBS 볼륨](EBS-볼륨)
  - [스냅샷](#스냅샷)
  - [AMI](#AMI)
  - [인스턴스 스토어](#인스턴스-스토어)
  - [EBS 볼륨](#EBS-볼륨)
    - [IOPS](#IOPS)
    - [스토리지](#스토리지)
    - [st1과 sc1](#st1과-sc1)
    - [EBS 다중 연결](#EBS-다중-연결)
  - [EFS](#EFS)
    - [성능 모드](#성능-모드)
    - [처리량 모드](#처리량-모드)
  - [EBS vs EFS](#EBS vs EFS)
    - [EBS](#EBS)
    - [EFS](#EFS)

# IAM: Users & Groups

IAM 은 `Identity and Access Management` 의 약자로  
IAM 에서는 사용자를 생성하고  
그룹에 배치하기 때문에 글로벌 서비스에 해당됩니다  

AWS에서는 모든 사용자에게 모든 것을 허용하지 않습니다  
그러면 엉망이 될 겁니다  
새로운 사용자가 너무 많은 서비스를 실행하여 큰 비용이  
발생하거나, 보안 문제를 야기할 수 있기 때문이죠  
따라서 AWS에서는 최소 권한의 원칙을 적용합니다  
즉 사용자가 꼭 필요로 하는 것 이상의 권한을 주지 않는 것입니다.  

## IAM User 만들기

처음으로 할 일은 IAM 사용자를 생성하는 것이죠

https://us-east-1.console.aws.amazon.com/iamv2/home?region=us-east-1#/users

Users 항목으로 이동해 Add users 를 선택하겠습니다  
보시는 것처럼 상단의 계정 이름을 클릭해 보시면  
현재 루트 계정을 사용 중이죠  
루트 사용자는 계정에 대한 모든 권한을 가지고 있습니다  
그렇기 때문에 위험한 계정이 될 수도 있죠  
따라서 별도의 관리자 계정을 만드는 것이 좋습니다  
루트 계정은 정말로 반드시 꼭 필요할 때만 사용할 겁니다  

그룹 이름은 admin으로 하겠습니다  
admin 그룹에 배치된 사용자는  
이 그룹에 부여된 권한을 승계하게 됩니다  
그리고 권한은 정책을 통해 정의되죠  
admin 그룹에 연결할 정책은 AdministratorAccess 입니다
이 정책은 admin 그룹에 속한 모든 사용자가
계정의 관리자 역할을 하도록 허용할 겁니다  

Next: Tags를 클릭합니다  
AWS에서는 어디에서든 태그를 찾을 수 있는데요  
사용자의 접근을 추적, 조직, 제어할 수 있도록 도와주는 정보입니다    
이 강의에서는 굳이 여기저기에 태그를 만들지 않을 겁니다  
다만 사용자를 위한 태그 생성 방법을 보여드리죠  
그 특정 사용자에 대해 단순히 정보를 추가하는 것입니다  
예를 들어, 이 사용자가 속한 부서는 엔지니어링이라고 표시할 수 있죠

## 정책

~~~
{
    "Version": "2012-10-17",
    "Id": "S3-Account-Permissions"
    "Statement": [
        {
            "Sid": "1",
            "Effect": "Allow",
            "Principal": {
                "AWS": ["arn:aws:iam::123123123:root"]
            },
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
            ],
            "Resource": ["arn:aws:s3:::mybuckey/*"]
        }
    ]
}
~~~

IAM 정책 구조 요소는 버전 숫자를 포함하는데요  
보통은 2012-10-17로 정책 언어 버전입니다  
정책을 식별하는 `ID` 도 있는데 선택 사항이고요  
문장들도 구성 요소입니다  
문장은 하나일 수도 여러 개일 수도 있는데  
문장에는 아주 중요한 부분들이 있죠  
먼저 `Sid` 는 문장 ID로 문장의 식별자이고 역시 선택 사항입니다  
오른쪽에 보시면 1번이라고 나와있죠  
정책에서 `Effect` 는 문장이 특정 API에 접근하는 걸 허용할지 거부할지에 대한 내용입니다  
`Principal` 은 특정 정책이 적용될 사용자, 계정, 혹은 역할로 구성됩니다
이 예시에선 AWS 계정의 루트 계정에 적용이 되죠  
`Action` 은 `Effect` 에 기반해 허용 및 거부되는 API 호출의 목록입니다  
그리고 `Resource` 는 적용될 `Action` 의 리소스의 목록으로  
이 예시에선 버킷이지만 다른 것들도 될 수도 있겠죠

## Password Policy

이 그룹과 사용자들의 정보가 침해당하지 않도록 보호해야겠죠  
다요소 인증, `MFA` 입니다  
`MFA` 는 여러분이 알고 있는 비밀번호와  
여러분이 가지고 있는 보안 장치를 함께 사용하는 것입니다  
`MFA` 의 장점은 사용자가 해킹을 당해 비밀번호가  
누출된 상황이라고 해도 해커에게는 로그인을 위해 휴대전화 등  
사용자 소유의 물리적 장치가 추가로 필요해질 테니  
계정이 침해당하지 않는다는 점입니다  

AWS 에서의 `MFA 장치 옵션` 으로는 어떤 것들이 있을까요?

### 가상 MFA 장치

`Google Authenticator` 를 사용할 수 있는데 하나의 휴대전화에서만 사용이 가능하죠
`Authy` 는 여러 장치에서 사용이 가능합니다  
장치의 개수가 다를 뿐 작동 방식은 동일합니다  
개인적으로 저는 `Authy` 를 사용하는데 컴퓨터와  
휴대전화에서 같이 사용할 수 있기 때문이죠  
`Authy` 는 하나의 장치에서도 토큰을 여러 개 지원합니다  
즉, 가상 `MFA` 장치를 사용하면  
루트 계정, IAM 사용자 또 다른 계정, 그리고  
또 다른 IAM 사용자가 지원되는 식으로 가상 MFA 장치에  
원하는 수만큼의 계정 및 사용자 등록이 가능합니다  

### U2F 보안 키

이는 물리적 장치로 예를 들어  
Yubico 사의 YubiKey 가 있죠 Yubico 는 AWS 의 제3자 회사로  
AWS 제공 장치가 아니라 제3자 회사의 장치입니다  
이렇게 `물리적 장치를 사용하면 전자 열쇠`에 달고 다닐 수 있으니  
사용이 상당히 편리할 수 있겠죠  
YubiKey 는 하나의 보안 키에서 여러 루트 계정과 IAM 사용자를  
지원하기 때문에 하나의 키로도 충분합니다

### 하드웨어 키 팝 MFA 장치

역시 AWS 의 제3자 회사인 Gemalto 의 제품입니다  
만약 미국 정부의 클라우드인 AWS GovCloud 를  
사용하시는 경우라면, MFA 숫자를 실시간으로 보여주는 특수한 키 팝(작은 물건)이 필요한데요  
역시 SurePassID 라는 제3자 회사가 제공하고 있죠  

## MFA 설정

왼쪽의 `Account settings (계정 설정)` 에 들어가서  
`Change password policy (암호 정책 변경)` 를 누르면  
여기서 비밀번호 정책 적용이 가능하죠    
비밀번호 최소 길이 지정이 가능하고  
적어도 하나의 대문자 및 소문자 숫자를 포함하도록 합니다  

오른쪽에 있는 계정 이름을 클릭하고  
`My Security Credential(보안 자격 증명)` 로 들어갑니다  
https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/security_credentials

`Multi-factor authentication (MFA) - 멀티 팩터 인증` 를 클릭하고  
휴대전화를 사용할 거니까 Virtual MFA device 를 선택하겠습니다

## AWS 액세스 키, CLI 및 SDK

Create access key 버튼으로 액세스 키를 생성하면  
곧 다운로드 권한이 주어질 겁니다  
직장에서 보안 문제를 피하기 위해서는  
절대 액세스 키를 공유하지 마세요 여러분만 알고 계셔야 합니다  

### CLI 란 무엇일까?

`CLI` 는 명령줄 인터페이스를 의미하며  
`AWS CLI` 는 명령줄 셸에서 명령어를 사용하여  
AWS 서비스들과 상호작용할 수 있도록 해 주는 도구입니다

`CLI` 를 사용하면 `AWS 서비스의 공용 API 로 직접 액세스가 가능`합니다
그리고 `CLI` 를 통해 리소스를 관리하는 스크립트를 개발해  
일부 작업을 자동화할 수 있죠  
`CLI` 는 오픈 소스로, GitHub 에서 모든 소스 코드를 찾으실 수 있으며  
AWS 관리 콘솔 대신 사용되기도 합니다  

### SDK 란 무엇일까?

`SDK 는 소프트웨어 개발 키트입니다`  
특정 언어로 된 라이브러리의 집합인데요  
따라서 프로그래밍 언어에 따라 개별 `SDK` 가 존재합니다  
이 방식을 사용해서도 역시 AWS 서비스나 API 에  
프로그래밍을 위한 액세스가 가능하도록 해줍니다  
하지만 `SDK 는 터미널 내에서는 사용하는 것이 아니라  
코딩을 통해 애플리케이션 내에 심어 두어야 하는 겁니다`  
애플리케이션 내에 자체적으로 AWS SDK 가 있는 거죠  
다양한 프로그래밍 언어를 지원하죠  
JavaScript Python, PHP, .NET  
Ruby, Java, Go Node.js, C++ 등을 지원합니다

## CLI Install

https://docs.aws.amazon.com/cli/latest/userguide/getting-started-version.html

## AWS CLI 연습

사용자 -> 생성된 IAM 유저 계정 클릭   
IAM 사용자인 상태이며 이제 Security credentials (보안 자격 증명) 로 이동합니다
액세스 키는 CLI, 즉 명령줄 인터페이스를 사용할 때 굉장히 유용합니다  
혹은 AWS 에 프로그래밍 언어의 구현을 위해 SDK 를 사용할 때도 유용하죠  
Create access key 를 클릭합시다 액세스 키는 기밀입니다  
오직 생성 시에만 표시 및 다운로드가 가능하죠  

먼저 AWS CLI 부터 구성해야 하는데요  
aws configure 라고 입력하겠습니다  
그러면 액세스 키 ID를 입력하라고 나오네요  
생성된 액세스 키를 붙여 넣어 입력한 후 Enter 를 누르고요  
이번엔 암호 액세스 키를 입력하라는 안내가 나옵니다  
역시 이렇게 입력해 주겠습니다  
기본 리전 이름은 가까운 리전을 말하는 겁니다  
강의 전체가 eu-west-1에서 진행될 테니 eu-west-1로 지정해 주겠습니다  
여러분들은 각자의 리전을 선택해 입력하시면 됩니다  

그럼 어떻게 작동하는지도 한 번 봐야겠죠
aws iam list-users 를 입력 후 Enter 를 누르면
제 계정의 모든 사용자를 목록으로 보여 줄 겁니다

## AWS 클라우드쉘

`CloudShell` 은 화면 우측 상단의 이 아이콘입니다  
사용 할 수 있는 리전에 있는지 확인하세요 모든 리전에서 가능한 건 아니거든요  
AWS CloudShell FAQs에 가시면 사용이 불가능한 리전이 나와 있습니다

## 역할

EC2 인스턴스는 AWS에서 어떤 작업을 수행하려고 할 수 있습니다  
그러기 위해서는 EC2 인스턴스에 권한을 부여해야 합니다  
이를 위해 IAM 역할을 만들어 이들을 하나의 개체로 만듭니다  
EC2 인스턴스가 AWS에 있는 어떤 정보에 접근하려고 할 때  
IAM 역할을 사용하게 될 것입니다  
만약 IAM 역할의 권한을 올바르게 부여한 경우  
하려고 하는 호출에 접근하게 될 것입니다  

역할은 여러분이 신뢰하는 개체에 권한을 부여하기 위해 사용됩니다

### IAM 액세스 관리자

이것은 사용자 수준에서 가능합니다 액세스 관리자는  
사용자에게 부여된 서비스의 권한과  
해당 서비스에 마지막으로 액세스한 시간이 보입니다  
최소권한의 원칙에 따랐을 때 매우 도움 되는 정보입니다  
해당 도구를 사용하여 어떤 권한이 사용되지 않는지 볼 수 있고  
따라서 사용자의 권한을 줄여 최소권한의 원칙을 지킬 수 있습니다

왼쪽 하단에 Credential report 가 있고 Download Report 를 클릭하여  
보고서를 다운로드합니다 CSV 파일이 다운로드될 거예요  
사용자가 언제 생성되었는지, 비밀번호가 활성화되었는지,  
비밀번호를 마지막으로 언제 사용했는지, 마지막으로 언제 변경되었는지,  
비밀번호 변경 주기를 활성화한 경우 다음 주기는 언제인지  
MFA 가 활성화되었는지 출력됩니다.

다음으로는 IAM 액세스 관리자를 이야기하겠습니다  
Users를 클릭합니다  
오른쪽에 Access Advisor 가 있습니다  
마지막에 사용된 서비스를 보여줄 것입니다  
보통 최근 4시간 동안의 활동 내역이 보입니다  
만약 보이지 않는다면 4시간이 지났기 때문이죠

### IAM 모범 사례

루트 계정은 AWS 계정을 설정할 때를 제외하고 사용하지 마세요  
사용자를 그룹에 넣어 해당 그룹에 권한을 부여할 수 있어요  
따라서 그룹 수준에서 보안을 관리할 수 있습니다  
또한 비밀번호 정책을 강력하게 만들어야 합니다  
다요소 인증(MFA)을 사용한다.  
AWS 서비스에 권한을 부여할 때마다 역할을 만들고 사용해야 합니다  
가상 서버인 EC2 인스턴스를 포함해서요  
AWS를 프로그래밍할 경우, 즉, CLI나 SDK를 사용할 경우  
반드시 액세스 키를 만들어야 합니다 액세스 키는 비밀번호와 같습니다

# EC2 기초

이것은 일래스틱 컴퓨트 클라우드의 약자로 AWS에서 제공하는 서비스형 인프라스트럭처입니다  
즉, EC2는 하나의 서비스가 아닙니다  
높은 수준에서 보면 많은 것을 포함하고 있습니다  
가상 머신을 EC2에서 임대할 수 있는데 이를 EC2 인스턴스라고 합니다  

데이터를 가상 드라이브 또는 EBS 볼륨에 저장할 수 있고  
일래스틱 로드 밸런서로 로드는 분산시킬 수 있습니다  
또 오토 스케일링 그룹(ASG)을 통해 서비스를 확장할 수 있습니다  

즉, EC2 사용자 데이터 스크립트를 사용하여 인스턴스를 부트스트래핑할 수 있습니다  
부트스트래핑이 무슨 뜻일까요?  
이는 머신이 작동될 때 명령을 시작하는 것을 말합니다  
스크립트는 처음 시작할 때 한 번만 실행되고 다시 실행되지 않습니다

## 인스턴스 유형

m5.2xlarge 라는 유형의 인스턴스를 예로 들어 보겠습니다  
`m 을 인스턴스 클래스`로 부르겠습니다  
그리고 이 인스턴스 클래스는 범용의 인스턴스입니다  
`5는 인스턴스의 세대`를 뜻합니다  
즉, AWS 가 하드웨어를 계속 개선해서 새로운 세대의 하드웨어를 출시하고  
m5 이후에 m 유형의 인스턴스 클래스를 개선하면  
m6가 되는 것입니다 2xlarge 는 인스턴스 클래스 내에서 크기를 나타냅니다  
small 로 시작해 large, 2xlarge 4xlarge 등의 크기가 있죠  
인스턴스의 크기를 나타내며 크기가 클수록 인스턴스에  
더 많은 메모리와 CPU 를 가지게 됩니다

### 범용의 인스턴스

먼저, 범용의 인스턴스는 웹 서버나 코드 저장소와 같은 다양한 작업에 적합합니다  
컴퓨팅, 메모리, 네트워킹 간의 균형도 잘 맞습니다

### 컴퓨팅 최적화 인스턴스

이제 컴퓨팅 최적화 인스턴스는 컴퓨터 집약적인 작업에 최적화된 인스턴스입니다  
그러면 고성능 프로세서는 어디에 사용할까요?  
일부 데이터의 일괄 처리에 사용하거나  
미디어 트랜스코딩 작업 시 혹은 고성능 웹 서버가 필요하거나  
고성능 컴퓨팅이라는 HPC 작업을 할 때 그리고 머신 러닝이나  
전용 게임 서버가 있을 때 사용합니다  
모두 훌륭한 CPU와 컴퓨팅을 요구하는 작업이며  
EC2 인스턴스는 이런 특성을 가지고 있습니다  
그리고 컴퓨터 최적화의 모든 인스턴스는  
C로 시작하는 이름을 가지고 있습니다  
C5, C6 등이죠  

### 메모리 최적화의 인스턴스

다음으로 메모리 최적화의 인스턴스를 살펴보겠습니다  
이 유형의 인스턴스는 메모리에서 대규모 데이터셋을  
처리하는 유형의 작업에 빠른 성능을 제공합니다  
메모리는 RAM을 뜻하고 사용 사례를 살펴보면  
대부분 인 메모리 데이터베이스가 되는  
고성능의 관계형 또는 비관계형의 데이터베이스에 사용하고  
일래스틱 캐시를 예로 들 수 있는  
분산 웹스케일 캐시 저장소에도 사용합니다  
즉, BI에 최적화된 인 메모리 데이터베이스와  
대규모 비정형 데이터의 실시간 처리를 실행하는  
애플리케이션에도 사용합니다

### 스토리지 최적화 인스턴스

로컬 스토리지에서 대규모의 데이터셋에  
액세스할 때 적합한 인스턴스입니다  
스토리지 최적화 인스턴스의 사용 사례로는  
고주파 온라인 트랜잭션 처리인 OLTP 시스템에 사용되며
관계형과 비관계형인 NoSQL 데이터베이스에 사용합니다  
데이터베이스 섹션에서 더 자세히 살펴보겠습니다  
예를 들어, 레디스(Redis) 같은  
메모리 데이터베이스의 캐시나 데이터 웨어하우징 애플리케이션과 분산 파일 시스템에 사용됩니다

## 보안 그룹

`EC2 인스턴스에 들어오고 나가는 트래픽을 제어`합니다
보안 그룹은 간단한데요 허용 규칙만 포함합니다  
출입이 허용된 것이 무엇인지 확인할 수 있고  
IP 주소를 참조해 규칙을 만들 수 있습니다  

### SSH

시큐어 셸이라는 의미로 다음 강의에서 살펴봅니다  
포트는 22번 포트로 Linux에서 EC2 인스턴스로 로그인하도록 합니다  
파일 전송 프로토콜인 FTP의 포트는 21번 포트이며 파일 공유 시스템에 파일을 업로드하는데 사용됩니다

SFTP도 22번 포트를 사용하는 이유는 무엇일까요? SSH를 사용해서 업로드하기 때문이고 
보안 파일 전송 프로토콜이 되기 때문입니다

원격 데스크톱 프로토콜인 RDP의 3389번 포트이며
윈도우 인스턴스에 로그인할 때 사용됩니다

### SSH 연결하기

SSH는 명령줄 인터페이스 도구로  
Mac과 Linux에서 사용할 수 있고  
Windows10 이상의 버전에서 사용할 수 있습니다  
Windows10 이하의 버전이라면  
퍼티(PuTTY)를 사용하면 됩니다  
퍼티는 SSH와 동일한 것입니다  
SSH를 사용해야 할 때 Windows에서는 퍼티를 사용합니다  
퍼티는 모든 버전의 Windows에서 사용 가능합니다  

이제 머신에 접속하기 위해  
ssh ec2-user@와  
35.180.100.144를 입력하고 키를 참조하도록 하기 위해  
머신에 접속할 수 있는 키를 이 중간에 입력합니다  
키를 사용하려면 -i를 입력하고 EC2Tutorial.pem을 입력합니다  
그러면 ssh -i EC2Tutorial.pem가 되고  
그다음은 인스턴스 사용자 이름과 인스턴스 IP가 오게 됩니다  
Enter를 클릭하면 다른 경고문이 나타납니다  
비보호의 개인 키 파일이라는 경고가 나타났습니다    
이 부분이 시험에 정말 잘 나옵니다  
파일을 처음 다운로드하면  
`0644 라는 권한이 생기는데 권한이 너무 열려 있어서 개인 키가 유출될 수 있습니다`
다른 사람이 개인 키에 접근할 수 있어 bad permissions가 나타나고  
SSH를 머신에 연결할 수 없도록 합니다  
해결하는 방법이 자주 출제되며 `해결하려면 chmod 0400` 를 입력하고  
이렇게 키 이름을 참조합니다

## 온-디맨드 인스턴스

`사용한 만큼 지불하는 옵션`이죠  
비용이 초당 청구됩니다 EC2 인스턴스가 실행된  
초반 1분 이후부터 1초당 비용이 청구되죠  
온-디맨드는 클라우드에 가장 적합한 방식으로  
`가격은 높지만, 선결제나 장기 약정이 필요 없습니다`  
사용 해지, 중지, 시작이 언제든 가능하죠  
온-디맨드 방식은  
`애플리케이션 작동 방식을 예측할 수 없는`  
연속적인 단기 워크로드에 적합합니다  

간단 예시  
첫 번째로 온-디맨드는 원할 때면 언제든
리조트에 묵을 수 있는 겁니다
전액을 지불해야 하지만 원하면 언제나 방을 얻을 수 있죠

## 예약 인스턴스

온-디맨드와 비교하면 약 75%의 비용을 절약할 수 있고
`1년 혹은 3년 중에서 선택할 수 있죠`  
3년의 기간을 선택하면 해당 인스턴스를 더 오랜 기간동안  
사용할 의향이 있다고 AWS에 알리는 것과 같습니다  

종종 오랜 시간 동안 사용해야 하는 서버가 있는 경우에는
이를 AWS에 알림으로써 비용을 절감할 수 있는데요
이럴 때 사용 가능한 첫 번째 옵션이 바로 예약 인스턴스입니다
예약 인스턴스는 최소 1년 이상 사용해야 합니다
약속된 기간이죠
예약 인스턴스에는 세 가지 종류가 있는데
첫 번째로는 단순한 예약 인스턴스로
데이터베이스 같은 장기 워크로드에 사용됩니다
그리고 전환형 예약 인스턴스가 있는데
시간이 지난 후 다른 종류의
인스턴스로 바꿀 수 있는 유연형 인스턴스죠

예약 인스턴스가 적합한 곳으로는  
애플리케이션이 안정된 상태로 사용되는, 즉 데이터베이스 등이 해당되죠  
3년간 데이터베이스를 사용해야 하는 상황이라면  
이런 인스턴스를 예약함으로써 비용을 크게 절감할 수 있을 겁니다  

간단 예시  
예약 인스턴스는 오랜 기간 호텔에 머무는 것으로  
미리 계획을 세웁니다  
할인도 괜찮게 받습니다  
한 달 정도 길게 머무는 손님이니까요  

### 정기 예약 인스턴스

그리고 정기 예약 인스턴스가 있습니다
예를 들어 일 년 내내는 아니지만 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)
일 년 동안 매주 목요일 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)
오후 3시부터 6시까지 서버가 필요한 경우죠 (정기 예약 인스턴스는 현재 사용되지 않으나 시험에는 나올 수 있습니다)

### 스팟 인스턴스

온-디맨드 인스턴스에 비교하면 최대 90%까지 할인이 되죠  
여러분이 지불하고자 하는 가격이  
현재 스팟 인스턴스의 가격보다 낮다면  
`인스턴스가 언제든 중단될 수 있다는 겁니다`

저렴한 단기 워크로드 용 인스턴스지만  
손실 가능성이 있으며 신뢰성이 낮습니다  

그럼 어떤 유형의 워크로드가 적합할까요?  
단발성 데이터 분석인 배치 로드  
그리고 이미지 프로세싱 이미지 변환이 중단되어  
한 이미지 변환에 실패해도 나중에 다시 시작하면 되니까요  
그리고 분산된 워크로드가 있는경우

간단 예시  
아시다시피 일부 호텔은 밤에 객실이 빌 때  
아주 공격적인 할인을 선보입니다  
객실을 비워 두면 손해를 볼 것이고 사업이 망할 수도 있죠  
하지만 이 호텔은 조금 이상합니다  
만약 호텔이 여러분보다 객실비를  
더 많이 지불할 수 있는 손님을 찾게 되면  
여러분을 쫓아낼 수 있거든요  
이러면 이상한 호텔이긴 하겠지만 스팟 인스턴스가  
이런 경우와 비슷하답니다

### 전용 호스트

Amazon 전용 호스트는 EC2 인스턴스를 갖춘 유저 중심의 물리적 서버입니다  
즉, AWS 데이터 센터 내 하나의 서버 전체를 임대하는 거죠  
`전용 호스트를 사용하면 준수 요건의 처리가 쉽고`   
기존의 `서버 결합 소프트웨어 라이센스`의 사용이 가능하기 때문에  
비용을 절감할 수 있습니다  

전체 서버를 독자적으로 이용하게 되니 비용은 더 올라갑니다  
만약 복잡한 라이센스 모델의 소프트웨어를 사용하거나  
자가 라이센스를 가진 경우, 혹은 강력한 규제나 규정 준수 요건이  
있을 때도 상당히 도움을 주는 옵션이죠  

간단 예시  
이 경우 리조트 전체를 혼자서 예약합니다  
규정 준수 관련 이유로 이웃이 없어야 하거나  
서버 결합 라이센스를 가지고 있는 등의 이유 때문이죠  

### 전용 인스턴스

여러분의 전용 하드웨어에서 실행되는 EC2 인스턴스를 의미합니다  
같은 계정의 다른 인스턴스와 하드웨어를 공유하며  
인스턴스가 어떻게 배치될지에 대해서는 여러분이 간섭할 수 없습니다  
다시 말해, 전용 하드웨어가 있어도  
해당 하드웨어의 근본에는 접근할 수가 없습니다  
전용 호스트의 약한 버전이라고 할까요

# EBS 볼륨

EBS 볼륨은 일래스틱 블록 스토어의 줄임말입니다  
네트워크 USB 스틱이라고 생각하시면 됩니다  
USB 스틱처럼 한 컴퓨터에서 꺼내, 다른 컴퓨터에 꽂는  
그런 장치는 맞지만 실제 물리적 연결은 없으며  
네트워크를 통해 연결되는 거죠  

EBS 볼륨은 특정한 가용 영역에 고정되어 있으므로  
us-east-1a에 생성된 볼륨은  
us-east-1b로 연결이 불가능합니다

## 스냅샷

언제든 원하는 시점에 EBS 볼륨을 가지고 와서  
`백업이라고 불리기도 하는 스냅샷(Snapshot)`을 생성할 수 있습니다

스냅샷을 생성하는 이유는 무엇일까요? 복원 목적도 있으나  
가용 영역(AZ) 또는 리전(Region)에 걸친 스냅샷을 복사할 수 있기 때문입니다

더불어서 AWS의 다른 리전에 데이터를 전송하여 글로벌 인프라를 활용하는 것이죠  
또 다른 가용 영역에 새로운 EBS 볼륨을 복원할 수 있습니다

## AMI

AMI는 Amazon Machine Image의 약자로 사용자 지정 EC2 인스턴스를 나타냅니다  
각자의 소프트웨어 구성에 대해 운영 체제를 정의 및 설정하며 모니터링 도구를 설정할 수도 있는데  
이때 자체적으로 AMI를 생성하면 부팅과 구성에 시간이 단축됩니다

다른 사용자가 만들어서 판매하는 AMI로 자주 찾아볼 수 있습니다 AWS의 공급 업체가  
자체적으로 AMI나 구성이 훌륭한 소프트웨어를 생성하고  
여러분은 시간 절약을 위해 `마켓 플레이스 AMI에서 이들을 구매`할 수 있습니다

`AMI는 특정 AWS 지역용으로 구축되며 각 AWS 지역마다 고유`합니다.   
다른 AWS 지역의 AMI를 사용하여 EC2 인스턴스를 시작할 수는 없지만   
AMI를 대상 AWS 지역에 복사한 다음 이를 사용하여 EC2 인스턴스를 생성할 수 있습니다.

## 인스턴스 스토어

EC2 인스턴스는 가상 머신이지만 `실제로는 하드웨어 서버에 연결`되어 있습니다  
EC2 인스턴스 스토어는 I/O 성능 향상을 위해 활용할 수 있습니다  
이들이 훌륭한 처리량을 갖추고 있어서 매우 향상된 디스크 성능을  
요할 때에 활용할 수 있도록 확보할 필요가 있습니다

이때 주의할 점은 여러분이  
EC2 인스턴스, 즉 인스턴스 스토어를 중지 또는 종료하면  
해당 스토리지 또한 손실된다는 것입니다  
이 같은 이유로 이를 임시 스토리지라고 부르며  
EC2 인스턴스 스토어가  
`장기적으로 데이터를 보관할 만한 장소가 될 수 없음을 보여 줍니다`

그러면 언제 사용하는 것이 좋을까요?  
버퍼나 캐시 스크래치 데이터 또는 임시 콘텐츠를 사용하려는 경우  
이들을 보관할 좋은 장소가 되지만 장기적인 스토리지는 될 수 없습니다  
장기 스토리지의 경우에는 EBS 가 적합합니다

마지막으로 EC2 인스턴스의 기본 서버에 장애가 발생할 시에는  
해당 EC2 인스턴스가 연결된 하드웨어에도  
장애가 발생하므로 데이터 손실에 대한 위험이 존재합니다  
따라서 EC2 인스턴스 스토어를 사용할 때에는  
여러분의 필요에 따라 데이터를 백업해 두거나  
복제해 둬야 합니다

## EBS 볼륨

총 여섯 개의 유형이 있고
이들을 여러 범주로 나눌 수 있습니다

`gp2/gp3`가 있는데 이는 범용 SSD 볼륨으로
`다양한 워크로드에 대해 가격과 성능의 절충안이 되어 줍니다`

`io1과 io2`가 있습니다  
최고 성능을 자랑하는 SSD 볼륨으로  
`미션 크리티컬이자 지연 시간이 낮고 대용량의 워크로드`에 쓰입니다

`st1` 볼륨이 있는데 이는 저비용의 HDD 볼륨으로  
`잦은 접근과 처리량이 많은 워크로드`에 쓰이죠

`sc1` 볼륨은 가장 비용이 적게 드는 HDD 볼륨으로  
`접근 빈도가 낮은 워크로드`를 위해 설계되었습니다

EBS 볼륨은 어떻게 정의하는 걸까요?  
가령 크기, 처리량과 IOPS가 있죠  
`IOPS는 초당 I/O 작업 수`를 뜻합니다

EC2 인스턴스에는  
`gp2/gp3와 io1/io2만이 부팅 볼륨`으로 사용될 수 있습니다  

gp2 는 짧은 지연 시간을 자랑하며 효율적인 비용의 스토리지입니다  
시스템 부팅 볼륨에서 가상 데스크톱, 개발, 테스트 환경에서 사용할 수 있죠   
gp2는 좀 더 오래된 버전으로 볼륨이 더 작습니다 최대 3,000 IOPS에  
볼륨과 IOPS가 연결되어 있어서 IOPS가 증가할 때면  
즉 볼륨의 GB 수를 늘릴 때에 세 배 더 증가한 16,000 IOPS가 된다는 의미입니다

gp2와 gp3에는 차이가 있는데 gp3는 최신 세대의 볼륨으로  
기본 성능으로 3,000 IOPS와 초당 125MB의 처리량을 제공합니다  
각각 IOPS는 최대 16,000 처리량은 1,000MB/s까지 증가시킬 수 있습니다

gp2/gp3가 비용 효과적인 스토리지이며  
`gp3에서는 IOPS와 처리량을 독자적으로 설정`할 수 있는 반면  
`gp2에서는 그 둘이 연결되어 있다는 점`입니다

### IOPS

이는 IOPS 성능을 유지할 필요가 있는 주요 비즈니스 애플리케이션이나  
16,000 IOPS 이상을 요하는 애플리케이션에 적합합니다  
일반적으로 `데이터베이스 워크로드`에 알맞죠

### 스토리지

io1/io2에 중에서는 최신 세대를 고르는 것이 좋습니다 4에서 16TB에 달하며  
Nitro EC2 인스턴스에서는 최대 64,000 IOPS까지 가능합니다  
Nitro EC2 인스턴스의 경우 이를 통해 더 높은 IOPS까지 이용할 수 있습니다  
Nitro EC2 인스턴스가 아닌 경우에는  
최대 32,000 IOPS까지 지원됩니다  
또한 io1/io2를 이용하면 gp3 볼륨처럼 프로비저닝된 IOPS를  
스토리지 크기와 독자적으로 증가시킬 수 있습니다  
io2 이용 장점은 무엇일까요?
`io1과 동일한 비용으로 내구성과 기가 당 IOPS의 수가 더 높습니다`  
현재까지는 io2를 사용하는 것이 더 합리적인 거죠

### st1과 sc1

부팅 볼륨일 수 없습니다   
최대 16TB까지 확장

두 가지 종류의 볼륨을 제공합니다  
하나는 st1인 처리량 최적화 HDD로  
빅 데이터나 데이터 웨어하우징 로그 처리에 적합합니다

최대 처리량은 초당 500MB 그리고 최대 IOPS는 500에 달합니다  
다음으로는 sc1인 콜드 HDD가 있는데 이는 아카이브 데이터용으로  
접근 빈도가 낮은 데이터에 적합합니다  
최저 비용으로 데이터를 저장할 때에 사용하죠  
최대 처리량은 초당 250MB  
그리고 최대 IOPS도 250입니다

### EBS 다중 연결

앞서 EBS 볼륨은 단일한 EC2 인스턴스에만 연결할 수 있다고 했습니다  
EBS 다중 연결을 제외한 경우에 말이죠   
동일한 가용 영역 내의 여러 EC2 인스턴스에 연결하여 사용할 수 있습니다  
EBS는 `io1이나 io2 제품군일 때만 여러 EC2 인스턴스에 연결이 가능`합니다

## EFS 

Elastic File System 의 약자로  
다양한 가용 영역에 걸쳐 다수의 EC2 인스턴스에  
마운트 할 수 있는 관리형 NFS 혹은 네트워크 파일 시스템입니다  
즉 `다중 AZ에서 동작`하며   
이 점이 EFS와 EBS의 가장 큰 차이를 보여 줍니다  

EBS는 단일 가용 영역에 묶여 있는 반면  
`EFS는 다중 가용 영역에 걸쳐서 마운트가 가능`합니다

따라서 가용성이 매우 높죠   
확장성도 높으며 비용도 많이 듭니다

EBS는 한 번에 하나의 EC2 인스턴스에만 연결되어 있어서  
데이터가 다중의 EC2 인스턴스 간 공유되지 않지만

EFS 에서는 네트워크 파일 시스템으로  
`EFS 드라이브의 모든 EC2 인스턴스가 동일한 파일에 대한 접근 권한`을 갖습니다

EFS는 콘텐츠 관리, 웹 서비스  
데이터 공유 또는 WordPress 웹사이트에서 쓰입니다  
`표준 NFSv4.1 프로토콜`이 사용되며  
이는 네트워크 드라이브 마운트 시 기본적인 방법입니다  

EFS는 Windows가 아닌 `Linux 기반 AMI에서만 작동`합니다

EFS 옵션에 대해서는 어떤 사항을 알고 있어야 할까요? 먼저 그 규모를 알아야 합니다
EFS는 수천 명의 동시 클라이언트와  
초당 최대 10GB의 처리량을 자랑합니다   
성능이 아주 우수한 거죠  
또한 파일 시스템 자체가 페타바이트(PB) 정도까지  
확장될 수 있으므로 용량을 따로 관리할 필요가 없습니다  
자동으로 수행되죠

### 성능 모드

웹 서버 운영이나 지연 시간에 민감한 파일이 있는 경우  
범용 성능 모드를 사용합니다

EFS에서 대규모 데이터 워크로드를 처리하는 경우  
Max I/O 성능 모드가 적합합니다    
지연 시간은 더 길겠지만 처리량은 더 향상됩니다

### 처리량 모드
 
기본적으로는 버스팅(Bursting) 처리량 모드로 설정되어 있습니다
1TB의 스토리지에 대해  
초당 50MB를 저장할 수 있으며  
여기에 초당 100MB까지 확장이 가능하다는 겁니다  
일반적으로는 파일 시스템의 크기에 따라  
처리량이 증가하므로 EFS 파일 시스템의  
크지는 줄이면서 처리량을 높이기 위해서는  
프로비저닝 된 처리량 모드로 설정을 바꿀 수 있습니다  
이 모드에서는 스토리지 크기와 상관없이 처리량을 설정할 수 있죠  
1TB의 스토리지에 불과하더라도  
초당 1GB의 처리량을 요청할 수 있습니다

접근 빈도가 높은 파일에 대해 표준으로 설정되어 있으며  
EFS-IA라고 부르며 저비용의 빈도가 낮은 접근에 대한 티어가 있습니다  
이와 같은 파일을 저장할 저비용의 장소인 거죠

## EBS vs EFS

### EBS

EBS 볼륨은 한 번에 하나의 인스턴스에만 연결이 가능하고  
특정 가용 영역에 한정됩니다  

gp2에서는 디스크 크기가 늘어나면 IO도 함께 증가하죠  

io 1은 IO를 볼륨 크기와 관계 없이 독립적으로 증가시킬 수 있죠  
중요한 데이터베이스를 실행할 때 좋은 방법입니다

EBS를 다른 가용 영역으로 옮기고자 할 때는  
가장 먼저 스냅샷을 찍어야 합니다  
스냅샷을 찍었다면  
다른 AZ에서 그 스냅샷을 복원시키죠

EBS의 스냅샷이나 백업을 만들 때에는  
EBS 볼륨 내의 IO를 전부 사용하게 되니  
`인스턴스가 EBS를 사용 중이 아닐 때에만 실행`하셔야 합니다

EBS의 경우에는 실제 사용한 양이 아니라  
EBS 드라이브의 크기에 따라  
실제 사용량이 아니라 정해진 사용량을 지불하는 식이었죠

반면 EBS는 네트워크 볼륨을 한 번에 하나의 인스턴스에  
연결할 수 있고 특정 AZ 내로 한정이 되죠  
인스턴스 스토어는 EC2 인스턴스에 IO를 최대로 사용하게끔 해주지만,
`인스턴스가 망가지면 함께 망가지는`  
임시 드라이브인 거죠

### EFS

EFS는 여러 개의 가용 영역에 걸쳐  
`무수히 많은 인스턴스들에 연결`될 수 있습니다

이는 Linux 인스턴스에서만, 가능한데 POSIX 파일 시스템이라  
Windows에서 구동되지 않기 때문입니다

`EFS 는 EBS 보다 훨씬 비쌉니다`  
거의 세 배 정도 더 비싸죠

# RDS

`RDS는 관계형 데이터베이스 서비스`를 나타내며  
이는 SQL을 쿼리 언어로 사용하는  
데이터베이스를 위한 관리형 데이터베이스를 뜻합니다  

EC2 인스턴스 상에 자체 데이터베이스 서비스를 배포하지 않고    
RDS를 사용하는 이유는 무엇일까요?
RDS는 관리형 서비스로  
AWS가 데이터베이스뿐만 아니라  
여러 기타 서비스 또한 제공하고 있습니다  
가령 해당 데이터베이스의 프로비저닝은 완전히 자동화되어 있고  
기본 운영 체제 패치 또한 자동으로 이루어집니다  
또한 지속적인 백업이 수행되며  
특정 타임스탬프도 복구할 수 있습니다  
이를 지정 시간 복구 PITR이라고 합니다  

다중 AZ를 설정할 수 있고  
재해 복구 시 유용하게 이용하는  
다중 AZ에 대한 강의 섹션 또한 찾아보실 수 있습니다  
업그레이드를 위한 유지 보수도 존재하고  
인스턴스 유형을 늘려서  
읽기 전용 복제본을 추가함으로써 인스턴스 유형의  
수직 및 수평 확장성을 증가시킬 수도 있습니다  
끝으로 스토리지가 EBS를 기반으로 하는데  
gp2 볼륨 또는 io1을 뜻한다는 것은 전에 다룬 바 있어서 다들 알고 계시겠죠

단 RDS 인스턴스에는  
SSH를 따로 가질 수 없습니다
이는 `관리형 서비스로 AWS에서 제공되므로 기본 EC2 인스턴스에 대해서는  
사용자가 따로 접근 권한을 갖지 않기 때문`이죠

## 백업

백업은 RDS에서 자동으로 활성화되며 자동으로 생성됩니다  
정의해 놓은 유지 관리 기간 동안  
매일 수행되는 데이터베이스 전체에 대한 백업과  
트랜잭션 로그, 즉 일일 트랜잭션 로그가  
매 `5분 마다 RDS에 백업`되죠

자동 백업은 기본적으로는 7일간 보관되지만  
`최대 35일까지로 보관 기간을 설정`할 수 있습니다  
또한 데이터베이스 스냅샷이 있는데  
스냅샷은 백업과 약간 다릅니다  
스냅샷은 사용자가 수동으로 발동시키는 백업으로  
백업 보관 기간을  
사용자 임의로 설정할 수 있습니다  

### 오토스케일링

RDS 데이터베이스를 생성할 때는 원하는 스토리지 용량을 지정해야 합니다  
스토리지를 20GB로 지정하는 것과 같이 말이죠  
단 데이터베이스 사용이 많고  
사용 가능한 공간이 부족해지는 경우  
바로 이 기능
`RDS 스토리지 오토 스케일링`이 활성화되어 있으면  
RDS가 자동으로 스토리지에 대한 스케일링을 수행하죠  
따라서 스토리지 확장을 위해  
데이터베이스를 중단하는 등의 작업을 따로 수행할 필요가 없습니다  
즉 애플리케이션이  
RDS 데이터에 다량의 읽기 및 쓰기 작업을 수행할 때에  
자동으로 특정한 임계값을 확인해서  
스토리지에 대한 오토 스케일링 작업이 수행되는 RDS 기능입니다  

## RDS 다중 AZ (Multi AZ)

다중 AZ는 `주로 재해 복구에 사용`됩니다    
만약 RDS DB를 만들고, DB에 특정 레코드를 인서트 할 시, 다른 AZ(Availability Zone)에 똑같은 복제본이 만들어집니다.  
Multi AZ는 AWS 에 의해서 자동으로 관리가 이뤄집니다.  
직접 번거로운 과정을 거치지 않아도 되고, 유사시 우리가 현재 사용하고 있는 메인 DB에 문제가 생길 경우  
RDS 는 이를 즉시 발견하고 다른 AZ에 만들어진 복제본을 그대로 사용합니다.  
이를 Disaster Recovery 라고 부릅니다. Multi AZ는 복제본을 만든다고 해서 성능이 더 좋아지는 건 아니지만, 만약 성능개선이 주목적이라면,  
Read Replicas 를 사용해야 합니다.

만약 Amazon RDS Active에 어떤 문제가 생긴다면,  
RDS는 자동으로 Amazon RDS back-up으로 fail over를 합니다.   
뭔가 새로 만들거나, 헤비 워크가 필요 없기 때문에 재해가 생길 시, 재해복구 시간이 현저히 감소됩니다.

재해 복구를 대비해서 `읽기 전용 복제본을 다중 AZ로 설정할 수 있다.`    
원하는 경우에는 읽기 전용 복제본을 다중 AZ로도 설정할 수 있습니다

단일 AZ에서 다중 AZ로 RDS 데이터베이스 전환이 가능할지 물을 수 있습니다  
이 작업에는 다운타임이 전혀 없는 점을 염두에 둬야 합니다  
즉 단일 AZ에서 다중 AZ로  
전환할 때에 데이터베이스를 중지할 필요가 없는 겁니다  

## 읽기 전용 복제본 (Read Replica)

읽기 전용 복제본은 이름에서 알 수 있듯 `읽기를 스케일`링합니다  

- 생성과정
  1. 원본 스냅샷 생성
  2. 스냅샷을 통해 복제본 인스턴스 생성
  3. 변경사항 발생 시 비동기식 복제

Replication 이란 `백업과 성능 향상을 위해서 데이터베이스를 여러 대의 서버에 복제`하는 행위를 뜻합니다.   
원본 데이터가 위치하는 서버를 마스터라고 하고, 그 원본을 복제한 서버를 슬레이브라고 합니다.  
마스터와 슬레이브를 `구분할 때는 읽기와 쓰기`를 이용합니다.  
데이터베이스의 작업은 읽기와 쓰기로 구분할 수 있습니다.  
SQL 로 말하면 읽기는 SELECT 구문이고, 쓰기는 INSERT, UPDATE, DELETE입니다.   
그런데 쓰기 작업은 저장된 데이터가 변경되기 때문에 복제된 서버들 간에 동일한 형태를 유지하는 것이 어렵습니다.  
그래서 보통 한대의 서버에만 쓰기 작업을 하고, `그 서버의 데이터를 복제해서 여러 대의 슬레이브 서버를 만든 후에 슬레이브에서는 읽기 작업만을 수행`합니다.   
read replica란 바로 이런 작업을 RDS에서 할 수 있도록 해주는 서비스입니다.

즉, Read Replica 는 RDS DB 인스턴스의 읽기 전용 인스턴스입니다.   
`서비스에서 읽기 위주의 작업이 많은 경우 Read Replica 를 여러 개 만들어서 부하를 분산`할 수 있습니다.   
즉, 쓰기 작업은 마스터 DB 인스턴스에 하고 읽기 작업은 Read Replica 에 할당하면 마스터 DB 인스턴스의 부하를 줄일 수 있습니다.   
만약 마스터 DB 인스턴스에 쓰기를 하면 자동으로 Read Replica DB 인스턴스로 데이터가 복제됩니다.   
단, 즉시 복제되는 것은 아니며 약간의 시간차가 있습니다.

Read Replica 는 성능 극대화를 위해 존재하기에, `Read heavy work 가 많을 시 Read Replica 를 사용`해야 합니다.   
만약 트래픽이 많아진다면, 서버 다운이 일어날 수 있는데, 이를 방지하기 위해 Read Replicas를 사용한다고 이해하면 좋습니다.   
앞서 배운 Multi AZ 와는 달리 이 기능은 Disaster Recovery 용도가 아닙니다.  
Read Replica 는 하나의 RDS DB에 대해 최대 5개까지 생성 가능합니다.  
또한 Read Replica 의 Read Replica 를 생성할 수 있습니다.  
하지만 생성 혹은 사용 시 약간의 latency 가 존재할 수 있습니다.  
그리고 마지막으로 Read Replica 는 고유의 앤드포인트가 존재합니다.   
RDS DB는 앤드포인트로 정체를 가려낼 수 있습니다.

RDS 읽기 전용 복제본과 관련된 네트워킹 비용을 한번 살펴보겠습니다  
AWS에서는 하나의 가용 영역에서 다른 가용 영역으로  
데이터가 이동할 때에 비용이 발생합니다  
하지만 예외가 존재하며 이 예외는 보통 관리형 서비스에서 나타납니다  
RDS 읽기 전용 복제본은 관리형 서비스입니다  
읽기 전용 복제본이 다른 AZ 상이지만  
`동일한 리전 내에 있을 때는 비용이 발생하지 않습니다`

하지만 서로 다른 리전에 복제본이 존재하는 경우  
즉 us-east-1에 대해서  
복제본이 eu-west-1에 존재하는 경우에는  
RDS DB 인스턴스와 읽기 전용 복제본이  
`여러 리전을 넘나들어야 하기 때문에 네트워크에 대한 복제 비용이 발생합니다`

## 암호화

먼저, 사용하지 않는 데이터인 미사용 데이터 암호화는  
AES 256비트 암호화를 사용하는  
AWS의 키 매니지먼트 서비스인 AWS KMS로  
마스터 데이터베이스와 읽기 전용 복제본을 암호화할 수 있습니다  
따라서 암호화 실행 시 실행 시간을 정의해야 하며  
마스터 데이터베이스를 암호화하지 않으면  
복제본도 암호화할 수 없습니다  

또, 늘 SSL 인증서가 필요한 전송 중 암호화도 있고  
이는 데이터 전송 중에 RDS로 암호화를 사용하는데  
클라이언트에서 데이터베이스로 전송 중인 것을 말합니다  

모든 클라이언트가 SSL을 사용하도록 하려면

PostgreSQL 에서는  
rds.force_ssl=I인 콘솔 매개변수 그룹을 설정해야 하며 꽤 명시적입니다  

MySQL 사용 시  
GRANT USAGE ON *.* TO 'mysqluser'@%'REQUIRE SSL이라는  
명령문을 데이터베이스 내부에서 실행해야 합니다  
이 또한 꽤 명시적이죠

RDS 백업을 암호화하는 방법입니다  
여기서 알아야 할 것은  
암호화 되지 않은 RDS 데이터베이스에서 스냅샷을 생성하면  
`스냅샷 자체는 암호화되지 않는 것`입니다  
마찬가지로 암호화된 RDS 데이터베이스에서 스냅샷을 생성하면  
모든 스냅샷이 기본으로 암호화되는데 이는 항상 기본 값은 아닙니다  
그래서 암호화되지 않은 스냅샷을  
암호화된 스냅샷으로 복제해야 합니다  
암호화되지 않은 RDS 데이터베이스의 스냅샷을 생성해 복제한 뒤  
이 스냅샷의 암호화된 버전을 쉽게 만들 수 있는 것이죠  

다음은 암호화되지 않은 RDS 데이터베이스의 암호화 방법입니다  
지금까지 배운 것으로  
암호화 되지 않은 RDS 데이터베이스의  
스냅샷을 생성해야 하고 이는 암호화되지 않습니다
그리고 스냅샷을 복제하고  
`복제한 스냅샷의 암호화를 활성화`합니다  
이제 복제된 암호화 스냅샷이 생겼습니다  
이 암호화된 스냅샷으로  
암호화된 스냅샷에서 데이터베이스를 복원할 수 있으며  
이는 암호화된 RDS 데이터베이스를 제공합니다  
이제 모든 애플리케이션을 이전의 암호화되지 않은  
RDS 데이터베이스에서 새 암호화된 RDS 데이터베이스로 옮기고  
이전 데이터 베이스를 삭제합니다  

정리하자면  
미사용 데이터 암호화는  
데이터베이스 인스턴스를 처음 생성할 때만 실행되며  
암호화되지 않았으면 스냅샷을 생성해야 합니다  
그리고 스냅샷을 복제해 암호화 한 다음에  
암호화된 스냅샷에서 새 데이터베이스를 생성하면  
데이터베이스를 암호화하죠

## 인증

이제 IAM 인증을 사용한 RDS 연결법을 살펴보겠습니다  
말씀드린 대로 `MySQL과 PostgreSQL에서만 실행`되며  
암호는 필요하지 않고  
`인증 토큰`이라는 것이 필요한데   
RDS API 호출을 사용해서 IAM으로 직접 얻을 수 있습니다

## Amazon 오로라(Aurora)

오로라는 AWS의 사유 기술입니다  
오픈 소스가 아니죠  
하지만 Postgres와 MySQL과 호환됩니다  

오로라에서는 장애 조치도 즉각적입니다  
MySQL RDS의 다중 AZ에서 장애 조치보다 속도가 훨씬 빠르죠  
기본적으로 클라우드 네이티브라서 가용성이 높기 때문입니다  
RDS보다 비용이 20% 정도 비싸지만  
규모 면에서 더 효율적이어서  
비용을 많이 절약할 수 있습니다

오로라가 특별한 이유는 3개 AZ에 걸쳐 기록하는 것은 무엇이든  
6개의 데이터 복제본을 저장하기 때문입니다  
6개의 복제본을 저장할 수 있는데  
쓰기에는 6개 중 4개만 필요합니다  
이는 한 개의 AZ가 다운돼도 괜찮다는 것을 말하며  
읽기에는 6개 중 3개만 필요하다는 의미입니다  
읽기에 아주 적합한 것이죠  
또한, 정말 훌륭한 자가 복구 과정이 있는데  
일부 데이터가 손상되거나 잘못된 경우  
백엔드에서 P2P 복제로  
자가 복구를 하는 것입니다  
하나가 아니라 수백 개의 볼륨에  
의지할 수 있는 것입니다

또, 읽기 전용 복제본에 오토 스케일링을 적용할 수 있습니다  
그래서 `최대 15개의 읽기 전용 복제본에 일정 수의 읽기 전용 복제본을 ` 
오토 스케일링을 통해 설정할 수 있습니다  
오토 스케일링으로 애플리케이션이 읽기 전용 복제본과 URL을  
추적하는 것이 어려워지고 연결하기도 어려워집니다  
이를 해결하는 방법이 시험에 자주 출제됩니다

`리더 엔드 포인트(Reader Endpoint)`라는 것은  
라이터 엔드 포인트와 동일한 기능이 있는데  
로드 밸런싱의 연결을 돕고  
`모든 읽기 전용 복제본에 자동으로 연결`합니다  
클라이언트가 리더 엔드 포인트에 연결할 때마다  
읽기 전용 복제본 중 하나가 연결돼  
이런 식으로 로드 밸런싱 됩니다  
한 가지 알아야 할 것은 로드 밸런싱은  
명령문 수준이 아니라 연결의 수준에서 발생합니다  

## Amazon 일래스틱 캐시

캐시란 무엇일까요? 캐시는 높은 성능과  
`낮은 지연 시간을 가진 인 메모리 데이터베이스`입니다  
그리고 일래스틱 캐시를 사용하면  
읽기 집약적인 워크로드의 부하를 줄이는데 도움이 됩니다  

일반적인 데이터베이스(RDBMS)는 디스크(HDD,SSD)에 데이터를 영구적으로 저장해 놓고, 필요한 데이터만 메모리에 읽어서 사용합니다.  
인 메모리 캐시는 `디스크에 접근하지 않고 메모리로만 모든 처리를 하기 떄문에 데이터 저장 및 검색 속도가 매우 빠릅니다.`   
단 데이터는 딱 메모리 크기까지만 저장할 수 있습니다.  
또한, 메모리에만 저장되어 있기 때문에 `서버의 전원 공급이 중단되면 데이터는 소멸`됩니다.

일래스틱 캐시와 RDS 데이터베이스 그리고 애플리케이션이 있고  
애플리케이션은 일래스틱 캐시를 쿼리합니다  
쿼리가 이미 생성됐는지  
이미 생성되어 일래스틱 캐시에 저장됐는지 확인하는 것은  
`캐시 히트(cache hit)`고  
이는 일래스틱 캐시에서 바로 응답을 얻어서  
쿼리하기 위해 데이터베이스로 이동하는 동선을 줄여줍니다  

`캐시 미스(cache miss)`의 경우에는 데이터베이스에서 데이터를 가져와서  
데이터베이스에서 읽습니다  
동일한 쿼리가 발생하는 다른 애플리케이션이나 인스턴스에서는  
데이터를 캐시에 다시 기록하여  
다음에는 `같은 쿼리로 캐시 히트를 얻도록 합니다`  
이는 RDS 데이터베이스에서 부하를 줄이는데 도움을 주는데  
데이터를 캐시에 저장하기 때문에  
캐시 무효화 전략이 있어야 하며  
가장 최근 데이터만 사용하는지 확인해야 합니다  
이것이 캐싱 기술 사용과 연관된 어려움이라고 할 수 있죠  

`레디스(Redis)`는 자동 장애 조치로 다중 AZ를 수행하는 기술이며  
읽기 전용 복제본은 읽기 스케일링에 사용되며 가용성이 높습니다  
약간 RDS와 비슷합니다  
그리고 지속성으로 인해 데이터 내구성도 있으며  
백업과 기능 복원 기능도 있습니다  
RDS와 많이 유사합니다

`멤캐시트(Memcached)`는 `데이터 분할에 다중 노드를 사용하고 이를 샤딩(sharding)` 이라고 합니다    
가용성이 높지 않고 복제도 발생하지 않습니다   
`지속적인 캐시가 아닙니다`  
백업과 복원 기능도 없죠  
그리고 다중 스레드 아키텍처로  
몇몇 샤딩과 함께 캐시에서 함께 실행되는  
여러 인스턴스가 있습니다  
여기서 기억해야 할 것은
`레디스는 고가용성과 백업읽기 전용 복제본 등이 있고`

`멤캐시트는 데이터를 손실할 수 없는 단순한 분산 캐시`입니다  
`가용성이 높지 않고 백업과 복원 기능도 없습니다`  
바로 이것이 두 기술의 가장 큰 차이점입니다

### Memcached 를 선택

`상대적으로 작고 정적인 데이터를 캐싱`하는 경우  
여러 코어 또는 스레드가 있는 멀티 스레드의 경우  
메모리 관리가 redis 만큼 정교하지는 않지만, `메타 데이터에 대한 메모리 리소스를 비교적 적게 소비하여 간단한 사용에 적합`하다.  
쉽게 확장할 수 있지만 해싱 사용 여부에 따라 캐시된 데이터의 일부 또는 전부를 잃는다.

### Redis 를 선택

문자열, 해시, 목록, 세트, 정렬된 세트 및 비트맵과 같은 `복잡한 데이터 유형이 필요한 경우`  
인 메모리 데이터 세트를 정렬하거나 순위를 지정해야 하는 경우  
키 저장소의 속성을 원할 경우  
읽기 집약적 애플리케이션을 위해 기본 항목에서 하나 이상의 읽기 전용 복제본으로 데이터를 복제해야 하는 경우  
`기본 노드가 실패할 때 자동 장애 조치가 필요한 경우`  
서버에 대한 `이벤트를 클라이언트에 알리기 위해 게시 및 구독(게시/구독) 기능이 필요한 경우`   
`백업 및 복원 기능이 필요한 경우`  
`여러 데이터베이스를 지원`해야 하는 경우

## 일래스틱캐시 (ElastiCashe) 전략

어떤 캐싱 설계 패턴이 가장 적합한가? 입니다

### 레이지 로딩(Lazy Loading)

시험에서는 캐시 어사이드(Cache-Aside)나  
레이지 포퓰레이션(Lazy Population) 라고도 합니다  
모두 같은 것을 의미합니다

### 라이트 스루(Write Through)

라이트 스루는 `데이터베이스가 업데이트될 때 캐시를 추가하거나 업데이트하는 것을 의미`합니다    
살펴보죠 아까와 같이 애플리케이션, 일래스틱 캐시, RDS가 있습니다  
애플리케이션이 일래스틱 캐시와 통신할 때  
캐시 히트가 발생하면 좋죠  
그리고 RDS에서 쓰기를 할 때  
즉, 애플리케이션이 아마존 RDS 데이터베이스를 수정할 때  
먼저 캐시에 쓸 것입니다  
라이트 스루라고 부르는 이유는  
일래스틱 캐시를 통해 RDS에 쓰기 때문입니다  
이 구조에서 무엇을 얻을 수 있을까요?  
캐시 데이터는 절대 오래될 수 없습니다  
아마존 RDS가 바뀔 때마다  
캐시도 자동으로 바뀌게 됩니다 

### 캐시 제거와 타임 투 리브(TTL)

즉, 캐시에 제한된 크기가 있습니다  
따라서 캐시 데이터를 제거하기 위해 Cache Eviction이란 방법을 사용합니다  
`예를 들어 항목을 캐시에서 명시적으로 삭제`하거나  
캐시 메모리가 꽉 찼을 때 사용합니다  
그러면 가장 최근에 사용되지 않은 항목이 제거됩니다  
이를 LRU 또는 최근 최소사용이라고 하거나  
항목을 타임 투 리브(TTL)로 설정할 수 있습니다  
예를 들어 이 항목은 5분 동안만 사용 가능하니  
5분이 되면 캐시에서 삭제될 것이라는 뜻입니다  
TTL은 리더보드, 코멘트, 활동 스트림 등등  
어떤 종류의 데이터에도 유용합니다

## Redis 클러스터 모드

레디스에서 할 수 있는 일래스틱 캐시 복제 방식은 2개이며 둘 다 알아야 합니다

### 클러스터 모드 비활성화입니다

샤드란  
샤드(shard)란 샤딩을 통해 나누어진 블록들의 구간(혹은 Epoch)을 말한다.   
샤드는 지분증명과 관련이 있는 것이 아니라 확장성 개선과 관련된 개념이다.   
샤딩(sharding)의 아이디어는 가능한 계정(계약도 계정)의 공간을 숫자 주소의 첫 번째 숫자를 기준으로 하위 공간으로 분할하는 것이다.   
샤드에 포함된 정보는 여전히 다른 노드와 공유할 수 있으며,   
모든 사람이 여전히 모든 원장 항목을 볼 수 있기 때문에 원장을 분산하고 안전하게 유지할 수 있다.   
그들은 단지 모든 정보를 처리하고 저장하지 않는다.

이 경우, 기본 노드는 1개이며  
`5개까지 노드를 복제`할 수 있습니다
레디스에는 샤드가 1개 있으며  
`모든 데이터가 이 샤드`에 있습니다  
기본 캐시 노드는 1개입니다  
선택적으로 `5개까지 캐시를 복제`할 수 있습니다  
즉, `노드의 복제본은 0개에서 5개`까지 가질 수 있습니다  
기본 노드와 복제본이 있을 때  
기본 노드에 실패가 발생하면  
복제본이 대신합니다  
`복제본은 캐시 간에 비동기적`이며  
기본 노드는 읽기와 쓰기에 사용됩니다  
다른 노드는 읽기 전용이죠  
장애 복구 외에도  
읽기 복제본을 활성화함으로써  
레디스용 일래스틱 캐시에서 읽기 성능을 올릴 수 있습니다  
즉, 샤드 1개가 있고  
모든 노드가 레디스 클러스에 있는 데이터를 갖게 될 것입니다  
이를 통해 노드 실패가 발생할 때 데이터의 손실을 대비합니다  
다중 AZ를 활성화할 수도 있습니다 다중 AZ 장애 조치를 위해  
기본값으로 활성화되어 있습니다  
다시 한번, 이것은 다중 AZ에 유용합니다  
또한 일래스틱 캐시 클러스터의  
읽기 성능을 올릴 때도 사용합니다  

### 클러스터 모드 활성화

이 모드에서는 `데이터가 여러 샤드로 분할`되며  
`쓰기를 확장할 때 유용`합니다  
예시로 살펴보겠습니다 여기 샤드 1  
샤드 2, 샤드 3, 샤드 N이 있습니다  
기본 아이디어는 데이터의 일부분이  
샤드 1에,  
일부분은 샤드 2에, 이런 식으로 샤드 N까지 분할됩니다  
즉, 데이터는 모든 샤드에 걸쳐 분할됩니다  
각 샤드는 이전에 본 클러스터 모드 비활성화처럼  
똑같이 동작합니다  
즉, 기본 노드 1개가 있고  
노드의 복제본은 5개까지 있습니다  
데이터가 복제되고 모든 샤드에서  
복제본 수를 동일하게 설정합니다  
다중 AZ도 가능합니다 기본값으로 활성화되어 있습니다  
기본 노드와 복제본 사이에서  
장애가 발생했을 때 장애 조치가 가능합니다  
클러스터 당 최대 500개의 노드를 가질 수 있습니다  
즉 복제본을 만들지 않는다면  
단일 마스터에 500개의 샤드를 갖는다는 뜻입니다  
복제본을 설정하면  
예를 들어, 마스터 1개와 복제본 1개를 원한다면  
250개의 샤드를 갖습니다  
마스터 1개에 5개의 복제본을 원하면  
최대 83개의 샤드를 가질 수 있습니다  
클러스터 모드를 활성화하는 경우  
데이터 샤딩에 정말로 관심 있는 것입니다  
`즉, 쓰기를 확장하기 원하고 데이터는 분할될 것입니다`    
데이터가 여러 샤드에 걸쳐 분할되겠죠  
이것이 일래스틱 캐시에서 클러스터 모드 활성화와  
클러스터 모드 비활성화의 차이점입니다  






























# ELB

## 고가용성과 확장성

### 확장성

확장성은 애플리케이션 시스템이  
`조정을 통해 더 많은 양을 처리`할 수 있다는 의미입니다  

우선 `수직 확장성`이 있고  
탄력성이라고 불리기도 하는 `수평 확장성`이 있습니다  

확장성과 고가용성은 서로 다른 개념입니다

먼저 수직 확장성입니다  
수직 확장성은 인스턴스의 크기(T2.small -> T2.lage) 처럼 `사양을 확장하는 것을 의미`합니다
그러면 이런 수직 확장성을 언제 사용하게 되는 걸까요?  
데이터베이스와 같이 분산되지 않은 시스템에서 흔히 사용됩니다   
하지만 일반적으로 확장할 수 있는 정도에는 한계가 있는데요  
하드웨어 제한이 걸려 있죠  

수평 확장성이란  
애플리케이션에서 `인스턴스나 시스템의 수`를 늘리는 방법입니다  
T2.small T2.small T2.small ...

`수평 확장은 인스턴스의 수를 늘린다는 뜻`인데  
AWS 용어로는 스케일 아웃과 스케일 인이라고 합니다  
인스턴스의 수가 `늘어나면 스케일 아웃`이고요  
`수를 줄이면 스케일 인`이죠  
다른 스케일링 그룹이나 로드 밸런서에도 사용합니다

고가용성은 `동일 애플리케이션의 동일 인스턴스를 다수의 AZ에 걸쳐 실행하는 경우`를 의미하죠   
다중 AZ가 활성화된 자동 스케일러 그룹이나 로드 밸런서에서도 사용됩니다  

## 로드 밸런싱

부하를 다수의 다운스트림 인스턴스로 분산하기 위해서죠  
다운스트림 인스턴스의 장애를 원활히 처리할 수 있죠  
로드 밸런서가 상태 확인 메커니즘으로  
어떤 인스턴스로 트래픽을 보낼 수 없는지 확인해 주거든요  

해당 인스턴스로는 트래픽을 보낼 수 없기 때문에  
로드 밸런서에겐 인스턴스의 상태가  
아주 중요하죠 그리고 상태 확인은  
포트와 라우트에서 이뤄집니다  

### Classic Load Balancers

이 로드 밸런서는 TCP나 트래픽 아니면 HTTP와 HTTPS를 지원합니다  
TCP는 4계층으로 HTTP/HTTPS는 7계층인데요

상태 확인은 TCP 또는 HTTP 기반으로 이루어집니다

### 애플리케이션 로드 밸런서

7계층, 즉 `HTTP 전용 로드 밸런서`로  
머신 간 다수 HTTP 애플리케이션의 라우팅에 사용이 되죠  
이러한 머신들은 대상 그룹이라는 그룹으로 묶이게 되는데요
동일 EC2 인스턴스 상의 여러 애플리케이션에 부하를 분산합니다  

컨테이너와 ECS를 사용하게 되죠  
HTTP/2와 WebSocket을 지원하며 리다이렉트도 지원하므로  
HTTP에서 HTTPS로 트래픽을 자동 리다이렉트하려는 경우  
로드 밸런서 레벨에서 가능하다는 의미가 되겠죠  

EC2 인스턴스가 대상 그룹이 될 수 있습니다

Application Load Balancer를 사용하여 EC2 인스턴스로 트래픽을   
분산할 때 요청을 수신하는 IP 주소는 ALB의 프라이빗 IP 주소가 됩니다.   
클라이언트의 IP 주소를 가져오기 위해 ALB는 클라이언트의 IP 주소를 포함하는  
X-Forwarded-For라는 추가 헤더를 추가합니다.

ALB는 URL 경로, 호스트 이름, HTTP 헤더 및 쿼리 문자열을 기반으로 트래픽을 다른 대상 그룹으로 라우팅할 수 있습니다.

### 네트워크 로드 밸런서

layer 4(L4) 밸런서로  
TCP나 UDP 기반의 트래픽을  
인스턴스로 전달하는 것입니다  
낮은 계층의 밸런서죠  
초당 수백만 건의 요청을 처리할 수 있어 매우 고성능입니다  
ALB보다 지연 시간이 훨씬 짧습니다

밸런서 `애플리케이션의 평균 지연 시간은 400ms` 이고
반면에 `NLB의 지연 시간은 약 100ms` 입니다

NLB의 사용 사례를 살펴보면 고성능이나 TCP 또는 UDP 수준의  
트래픽을 원할 때 사용합니다

그렇다면 NLB는 무엇을 트래픽에 보낼까요?

여러 대상 그룹인데  
첫 번째는 EC2 인스턴스로  
대상 그룹에 EC2 인스턴스를 등록하면  
NLB에서 트래픽 전송 방법을 파악합니다  

두 번째는 IP 주소입니다  
고정 IP와 개인 IP를 지정해서  
NLB에서 직접 트래픽을 보내도록 합니다  
이유가 무엇일까요?  
약간 과하지만 EC2 인스턴스의 경우  
자체 데이터 센터에 서버가 있는 경우에는  
가급적이면 그대로 개인 IP가 있는 서버의 로드 밸런서를 사용합니다

세 번째 옵션은 ALB입니다  
`NLB와 ALB를 결합`하는 것이 가능하죠  
왜 결합할까요?  
NLB의 기능을 활용해서 고정 IP를 가질 수 있기 때문입니다  
따라서 NLB 수준의 고정 IP를 가지면서  
규칙과 같은 HTTP 관련 기능에  
ALB를 활용할 수 있는 것이죠  

Network Load Balancer에는 AZ당 하나의 static IP 주소가 있으며 
Elastic IP 주소를 연결할 수 있습니다. 
Application Load Balancer 및 Classic Load Balancer는 
static DNS 이름입니다.

### 게이트웨이 로드 밸런서

GWLB는 네트워크의 모든 트래픽이  
방화벽을 통과하게 하거나  
침입 탐지 및 방지 시스템에 사용합니다  
그래서 IDPS나 심층 패킷 분석 시스템 또는  
일부 페이로드를 수정할 수 있지만  
네트워크 수준에서 가능합니다

모든 로드 밸런서보다 낮은 수준에서 실행됩니다  
IP 패킷의 네트워크 계층인 L3입니다  
이제 GWLB는 2가지 기능을 갖게 됩니다

첫 번째는 투명 네트워크 게이트웨이입니다  
VCP의 모든 트래픽이 GWLB가 되는  
단일 엔트리와 출구를 통과하기 때문입니다  
그리고 대상 그룹의 가상 어플라이언스 집합에  
전반적으로 그 트래픽을 분산해 로드 밸런서가 됩니다  
이 부분이 GWLB에 관해 꼭 알아야 할 부분입니다  
마지막으로 시험 볼 때  
6081번 포트의 GENEVE 프로토콜을 사용하세요  
바로 GWLB가 됩니다

## Sticky Sessions

중요한 정보를 취하는  
세션 데이터를 잃지 않기 위해  
사용자가 동일한 백엔드 인스턴스에 연결됩니다  
고정성을 활성화하면  
백엔드 EC2 인스턴스 부하에 불균형을 초래할 수 있습니다  
일부 인스턴스는 고정 사용자를 갖게 됩니다  

### 애플리케이션 기반 쿠키

대상으로 생성된 사용자 정의 쿠키로  
애플리케이션에서 생성됩니다  
그리고 애플리케이션에 필요한 모든 사용자 정의 속성을 포함할 수 있죠  
쿠키 이름은 각 대상 그룹별로 개별적으로 지정해야 하는데  
이런 이름은 사용하면 안 됩니다  
AWSALB, AWSALBAPP 혹은 AWSALBTG 같은 이름이죠  
ELB에서 사용하기 때문입니다

애플리케이션 쿠키가 될 수도 있는데  
지금은 로드 밸런서 자체에서 생성됩니다  
그리고 ALB의 쿠키 이름은 AWSALBAPP입니다 

### 기간 기반 쿠키

로드 밸런서에서 생성되는 쿠키로  
ALB에서는 이름이 AWSALB이며 CLB에서는 AWSELB입니다  
특정 기간을 기반으로 만료되며 그 기간이 로드 밸런서 자체에서  
생성되는 것입니다  
애플리케이션 기반의 쿠키는  
애플리케이션에서 기간을 지정할 수 있습니다

## 교차 영역 로드 밸런싱

교차 영역 로드 밸런싱은 ALB에서 늘 활성화되어 있고
비활성화할 수 없습니다  
보통 데이터가 한 가용 영역에서 다른 가용 영역으로 이동하면  
비용을 지불해야 합니다  
하지만 활성화되어 비활성화할 수 없으니  
AZ 간 데이터 전송에 관한 비용이 없습니다  

네트워크 로드 밸런서에는 기본으로 비활성화되어 있어서  
교차 영역 로드 밸런싱 활성화에 비용을 지불해야 합니다  
가용 영역 간 데이터 전송에 비용을 지불해야 하는 것이죠

마지막으로 클래식 로드 밸런서에는  
교차 영역 로드 밸런싱이 기본으로 비활성화되어 있습니다  
활성화하면 가용 영역 간 데이터 전송에 비용이 발생하지 않습니다  
모든 로드 밸런서에서 사용할 수 있는 것이죠

`ALB에는 기본적으로 활성화`되어 있고  
`NLB에서 활성화하려면 비용`을 내야 합니다  
그리고 `CLB 에는 비용 없이 활성화`할 수 있습니다

## SSL

SSL 인증서를 사용하면 클라이언트와 로드 밸런서  
사이에서 전송 중에 있는 트래픽을 암호화할 수 있습니다  
인-플라이트 암호화라고 불리는 과정으로  
`즉 데이터가 네트워크를 통과하는 중에 암호화되고  
발신자와 수신자만이 이를 해독할 수 있는 거죠`  
SSL은 보안 소켓 계층을 뜻하며 연결을 암호화하는 데에 사용됩니다  
그리고 TLS는 SSL의 최신 버전으로써 전송 계층 보안을 의미하죠  
요즘에 주로 사용되는 건 TLC 인증서지만  
저를 포함한 많은 사람들은 이를 여전히 SSL이라고 부르고 있습니다  

공용 SSL 인증서는 Comodo, Symantec GoDaddy, GlobalSign  
Letsencrypt 등의 인증 기관에서 발급됩니다  
로드 밸런서와 연결된 공용 SSL 인증서를 사용하면  
클라이언트와 로드 밸런서 사이의 연결을 암호화할 수 있습니다

유저가 HTTPS를 통해 연결됩니다  
이때 S는 SSL 인증서를 사용하고 있다는 의미이며  
암호화되어 안전한 상태죠  
그리고 공용 인터넷을 통해 로드 밸런서와 연결되죠  
그리고 이때 로드 밸런서는 내부적으로  
SSL 인증서 종료라는 작업을 수행합니다  
그리고 백엔드에서는 EC2 인스턴스와 통신할 수 있는데, HTTP를 사용하기  
때문에 암호화는 되어 있지 않죠 하지만 트래픽은 어느 정도의 안전성을  
보장하는 사설 네트워크인 VPC를 통해 전송됩니다  
그럼 로드 밸런서가 X.509 인증서를 불러옵니다  
SSL 혹은 TLS 서버 인증서라고 불리는 인증서죠  
그리고 AWS에서 ACM을 사용해 SSL 인증서를 관리할 수 있습니다  
ACM은 AWS 인증서 관리자의 약자죠

SNI, 즉 서버 이름 표시  
CLB는 구형 버전으로 SNI를 지원하지 않는다는 점  
반면 ALB와 NLB는, SNI 및 다중 SSL 인증서를 지원하죠

## 등록 취소 지연

클래식 로드 밸런서를 사용할 경우에는 연결 드레이닝이라 부르고  
애플리케이션 밸런서나 네트워크 로드 밸런서를 사용하는 경우에는 등록 취소 지연 이라 부른다.

인스턴스가 등록 취소, 혹은 비정상인 상태에 있을 때  
인스턴스에 어느 정도의 시간을 주어  
인-플라이트 요청, 즉 활성 요청을 완료할 수 있도록 하는 기능이죠  
연결이 드레이닝되면 즉 인스턴스가 드레이닝되면  
ELB는 등록 취소 중인 EC2 인스턴스로  
새로운 요청을 보내지 않는 거죠

연결 드레이닝 파라미터는 매개변수로 표시할 수 있습니다  
1부터 3,600초 사이의 값으로 설정할 수 있는데  
`기본적으로는 300초, 즉 5분`입니다

## 오토스케일링 AGS

스케일 아웃이 있습니다  
부하가 증가하면 거기 맞춰서 EC2 인스턴스를 추가하는 거죠  
반면 스케일 인은 줄어든 부하에 맞춰 EC2 인스턴스를 제거하는 작업입니다  
그리고 오토 스케일링 그룹은 EC2 인스턴스가 일정량만큼만  
증가하거나 줄어들도록 만들 수도 있는데요  
그렇게 되면 ASG에서 실행되는  
머신의 최소 및 최대 숫자를 설정할 수 있습니다
마지막으로 ASG에는 굉장히 좋은 기능이 있는데요  
`로드 밸런서에 자동으로 새 인스턴스를 등록해 주는 기능입니다`

### 오토 스케일링 그룹의 스케일링 정책

먼저 동적 스케일링 정책부터 보겠습니다  
동적 스케일링 정책은 세 가지 유형이 있습니다  

첫 번째는 대상 추적 스케일링으로 가장 단순하고 설정하기도 쉽죠  
예를 들면 모든 EC2 인스턴스에서  
오토 스케일링 그룹의 평균 CPU 사용률을 추적하여  
이 수치가 40%대에 머무를 수 있도록 할 때에 사용합니다  
이처럼 기본 기준선을 세우고  
상시 가용이 가능하도록 하는 거죠  

단순과 단계 스케일링은 좀 더 복잡합니다  
CloudWatch 경보를 설정하고  
가령 다음과 같이  
전체 ASG에 대한 CPU 사용률이 70%를 초과하는 경우  
용량을 두 유닛 추가하도록 설정할 수 있죠  
그리고 전체 ASG 내의  
CPU 사용률이 30% 이하로 떨어지면 유닛 하나를 제거한다는  
설정도 추가할 수 있습니다

예약된 작업이 있습니다  
나와 있는 사용 패턴을 바탕으로 스케일링을 예상하는 거죠  
예를 들어서  
금요일 오후 5시에 큰 이벤트가 예정되어 있으니  
여러 사람들이 애플리케이션을 사용하는 데에 대비해  
여러분의 ASG 최소 용량을  
매주 금요일 오후 5시마다 자동으로 10까지 늘리도록 하는 겁니다  

제 생각에는 머신 러닝을 기반으로 하며  
손쉬운 ASG 오토 스케일링 중 하나인 예측 스케일링이 향후 더욱 대두될 겁니다
따라서 스케일링 기반이 될 훌륭한 지표가 있어야겠죠  
여러분의 애플리케이션의 목적과 작동 방식에 따라 달라지긴 하지만  
대표적인 것들을 살펴보겠습니다  
첫째로는 CPU 사용률을 들 수 있습니다  
일반적으로 인스턴스에 요청이 갈 때마다  
일종의 연산이 수행되어야 하므로  
이 과정에서 일부 CPU가 사용됩니다  
모든 인스턴스의 평균 CPU 사용률을 봤을 때  
이 수치가 올라가면  
인스턴스가 잘 사용되고 있다는 의미이니  
스케일링에 있어서 좋은 지표가 될 겁니다  
또 다른 지표를 보겠습니다  
애플리케이션에 따라 다를 수 있습니다만  
테스트를 기반으로 하는 대상별 요청의 수를 들 수 있습니다  
EC2 인스턴스는 한 번에 대상별로  
1,000개의 요청까지만 최적으로 작동하므로  
바로 이 대상을 스케일링에 활용할 수 있겠습니다  
예를 들어서 업로드와 다운로드가 많아  
EC2 인스턴스에 대해 해당 네트워크에서 병목 현상이 발생할 것으로 판단된다면  
평균 네트워크 입출력량을 기반으로 스케일링을 수행해서  
특정 임계값에 도달할 때  
스케일링을 수행하도록 설정할 수 있습니다  
또는 여러분이 직접 CloudWatch에서  
애플리케이션 별로 지표를 설정하고  
이를 기반으로 스케일링 정책을 바꿀 수 있습니다

스케일링 휴지(Scaling Cooldown)
인스턴스의 추가 또는 삭제를 막론하고  
기본적으로 5분 혹은 300초의 휴지 기간을 갖는 것입니다  
휴지 기간에는 ASG가 추가 인스턴스를 실행 또는 종료할 수 없습니다 

EC2 Health Checks(기본값) 대신 Application Load Balancer Health Checks을 기반으로 EC2 인스턴스의 상태를 확인하도록 ASG을 구성할 수 있습니다. EC2 인스턴스가 ALB Health Checks에 실패하면 비정상으로 표시되고 ASG가 새 EC2 인스턴스를 시작하는 동안 종료됩니다.















































































































































































































































































































































































































